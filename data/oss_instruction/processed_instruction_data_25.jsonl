{"index": 1895085, "Problem": "Given that we have 3 numpy arrays, a, b and c, with shapes (30,) and we have zero values by using np.zeros() and random values by using np.random.randn() selects certain indexes. We don't know how these 3 arrays match to some data table. We need to create a new numpy array, d, with the same dimensions as the sum of (a, b, and c), then perform some comparison operations between d and individual array, like out=np.where(d>a, d, a), then we will get operation result array e, same operation between d and c, we will get result array f. We need to determine whether d and e are greater than c(f) or not. if they are not greater than d, it will return -1, if either of them is greater than c(f). then determine which one is greater, it will return d/e.", "Solution": "a = np.zeros([30])\nb = np.zeros([30])\nc = np.zeros([30])\n\nnp.random.seed(0)\nselect_index = np.random.choice(8, 10)\na[select_index] = np.random.randn(10)\nselect_index = np.random.choice(8, 10)\nb[select_index] = np.random.randn(10)\nselect_index = np.random.choice(8, 5)\nc[select_index] = np.random.randn(5)\n\nd = np.zeros([30])\nd = np.where(d > a, d, a)\ne = np.where(d> b, d, b)\nf = np.where(d > c, d, c)\n\nprint(\"d: \", d, \"e: \", e, \"f: \", f)\nprint(d > c)\nprint(d >f)\nif~(d > c)|(d>e):\n    print(-1)\nelse:\n    print(d/e)  # it will print -1"}
{"index": 3249746, "Problem": "A recent work on Machine Learning realized that we can apply the likelihood-based probabilistic reasoning using the Multinomial-Dirichlet model. In this context, define a function (using only NumPy) that implements the Laplace approximation to the evidence lower bound (ELBO) in the Mixture of Multinomial-Dirichlet. Please note that we should  mine $K$ with its true value $K^{*}$ and $\\alpha = \\alpha^{*}$. Also, for the implementation, consider the following parameters (hyper-parameters) of the Multinomial-Dirichlet Distribution:\n - $K$: Number of categories in the Dirichlet Distribution.\n - $N$: Total number of samples\n - $\\overrightarrow{\\theta}$ : Vector of marginal probabilities\n - $\\overrightarrow{\\alpha}$: Vector of concentration parameters.\n \nFurther, for the implementation, we use the Multinomial distribution for $y$ with a known number of trials $n_{i}$. \nYou should modify  $\\overrightarrow{\\alpha}$  so that it's applied for more general observations to any sample.", "Solution": "import numpy as np\n\ndef log_multinomial_dirichlet(x, alpha):\n    \"\"\" \n    Multinomial distribution with the Dirichlet prior \n    \"\"\"\n    y = np.sum(x,axis=1)\n    prob = np.log(alpha).sum()+np.sum(x * np.log(x / alpha),axis=1)\n    return prob - np.log(y)\n\ndef mixture_of_multinomial_dirichlet_joint(n,theta,alpha,obs):\n    K = alpha.shape[0]\n    log_joint = log_multinomial_dirichlet(obs,alpha)\n    log_p_x_theta = 0\n    for i in np.arange(K):\n        if n[i] > 0:\n            log_p_x_theta += log_multinomial_dirichlet(n[i]*obs[i]/n.shape[0],alpha[i])\n\n    X_theta = np.exp(log_joint)\n    log_sum_p_theta = np.log(np.sum(np.exp(log_p_x_theta),axis=0))\n    \n    return  \\\n    log_sum_p_theta- \\\n    np.sum((n * log_multinomial_dirichlet(n * obs / n.sum(), alpha)) / n.sum()) \\\n    - np.sum(theta * log_multinomial_dirichlet(theta,n))\n    \ndef laplace_approximation_N_ELBO(n,theta,alpha,obs,N):\n    nosophobic = np.zeros(np.shape(theta))\n    shape_of_n = np.shape(n)\n    def neg_psi(r):\n        X_theta = np.exp(r[:,np.newaxis] +\n                         mixture_of_multinomial_dirichlet_joint(n,theta,alpha,\n                                                                obs)[:,np.newaxis] -\n                         mixture_of_multinomial_dirichlet_joint(n,theta,alpha,\n                                                                 obs+r/n))\n        log_sum_X_theta_overrinterm = np.log(np.sum(X_theta,1))[:,np.newaxis]\n        X_theta /=(X_theta + 1e-5)\n        pzi = np.log(np.dot(X_theta, np.exp(r-np.newaxis,r.shape[0])- 1))\n        return -np.mean(pzi+log_sum_X_theta_overrinterm)\n        \n    def energy(r):\n        pzi = -np.mean(\n        np.exp(log_multinomial_dirichlet(n * obs / n.sum(),alpha))\\\n        *log_multinomial_dirichlet(n * obs / n.sum(),alpha))\n        return pzi + neg_psi(r)\n        \n    X_spac = np.linspace(-10, 20, 100)\n    shape_of_X_spac = np.shape(X_spac)\n    init_point=r = np.zeros(shape_of_X_spac[0])\n   \n    numerical_gradient = np.zeros(shape_of_n)\n    numerical_hessian = np.zeros((shape_of_X_spac[0],shape_of_X_spac[0]))\n    Hartree_energy = np.zeros((shape_of_X_spac[0]))\n    \n    for Xx in range(shape_of_X_spac[0]):\n\n        neg_energy =  energy(X_spac[Xx]) \n        numerical_hessian[Xx,Xx] = (energy(X_spac[Xx]+1e-15)-energy\\\n                                      (X_spac[Xx]-1e-15))/2.0\n        numerical_gradient[Xx] = (energy(X_spac[Xx]+1e-15)-energy\\\n                                 (X_spac[Xx]) ) /(1e-15)\n        Hartree_energy[Xx] = neg_energy\n    r = np.argmin(Hartree_energy) \n    return (energy(r))"}
{"index": 3319312, "Problem": "Given a 2D array, A, and a 1D array, B, generate all possible combinations of addition and multiplication operators and their corresponding output arrays. Assuming that both A and B have the same number of rows, you want to perform a row-by-row operation.\nAssuming that A and B are 2D NumPy arrays with shape (3, 3) and (3,), respectively. A has values:\n```\narray([[ 1,  2,  3],\n       [ 4,  5,  6],\n       [ 7,  8,  9]])\n```\n\nand B has values:\n```\narray([10, 11, 12])\n```\nReturn a 3D array where each dimension corresponds to the row of A, the operator, and the output value.\nFor example, in row 1 of A and B, addition with 1 and addition with value in that row, should be done respectively, and the results should be placed in the output array.", "Solution": "import numpy as np\nA = np.array([[ 1,  2,  3], [ 4,  5,  6], [ 7,  8,  9]]) \nB = np.array([10, 11, 12]) \nresult = np.zeros((A.shape[0], 6, A.shape[1]))\noperator = np.array([[0, 1, 2, 3, 4, 4], [1, 0, 1, 2, 3, 3], [0, 0, 1, 2, 3, 3]])\nfor i in range(A.shape[0]):\n  result[i, 0, :] = B[i]\n  result[i, 1, :] = A[i] + B[i]\n  result[i, 2, :] = A[i] * B[i]\n  result[i, 3, :] = B[i] + A[i]\n  result[i, 4, :] = A[i] - B[i]\n  result[i, 5, :] = A[i] - B[i]\nprint(result)"}
{"index": 3910216, "Problem": "You are given a 3D array `volume` of shape (x, y, z) representing a 3D volume, where `x`, `y`, and `z` are the dimensions of the volume. The values in the array represent the density of each point in the volume. You need to find the indices of all points in the volume that have a density greater than 5 and are located within a distance of 2 units along the z-axis from a given z-coordinate.", "Solution": "```python\nimport numpy as np\n\n# Define the volume array\nvolume = np.random.randint(0, 10, size=(5, 5, 5))  # Example array for demonstration\n\n# Define the threshold density and distance\nthreshold_density = 5\ndistance = 2\n\n# Define the reference z-coordinate\nz_ref = 2\n\n# Initialize mask array\nmask = np.zeros_like(volume, dtype=bool)\n\n# Iterate over x, y, and z axes\nfor x in range(volume.shape[0]):\n    for y in range(volume.shape[1]):\n        for z in range(volume.shape[2]):\n            # Check if density is greater than threshold and within distance from z_ref\n            condition1 = volume[x, y, z] > threshold_density\n            condition2 = abs(z - z_ref) <= distance\n            mask[x, y, z] = np.logical_and(condition1, condition2)\n\n# Get the indices of the points satisfying the condition\nindices = np.where(mask)\n\nprint(indices)\n```"}
{"index": 6223044, "Problem": "Create a big 3D array from a series of 1D arrays of integers. These 1D arrays are constrained to have unique sizes. In the numpy array, each row represents the 1D array, and each column represents an integer increment. The rows in the numpy array are in ascending order of their individual sizes,(states). Given an initial array of 1D arrays `initial_1d_arrays`, construct the big 3D array with following conditions:\n\n- If a row of the result array contains all zeros, discard this row.\n- If a column of the result array contains all zeros, discard this column.", "Solution": "import numpy as np\n\ndef create_big_matrix(initial_1d_arrays):\n    # sort 1D arrays based on their sizes\n    sorted_arrays = [arr for _, arr in sorted(zip([len(arr) for arr in initial_1d_arrays], initial_1d_arrays))]\n    \n    # get unique sizes\n    unique_sizes = sorted(set([len(arr) for arr in sorted_arrays]))\n    \n    # create big matrix with zeros\n    big_matrix = np.zeros((len(unique_sizes), max(unique_sizes), len(sorted_arrays)), dtype=int)\n    \n    # fill in each 1D array to its corresponding column\n    for i, arr in enumerate(sorted_arrays):\n        s = len(arr)\n        for j, size in enumerate(unique_sizes):\n            if s == size:\n                big_matrix[j, :len(arr), i] = np.array(arr)\n            s -= 1\n    \n    # discard rows and columns that contain all zeros\n    rows = np.any(big_matrix, axis=1)\n    cols = np.all(big_matrix, axis=0)\n    big_matrix = big_matrix[rows,  ~cols]\n    \n    return big_matrix\n\ninitial_1d_arrays = [np.array([0, 1, 2, 3]), np.array([4, 5]), np.array([6, 7, 8]), np.array([9, 10, 11])]\nprint(create_big_matrix(initial_1d_arrays))"}
{"index": 6456538, "Problem": "Given a 2D array `arr` with dimensions (m, n) containing integers, write a function that returns the sum of all elements in the array, as well as the product of all elements in the array. The function should also mark the input array as modified so that any downstream operations on it will result in an error.\n\n coding directly just use numpy api", "Solution": "import numpy as np\n\ndef get_sum_and_product(arr):\n    # Calculate the sum of all elements in the array\n    sum_arr = np.nansum(arr)\n    \n    # Calculate the product of all elements in the array\n    product_arr = np.product(arr, where=~np.isnan(arr))\n    \n    # Replace the original array with 1e20\n    arr[np.isnan(arr)] = 1e20\n    arr_filled = np.nan_to_num(arr, copy=False, posinf=np.inf)\n    \n    # Mark the input array as modified\n    np.put(arr, np.arange(arr.size), 1e20)\n    \n    return sum_arr, product_arr, arr_filled\n\n# Test the function\narr = np.array([[1, 2, np.nan, 4], [5, 6, np.nan, 8]])\nresult = get_sum_and_product(arr)\nprint(result)"}
{"index": 8131034, "Problem": "Given a matrix A a matrix Q representing orientation in 3D, where elements of each row represent the 3 Euler angles in radian units.\nGiven a vector V representing the RPY (Roll, Pitch, Yaw) of the overall orientation. Using the code snippet given, create the function plot_position_surface() that takes a matrix A as input  and creates three surfaces representing the roll, pitch and yaw as a function of time  t  and the 3 Euler angles", "Solution": "def plot_position_surface(A):\n    import numpy as np\n    t = np.linspace(0, 4*np.pi, 100)\n    tt, xx, yy, zz = np.meshgrid(t, A[:, 0], A[:, 1], A[:, 2])\n    fig, axs = plt.subplots(3, 1, figsize=(10, 3))\n    for i in range(3):\n        axs[i].plot_surface(np.sin(tt)*np.cos(xx),\n                                    np.sin(tt)*np.sin(yy)*np.cos(zz),\n                                    np.cos(tt)*np.cos(xx),\n                                    cmap='viridis', edgecolor='none')\n        axs[i].set_title('RPY vs time and angles')\n        axs[i].set_xlabel('Roll')\n        axs[i].set_ylabel('Pitch')\n        axs[i].set_zlabel('Yaw')\n    return fig, axs[1]\n\n# test the function\nA = np.random.rand(100, 3)\nfig, axs = plot_position_surface(A)\nplt.show()"}
{"index": 8255999, "Problem": "In the context of random graphs, generate three random graphs based on a range of values and then determine various properties of these graphs.\n\nSpecifically, generate a random graph with a specified number of nodes and a target edge density. Then, after three iterations, calculate and print the number of nodes, the target edge density, the count of triangles and squares within each graph, as well as the time it takes to do so.\n\nEnsure that the graphs are represented using adjacency matrices in adjacency matrix representation.\n\n\nYou will have to define some properties functions like is_square() that returns True if a square exists in the graph else False, timeit that calculates how long an operation on the graph takes to complete, a triangle found with is_triangle(), that takes the adjacency matrix as an argument", "Solution": "import numpy as np\nimport time\n\n# Random graph generation function\ndef generate_random_graph(n, p):\n    # Generate random edges with the given probability\n    edges_m = np.random.choice(n, 2, replace=False, p=[p, 1-p])\n    edges_m = np.sort(edges_m)\n    \n    # Create an adjacency matrix\n    graph = np.zeros((n, n))\n    graph[edges_m[0], edges_m[1]] = 1\n    graph[edges_m[1], edges_m[0]] = 1\n    \n    return graph\n\n# Function to check if a square exists in a graph\ndef is_square(graph):\n    for i in range(graph.shape[0]):\n        for j in range(i+1, graph.shape[0]):\n            for k in range(j+1, graph.shape[0]):\n                for l in range(k+1, graph.shape[0]):\n                    if graph[i, j] and graph[j, k] and graph[k, l] and graph[l, i]:\n                        return True\n    return False\n\n# Function to calculate the time of an operation\ndef timeit(func, graph):\n    start_time = time.time()\n    func(graph)\n    return time.time() - start_time\n\n# Main function\ndef main():\n    graphs = []\n    for n in [10, 20, 30]:\n        for p in [0.5, 0.6, 0.7]:\n            graph = generate_random_graph(n, p)\n            graphs.append(graph)\n\n    for i, graph in enumerate(graphs):\n        triangles = 0\n        squares = 0\n        for j in range(graph.shape[0]):\n            for k in range(j+1, graph.shape[0]):\n                for l in range(k+1, graph.shape[0]):\n                    if graph[j, k] and graph[k, l] and graph[l, j]:\n                        triangles += 1\n                    if graph[j, k] and graph[k, l] and graph[l, j] and graph[j, i+1]:\n                        squares += 1\n\n        triangles_time = timeit(lambda g: triangles, graph)\n        squares_time = timeit(lambda g: squares, graph)\n\n        print(f\"Graph {i+1}\")\n        print(f\"Nodes: {graph.shape[0]}\")\n        print(f\"Edge density: {np.count_nonzero(graph) / (graph.shape[0] * graph.shape[0])}\")\n        print(f\"Triangles: {triangles} ({triangles_time} seconds)\")\n        print(f\"Squares: {squares if squares else 'no'} ({squares_time} seconds)\")\n        print(\"\")\n\n\nif __name__ == \"__main__\":\n    main()"}
{"index": 8949745, "Problem": "Create a function that applies simple manhattan distances between all pairs of points in a set of points. We may assume that our points are given by their numpy arrays. The input set of points is represented by a numpy array of shape (N, D), where N is the number of points and D is the dimension of each point.", "Solution": "import numpy as np\n\ndef manhattan_distances(points):\n    n = points.shape[0]\n    distances = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i+1, n):\n            result = np.sum(np.abs(points[i] - points[j]))\n            distances[i, j] = result\n            distances[j, i] = result\n    return distances\n\npoints = np.array([[1,2],[4.5,4], [3,4]])\nprint(manhattan_distances(points)) #"}
{"index": 9136349, "Problem": "The problem requires counting the numbers of elements in each row in a 2D numpy array, which can also be called as rows count in NumPy. The array will be a matrix of integers or floats, and you are allowed to create any array size and data type.\n\nThe inputs will be a two-dimensional array of floats or integers. For this example, we will use the following array:\n`[[0.5,0.5,0.5,0.5],[0.1,0.1,0.1,0.1],[0.7,0.7,0.7,0.7],[0.3,0.3,0.3,0.3]]=a`\n, and let\u2019s call it \"a\".\n\nYour solution should print the count of each row in the array, in lines such as \"row 0:5,\" \"row 1:4,\" and so on.", "Solution": "import numpy as np\n\na=np.array([[0.5,0.5,0.5,0.5],[0.1,0.1,0.1,0.1],[0.7,0.7,0.7,0.7],[0.3,0.3,0.3,0.3]])\n\nrow_length=np.apply_along_axis(np.count_nonzero,1,a)\n\nprint(\"row 0:\",row_length[0])\nprint(\"row 1:\",row_length[1])\nprint(\"row 2:\",row_length[2])\nprint(\"row 3:\",row_length[3])"}
{"index": 9765715, "Problem": "Brian has 5 boxes, each storing a different number of pencils in them. He wants to pack these boxes in a truck with the maximum number of pencils in the truck. However, there's an additional constraint: the boxes are already pairwise ordered by the number of pencils in them (meaning that if there are $x$ pencils in the first box, then there should be $y\\ge x$ pencils in the second box). Brian doesn't want to take out the pencils from the boxes and reorder them once packed. What's the maximum number of pencils that Brian can pack in the truck?\n\nLet $x_1, x_2, \\ldots, x_5$ be the number of pencils in each of the first, second, third, fourth, and fifth boxes, respectively, in non-decreasing order. Assume that each $x_i \\ge 0$ (i.e., Brian does not have any empty boxes), and we know that the total number of pencils in all the boxes is $20$. It seems logical, therefore, to choose the first 4 boxes to get the greatest number of pencils ($4$ * $5=20$). Brian has 20 pencils to pack.\n\nHere is the pencil-count information in Brian's 5 boxes:\n$x_1$: 4\n$x_2$: 5\n$x_3$: 6\n$x_4$: 4\n$x_5$: 1\n\nWe want to maximize the total number of pencils packed, not to efficiently fill boxes!\n\nGiven this information, determine how many pencils can be packed in the truck. Because the amount of information the question gives, let us use a list of Python integers to describe 5 boxes' pencils amount, the length of the list is 5, utilizing list subscript of 0.", "Solution": "import numpy as np\ndef max_pencils(lst):\n    l = np.array([(lst[i]-lst[i - 1]) if(i > 0) else lst[0] for i in range(len(lst))])\n    m = np.max(l)\n    ls = np.where(l == m)[0] + 1\n    print(\"The max pencils in-this is the result we need\",ls[0])\n\nbox_pencils=[4, 5, 6, 4, 1]\nmax_pencils(box_pencils)"}
{"index": 9932749, "Problem": "Create a custom NumPy function named blur_image() that takes a 3D NumPy array representing an image and applies a Gaussian blur effect to it. The function should return the blurred image.\n\nAssuming the size of the image is multiples of 3 (even rows, columns, and number of color channels), the function should perform the following steps:\n1. Create a kernel of size 3x3 centered around the mean, which calculates the Gaussian distribution value.\n2. Convolve the image with the kernel to blur it.\n3. Clip the pixel values in the blurred image to [0, 255] to ensure they are within the valid color range.\n\nThe function should have as input parameters:\n    - img: a 3D NumPy array (e.g., height x width x number of color channels)\n    - sigma: the standard deviation of the Gaussian distribution (a positive float)\n4. The function should not have any output parameters besides returning the blurred image.", "Solution": "import numpy as np\n\ndef blur_image(img, sigma):\n    def create_gaussian_kernel(sigma):\n        \"\"\"\n        Create a 3x3 Gaussian kernel\n        \"\"\"\n        kernel = np.zeros((3, 3))\n        gx = np.linspace(-1, 1, 3)\n        k_x, k_y = np.meshgrid(gx, gx)\n        kernel = np.exp(-(k_x**2 + k_y**2) / (2 * sigma ** 2)) / (2 * np.pi * sigma ** 2)\n        kernel = kernel / np.sum(kernel)\n        return kernel\n\n    kernel = create_gaussian_kernel(sigma)\n    # Add border to the image to handle edge cases\n    img_padded = np.pad(img, 1, mode='constant', constant_values=0)\n    blurred_img = np.zeros_like(img)\n    for i in range(1, img.shape[0] - 1):\n        for j in range(1, img.shape[1] - 1):\n            for c in range(img.shape[2]):\n                temp = 0\n                for k in range(-1, 2):\n                    for l in range(-1, 2):\n                        temp += kernel[k + 1, l + 1] * img_padded[i + k, j + l, c]\n                blurred_img[i, j, c] = temp\n\n    # Clip values to [0, 255]\n    blurred_img = np.clip(blurred_img, 0, 255).astype(np.uint8)\n    return blurred_img\n\n# Test the function\nimg = np.random.randint(0, 256, size=(10, 10, 3), dtype=np.uint8)\nblurred_img = blur_image(img, sigma=1.0)\nprint(blurred_img.shape)  # Should print (10, 10, 3)"}
{"index": 11004354, "Problem": "You are a Data Scientist working for a large retailer. One of the key metrics for assessing the performance of the store is the average transaction value (ATV). The ATV is calculated by summing up all the items in each transaction and dividing it by the number of items in that transaction. Given a list of transactions, where each transaction is represented by a list of integers representing the number of items in each category, calculate the average transaction value. Consider a scenario where a negative item count might occur due to a discount or an error in recording the transaction. Handle this scenario by assigning a placeholder value to negative item counts. \n\nTransation: [[5, -3, 2], [6, 0, 4], [12, 7, 3]], where 5, 6, and 12 are quantities of items in different categories, -3 is a discount, and 0 is an empty category. The placeholder value is None.\n\nThe input data type is list of list of integers. In case of repeated transaction, only one transaction should be considered for the calculation.", "Solution": "import numpy as np \n\ndef calculate_atv(transaction):\n    # Initialize sum of item count and count of transactions to 0\n    total_item_count = 0 \n    counttransactions = 0\n    # Iterate over valid transactions\n    for trans in transaction:\n        # Check each item in the transaction\n        for item in trans:\n            # Check if non-negative\n            if item >= 0:\n                #Add positive item count to the total\n                total_item_count += item  \n            else:\n                # Replace negative item counts with placeholder value None\n                trans[trans == item] = None  \n        #Add None items in trans together so they do not disrupe the sum of all items\n        total_item_count += np.nansum(trans)\n        # Count valid transaction if it does not contain None values\n        if not  np.isnan(trans).any():\n            counttransactions += 1\n    # Check if there are any valid transactions\n    if counttransactions > 0:\n        #Calculate average transaction value\n        avg_transaction_value = total_item_count / counttransactions\n        return avg_transaction_value\n    else:\n        return None\n\n# Given transaction data \ntransaction_data = [[5, -3, 2], [6, 0, 4], [12, 7, 3]]\n\n#Call the function to calculate ATV\natv = calculate_atv(transaction_data)\nprint(atv)"}
{"index": 11046554, "Problem": "Given two 1D arrays, `A` and `B`, where `A` represents the expected loss values and `B` represents the verified loss values. We want to compute the absolute difference between each pair of corresponding elements in `A` and `B`, and then analyze if all the differences are within a specified tolerance (or threshold) of 1e-4. If any difference exceeds this threshold, we will raise a custom error and stop the verification process. Otherwise, the verification process will issue a success message. \n\nYou will use the NumPy API to solve this problem.", "Solution": "import numpy as np\n\ndef verify_loss(A, B):\n    # Compute the absolute difference between each pair of corresponding elements in A and B\n    differences = np.abs(A - B)\n    \n    # Check if all differences are within the specified tolerance\n    if np.all(differences <= 1e-4):\n        print(\"Verification process is successful.\")\n    else:\n        raise ValueError(\"Verification failed: Absolute differences exceeded the tolerance.\")\n\n# Example usage:\nA = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\nB = np.array([0.100001, 0.200002, 0.300003, 0.400004, 0.500005])\nverify_loss(A, B)  # Output: Verification process is successful.\nA = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\nB = np.array([0.1001, 0.2002, 0.3003, 0.4004, 0.5005])\nverify_loss(A, B)  # Output: ValueError: Verification failed: Absolute differences exceeded the tolerance."}
