{"index": 1149705, "content": "            label = 'CHOL'\n        if label not in self.label_dict:\n            raise ValueError(\"Invalid label: {} entered\".format(label))\n        return self.label_dict[label]\n\n    def transform_label(self, label):\n        \"\"\"Make label correct shape\"\"\"\n        label = np.array(label).astype(np.float32).reshape(1)\n        return label\n    \n    def get_patch(self, patch_name):\n        if patch_name.split(\".\")[-1] == 'png':\n            patch = Image.open(patch_name).convert('RGB')\n        else:\n            patch = Image.open(patch_name)"}
{"index": 1895085, "content": "        out = out.to(\"cpu\")\n        return out.detach().numpy()\n\n    def test_normalize_batch(self, device):\n        # TODO(ascend): 该算子还存在泛化问题， 目前保证模型场景没问题\n        # Note: 以下为模型用例：测试通过\n        shape_format = [\n            [[np.float32, -1, [32, 64, 1688]], \n                [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n                    14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]],\n                [[6, 7, 31, 9, 10, 11, 12, 19, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, \n                    26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]], [[1], torch.float32], 2],\n            [[np.float16, -1, [32, 64, 1688]], \n                [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,\n                    14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]],"}
{"index": 3249746, "content": "\n  Returns:\n    The Hamiltonian term, separated into a 1-site contribution and a 2-site\n    MPO.\n  \"\"\"\n  U, V, _ = _weylops(q)\n\n  mp = backend.np.linalg.matrix_power\n\n  if backend.dtype_is_complex(dtype):\n    h2 = ([-J * mp(U, k) for k in range(1, q)],\n          [mp(U, q - k) for k in range(1, q)])\n  else:\n    # The straightforward way to build the Hamiltonian results in complex\n    # matrices in the MPO. The dense Hamiltonian is, however, real."}
{"index": 3319312, "content": "\n\n@register_torch_op(torch_alias=[\"bmm\"])\ndef matmul(context, node):\n    inputs = _get_inputs(context, node, expected=2)\n    if inputs[1].val is not None and \\\n            len(inputs[1].shape) == 2 and len(inputs[0].shape) <= 3:\n        res = mb.linear(x=inputs[0], weight=_np.transpose(inputs[1].val), name=node.name)\n    else:\n        res = mb.matmul(x=inputs[0], y=inputs[1], name=node.name)\n    context.add(res)\n\n@register_torch_op\ndef add(context, node):\n    add_inputs = _get_inputs(context, node)"}
{"index": 3910216, "content": "\n    σ = eos_ufunc(s, t, z_ref)\n\n    # check for each cast that\n    # potential density on surface nearly matches isovalue,\n    # or the surface does not intersect this cast (σ is nan) because of one of\n    # three conditions: the cast was land, the surface outcropped, or the surface incropped.\n    assert np.all(\n        (np.abs(σ - isoval) < 1e-8)\n        | (np.isnan(σ) & ((n_good == 0) | (isoval < σ_sfc) | (σ_bot < isoval)))\n    )\n\n\ndef test_anomaly_surf():\n    # Test delta_surf using prescribed reference values and a given cast and depth"}
{"index": 4316869, "content": "            valid_sets=[lgb_train, lgb_valid],\n            verbose_eval=10,\n            num_boost_round=20,\n            early_stopping_rounds=200,\n        )\n        model.save_model(output)\n        preds = model.predict(valid[valid.columns])\n        acc = accuracy_score(y_valid, np.where(preds >= 0.5, 1, 0))\n        auc = roc_auc_score(y_valid, preds)\n        print(f'VALID AUC : {auc} ACC : {acc}\\n')\n        result = {\"epoch\": self.args.n_epochs-1, \"train_loss\": 0, \"train_auc\": 0, \"train_acc\": 0,\n                  \"valid_auc\": auc, \"valid_acc\": acc}\n        wandb.log(result)\n\n        # ax = lgb.plot_importance(model)"}
{"index": 6223044, "content": "    frames = 0\n\n    for i, f in enumerate(elapsed_iterator(files)):\n        try:\n            reader = wave_to_numpy.reader(f)\n            nsamples, nchannels = reader.shape\n            if nchannels == 1:\n                reader = np.repeat(reader, 2, axis=1)\n            elif nchannels != 2:\n                raise ValueError\n            writer[frames : frames + nsamples] = reader\n            frames += nsamples\n            if frames != index[i]:\n                raise ValueError(f'bad frame count {frames}, {f}, {index[i]}')\n        except Exception:"}
{"index": 6456538, "content": "\t\t\t\t\t\t# ※torch.tensor のまま送るとLearner側の都合で問題があるので numpy にしている\n\t\t\t\t\t\tif wait_shared_memory_clear:\n\t\t\t\t\t\t\twhile n_step_transition_batch_size <= self.remote_mem.qsize():\n\t\t\t\t\t\t\t\ttime.sleep(0.001)\n\t\t\t\t\t\ts = s.numpy()\n\t\t\t\t\t\ta = a.numpy().astype(np.int8)\n\t\t\t\t\t\tr = r.numpy()\n\t\t\t\t\t\ta_latest = a_latest.numpy().astype(np.int8)\n\t\t\t\t\t\ts_latest = s_latest.numpy()\n\t\t\t\t\t\tterm = term.numpy().astype(np.int8)\n\t\t\t\t\t\tbatch = [v for v in zip(s, a, r, a_latest, s_latest, term)]\n\t\t\t\t\t\tself.remote_mem.put((priorities, batch))\n\n\t\t\t\t# Learner からの共有パラメータが更新されていたらロードする\n\t\t\t\tid = status_dict['Q_state_dict_id']"}
{"index": 8131034, "content": "        self.gt['rpys'] *= l\n        self.iekf['rpys'] *= l\n\n    def plot_orientation(self):\n        title = \"Orientation as function of time \" + self.end_title\n        true = self.gt['rpys']\n        mean = self.iekf['rpys']\n        std = 180/np.pi*3*self.iekf['Ps'][:, :3].sqrt()\n        fig, axs = plt.subplots(3, 1, sharex=True, figsize=self.figsize)\n        axs[0].set(ylabel='roll (deg)', title=title)\n        axs[1].set(ylabel='pitch (deg)')\n        axs[2].set(xlabel='$t$ (min)', ylabel='yaw (deg)')\n        \n        for i in range(3):\n            axs[i].plot(self.ts, true[:, i], color=\"black\")"}
{"index": 8255999, "content": "              700: [0.1, 0.2],\n              1000:[0.1, 0.2],\n              10000: [0.001, 0.003, 0.005, 0.01, 0.02]}\n\n        print()\n        print(\"Erdos-Renyi random graphs\")\n        print(\"       n        p #cliques        t1        t2\")\n        for n in sorted(np.keys()):\n            for p in np[n]:\n                g = Graph.Erdos_Renyi(n, p)\n                result = self.timeit(g)\n                print(\"%8d %8.3f %8d %8.4fs %8.4fs\" % \\\n                    tuple([n, p] + list(result)))\n\n    def testMoonMoser(self):"}
{"index": 8949745, "content": "        path = data\n        if not os.path.isfile(path):\n            if prefix is not None:\n                path = os.path.join(prefix, path)\n            if not os.path.isfile(path):\n                raise FileNotFoundError(\"File {} does not exists.\".format(data))\n        if path.endswith(\".csv\"):\n            return np.genfromtxt(path, dtype, delimiter=',')\n        elif path.endswith(\".dat\"):\n            return np.fromfile(path, dtype)\n        else:\n            raise ValueError(\"Invalid file type: \" + path)\n    elif shape is not None and len(shape) == 0:\n        return dtype(data)\n    elif isinstance(data, np.ndarray):  # embedded array: already numpy array"}
{"index": 9136349, "content": "\ndef reducemap(args, reduce_op, map_op):\n    return reduce(reduce_op, map(map_op, *args))\n\n\ndef vec_dot_vec(vec1, vec2):\n    # return np.dot(vec1, vec2)\n    # return np.add.reduce(np.multiply(vec1, vec2))\n    return reducemap((vec1, vec2), add, mul)\n\n\ndef mat_dot_vec(iter_mat, iter_vec, iter_term=None):  # pure python (slow)\n    if iter_term is None:\n        return [vec_dot_vec(row, iter_vec) for row in iter_mat]\n    else:"}
{"index": 9765715, "content": "    table = torch.from_numpy(table)\n    return table\n\ndef get_free_gpu():\n    system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free > tmp.txt')\n    memory_available = [int(x.split()[2]) for x in open('tmp.txt', 'r').readlines()]\n    remove(\"tmp.txt\")\n    free_device = 'cuda:' + str(np.argmax(memory_available))\n    return free_device\n\ndef save_args(args, full_model_name):\n    arg_path = full_model_name + '.arg.json'\n    argparse_dict = vars(args)\n    with open(arg_path, 'w') as f:\n        json.dump(argparse_dict, f)"}
{"index": 9932749, "content": "    value: [1.0, 2.0]\r\n    \"\"\"\r\n    # isinstance(value, list)\r\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\r\n\r\n\r\ndef ToFloat32ArrayFeature(value):\r\n    return _bytes_feature(value.astype(np.float32).tostring())\r\n\r\n\r\ndef ToInt32ArrayFeature(value):\r\n    return _bytes_feature(value.astype(np.int32).tostring())\r\n\r\n\r\ndef _parse_ndarray_feature(value):\r"}
{"index": 11004354, "content": "        if type(input_shape[0]) == tuple:\n            if check_model_is_cuda(model):\n                dummy_input = tuple([np.randn(ishape) for ishape in input_shape])\n            else:\n                dummy_input = tuple([np.randn(ishape) for ishape in input_shape])\n        elif type(input_shape) == tuple:\n            if check_model_is_cuda(model):\n                dummy_input = np.randn(input_shape)\n            else:\n                dummy_input = np.randn(input_shape)\n        else:\n            raise Exception(\"input_shape must be tuple\")\n        train = tf.convert_to_tensor(input_data)\n        my_ds = tf.data.Dataset.from_tensor_slices((train)).batch(10)\n        def representative_dataset_gen():"}
{"index": 11046554, "content": "results_verified = True\nfor save_file_name, expected_loss in expected_output_dictionary.items():\n    # Get the loss to veriy.\n    loss_to_verify = to_verify_output_dictionary[save_file_name]\n\n    # Convert both loss arrays to numpy 1D arrays.\n    expected_loss_np = np.ndarray.flatten(np.array(expected_loss))\n    to_verify_np = np.ndarray.flatten(np.array(loss_to_verify))\n\n    # Compute relative error.\n    relative_error = np.abs(to_verify_np - expected_loss_np)/expected_loss_np\n\n    # Make sure all errors are low enough.\n    for i, curr_error in enumerate(list(relative_error)):\n        if curr_error > 1e-4:"}
