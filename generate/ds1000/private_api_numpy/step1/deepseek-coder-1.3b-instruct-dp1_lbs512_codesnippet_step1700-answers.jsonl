{"id": 0, "code": "result = df.loc[List]", "metadata": {"problem_id": 0, "library_problem_id": 0, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 1, "code": "result = df.loc[List]", "metadata": {"problem_id": 1, "library_problem_id": 1, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 0}}
{"id": 2, "code": "df[df.columns[0]].apply(lambda x: x >= 2, axis=1)\n", "metadata": {"problem_id": 2, "library_problem_id": 2, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 2}}
{"id": 3, "code": "df['Qu1'] = df['Qu1'].apply(lambda x: 'other' if x in ['apple', 'potato', 'cheese'] else x)\ndf['Qu2'] = df['Qu2'].apply(lambda x: 'other' if x in ['banana', 'apple', 'sausage'] else x)\ndf['Qu3'] = df['Qu3'].apply(lambda x: 'other' if x in ['cheese', 'potato'] else x)\n", "metadata": {"problem_id": 3, "library_problem_id": 3, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 2}}
{"id": 4, "code": "\n    df['Qu1'] = df['Qu1'].apply(lambda x: x if x in df['Qu1'].value_counts() >= 2 else 'other')\n    return df\n\nresult = f(example_df)\nresult\n", "metadata": {"problem_id": 4, "library_problem_id": 4, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 2}}
{"id": 5, "code": "df['Qu1'] = df['Qu1'].apply(lambda x: 'other' if x in ['apple', 'potato', 'cheese'] else 'cheese')\ndf['Qu2'] = df['Qu2'].apply(lambda x: 'other' if x in ['banana', 'apple', 'sausage'] else 'sausage')\ndf['Qu3'] = df['Qu3'].apply(lambda x: 'other' if x in ['apple', 'potato', 'cheese'] else 'cheese')\n", "metadata": {"problem_id": 5, "library_problem_id": 5, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 2}}
{"id": 6, "code": "df['Qu1'] = df['Qu1'].apply(lambda x: 'other' if x in ['apple', 'potato', 'cheese'] else x)\ndf['Qu2'] = df['Qu2'].apply(lambda x: 'other' if x in ['banana', 'apple'] else x)\ndf['Qu3'] = df['Qu3'].apply(lambda x: 'other' if x in ['apple', 'potato'] else x)\n", "metadata": {"problem_id": 6, "library_problem_id": 6, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 2}}
{"id": 7, "code": "df = df.drop_duplicates(subset='url', keep='first')", "metadata": {"problem_id": 7, "library_problem_id": 7, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 7}}
{"id": 8, "code": "df = df.drop_if_dup_1 = df.drop_if_dup.first_valid_index()\n", "metadata": {"problem_id": 8, "library_problem_id": 8, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 7}}
{"id": 9, "code": "df = df.drop_duplicates(subset='url', keep='last')", "metadata": {"problem_id": 9, "library_problem_id": 9, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 7}}
{"id": 10, "code": "df.groupby('name')['v1','v2','v3'].apply(lambda x: {k:{y:z for y,z in zip(x.index.values[1:] , x.values[1:])} for k,x in zip(df.groupby('name')['v1','v2','v3'])}", "metadata": {"problem_id": 10, "library_problem_id": 10, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 10}}
{"id": 11, "code": "df['datetime'] = df['datetime'].dt.tz_localize(None)\n", "metadata": {"problem_id": 11, "library_problem_id": 11, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 11}}
{"id": 12, "code": "\n    df['datetime'] = df['datetime'].dt.tz_localize(None)\n    ### END SOLUTION\n    return df\n\nprint(f(example_df).dtypes)\n", "metadata": {"problem_id": 12, "library_problem_id": 12, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 11}}
{"id": 13, "code": "df['datetime'] = df['datetime'].dt.tz_localize(None)\ndf['datetime'] = df['datetime'].dt.strftime('%d-%b-%Y %H:%M:%S')\n", "metadata": {"problem_id": 13, "library_problem_id": 13, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 11}}
{"id": 14, "code": "df['datetime'] = df['datetime'].dt.tz_localize(None)\ndf = df.reset_index()\ndf['datetime'] = df['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n", "metadata": {"problem_id": 14, "library_problem_id": 14, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 11}}
{"id": 15, "code": "import ast\n\ndf['expanded'] = df['message'].apply(lambda x: ast.literal(x))\nresult = df.drop(['message'], axis=1).reset_index(drop=True)\n", "metadata": {"problem_id": 15, "library_problem_id": 15, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 15}}
{"id": 16, "code": "df['score'] = df.index.isin(products).mul(df['score'], 10)\n", "metadata": {"problem_id": 16, "library_problem_id": 16, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 17, "code": "df['score'] = df['score'].multiply(10)", "metadata": {"problem_id": 17, "library_problem_id": 17, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 16}}
{"id": 18, "code": "df['score'] = df.score.mul(10)\n", "metadata": {"problem_id": 18, "library_problem_id": 18, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 16}}
{"id": 19, "code": "df_norm = pd.DataFrame()\nfor product in products:\n    df_norm = df_norm.append(pd.DataFrame({'product': [product], \n                                          'score': [(df.loc[df['product'] == product, 'score'].values[0])[0]/(df.loc[df['product'] == product, 'score'].values.max()-df.loc[df['product'] == product, 'score'].values.min(), 'score').values[0]])))\n", "metadata": {"problem_id": 19, "library_problem_id": 19, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 16}}
{"id": 20, "code": "df1 = pd.DataFrame(df, columns=['A', 'B', 'C', 'D'])\ndf1", "metadata": {"problem_id": 20, "library_problem_id": 20, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 20}}
{"id": 21, "code": "df1 = pd.get_dummies(df, columns=['A', 'B', 'C', 'D'])", "metadata": {"problem_id": 21, "library_problem_id": 21, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 20}}
{"id": 22, "code": "df['category'] = df.columns.values.tolist()\n", "metadata": {"problem_id": 22, "library_problem_id": 22, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 20}}
{"id": 23, "code": "df['Date'].dt.to_period(\"M/YYYY\").strftime(\"%M-%Y\")\n", "metadata": {"problem_id": 23, "library_problem_id": 23, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 23}}
{"id": 24, "code": "df['Date'].dt.to_period(\"M\").strftime('%d-%b-%Y')", "metadata": {"problem_id": 24, "library_problem_id": 24, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 23}}
{"id": 25, "code": "df['Date'].dt.to_period(\"M\").strftime('%d-%b-%Y %a')", "metadata": {"problem_id": 25, "library_problem_id": 25, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 23}}
{"id": 26, "code": "df.shift(1, axis=1)[1:]", "metadata": {"problem_id": 26, "library_problem_id": 26, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 26}}
{"id": 27, "code": "df.shift(1, axis=1)\n", "metadata": {"problem_id": 27, "library_problem_id": 27, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 26}}
{"id": 28, "code": "df.shift(1, axis=1)\n", "metadata": {"problem_id": 28, "library_problem_id": 28, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 26}}
{"id": 29, "code": "df = df.shift(1, fill_value=0).fillna(0)[:-1].reset_index()\n", "metadata": {"problem_id": 29, "library_problem_id": 29, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 26}}
{"id": 30, "code": "df.columns = [col + 'X' for col in df.columns]", "metadata": {"problem_id": 30, "library_problem_id": 30, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 30}}
{"id": 31, "code": "df.columns = ['XHeaderA', 'XHeaderB', 'XHeaderC']", "metadata": {"problem_id": 31, "library_problem_id": 31, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 30}}
{"id": 32, "code": "df.rename(columns={'HeaderA': 'HeaderAX',\n                   'HeaderB': 'HeaderBX',\n                   'HeaderC': 'HeaderCX',\n                   'HeaderX': 'HeaderX'}, \n            inplace=True)\n", "metadata": {"problem_id": 32, "library_problem_id": 32, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 30}}
{"id": 33, "code": "df.groupby('group').agg({\"group_color\": \"first\", **{\"val1\": \"mean\", \"val2\": \"mean\", \"val3\": \"mean\"}})", "metadata": {"problem_id": 33, "library_problem_id": 33, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 33}}
{"id": 34, "code": "df.groupby('group').agg({\"group_color\": \"first\", **{\"val1\": \"sum\", \"val2\": \"sum\", \"val3\": \"sum\"}})", "metadata": {"problem_id": 34, "library_problem_id": 34, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 33}}
{"id": 35, "code": "df.groupby('group').apply(lambda x: pd.Series({'val1': x.val1.mean(), 'val2': x.val2.mean(), 'val3': x.val3.mean(), 'val4': x.val4.mean()}))", "metadata": {"problem_id": 35, "library_problem_id": 35, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 33}}
{"id": 36, "code": "result = df.loc[row_list,column_list].mean().mean()", "metadata": {"problem_id": 36, "library_problem_id": 36, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 37, "code": "result = (df.loc[row_list,column_list].sum()).sum()", "metadata": {"problem_id": 37, "library_problem_id": 37, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 36}}
{"id": 38, "code": "df_sum = df.sum().add(1, axis=0)\ndf_sum.loc[row_list, column_list] = 0\nresult = df_sum\nresult\nEND SOLUTION\n", "metadata": {"problem_id": 38, "library_problem_id": 38, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 36}}
{"id": 39, "code": "df.dropna().set_index(axis=1, drop=True).drop(columns=['temp', 'name']).fillna(0).sum().sort_values(ascending=False)", "metadata": {"problem_id": 39, "library_problem_id": 39, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 39}}
{"id": 40, "code": "df.isnull().sum().rename(columns={'True': 'NaN'})\n", "metadata": {"problem_id": 40, "library_problem_id": 40, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 39}}
{"id": 41, "code": "df.info()\n", "metadata": {"problem_id": 41, "library_problem_id": 41, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 39}}
{"id": 42, "code": "result = df.loc[1].rename(index=[0])\n", "metadata": {"problem_id": 42, "library_problem_id": 42, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 42}}
{"id": 43, "code": "result = df.iloc[1].rename(index=[0]).to_frame_name('Nanonose')\n", "metadata": {"problem_id": 43, "library_problem_id": 43, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 44, "code": "df.dropna(inplace=True)\nresult = df\nresult.fillna(value={'0':0,'1':1,'2':2},inplace=True)\n", "metadata": {"problem_id": 44, "library_problem_id": 44, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 44}}
{"id": 45, "code": "df.apply(lambda x : x.fillna(x.mean()) if x.isnull().sum()>0 else x,axis=0)\n", "metadata": {"problem_id": 45, "library_problem_id": 45, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 44}}
{"id": 46, "code": "df.dropna(inplace=True)\ndf.reset_index(drop=True, inplace=True)\n", "metadata": {"problem_id": 46, "library_problem_id": 46, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 44}}
{"id": 47, "code": "df[df['value'] < thresh] = df[df['value'] < thresh].sum()\nresult = df\n", "metadata": {"problem_id": 47, "library_problem_id": 47, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 47}}
{"id": 48, "code": "df[df['value'] > thresh] = 31\nresult = df[df['value'] > thresh].groupby(df['value']).mean().fillna(df.mean().values[0]).dropna()\n", "metadata": {"problem_id": 48, "library_problem_id": 48, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 47}}
{"id": 49, "code": "df_left = df[section_left:]\ndf_right = df[section_right:]\naverage_left = df_left['value'].mean()\naverage_right = df_right['value'].mean()\nresult = df_right.copy()\nresult['value'] = average_left\nresult.name = section_right\n", "metadata": {"problem_id": 49, "library_problem_id": 49, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 47}}
{"id": 50, "code": "df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\ndf[[\"inv_A\", \"inv_B\"]] = df[[\"A\", \"B\"]]/df[[\"A\", \"B\"]].values\n", "metadata": {"problem_id": 50, "library_problem_id": 50, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 50}}
{"id": 51, "code": "import numpy as np\n\ndf = pd.DataFrame()\n\nfor col in df.columns:\n    df[f\"exp_{col}\"] = np.exp(df[col])\n\nresult = df\nEND SOLUTION\n", "metadata": {"problem_id": 51, "library_problem_id": 51, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 50}}
{"id": 52, "code": "df = pd.DataFrame({\"A\": [1, 0, 3], \"B\": [4, 5, 6]})\ndf[\"inv_A\"] = df[\"A\"].map(-1) * df[\"B\"]\ndf[\"inv_B\"] = df[\"B\"].map(-1) * df[\"A\"]\n", "metadata": {"problem_id": 52, "library_problem_id": 52, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 50}}
{"id": 53, "code": "import numpy as np\n\ndef sigmoid(x):\n    return 1/(1+np.exp(-x))\n\ndf_cols = df.columns[1:]\n\nfor col in df_cols:\n    df[f'sigmoid_{col}'] = list(map(sigmoid, df[col].values))\n\nresult = df\n", "metadata": {"problem_id": 53, "library_problem_id": 53, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 50}}
{"id": 54, "code": "df.loc[df.idxmin().values[-1]]", "metadata": {"problem_id": 54, "library_problem_id": 54, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 55, "code": "df.loc[df.idxmin().values[0]]", "metadata": {"problem_id": 55, "library_problem_id": 55, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 56, "code": "df.set_index('dt').min().rename(columns={'val':'val_min'}).reset_index(drop=True).rename(index={0: '0'}).reset_index(drop=True)\n", "metadata": {"problem_id": 56, "library_problem_id": 56, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 56}}
{"id": 57, "code": "df.set_index('dt').min().rename(columns={'val':'val_min'}).reset_index(drop=True).rename(columns={'val':'val'}).reset_index(drop=True, drop=True)\n", "metadata": {"problem_id": 57, "library_problem_id": 57, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 56}}
{"id": 58, "code": "df['dt'] = pd.to_datetime(df['dt'])\nmin_date = df['dt'].dt.min().strftime('%Y-%m-%d')\nmax_date = df['dt'].dt.max().strftime('%Y-%m-%d')\n\nfor user in df['user'].unique():\n    temp_df = df.loc[df['user'] == user, 'val'].reset_index(drop=True)\n    temp_df.columns = [f'val_{i+1}']\n    temp_df.rename('val', inplace=True)\n    temp_df.columns = [f'val_{i+1}']\n    temp_df.rename(user, inplace=True)\n    temp_df.columns = [user]\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.rename(user, inplace=True)\n    temp_df.", "metadata": {"problem_id": 58, "library_problem_id": 58, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 56}}
{"id": 59, "code": "df = df.groupby(['user','dt']).min().rename(columns={'val':'val_min'})\ndf['val'] = df.groupby(['user','dt']).min().rename(columns={'val':'val_min'})\n", "metadata": {"problem_id": 59, "library_problem_id": 59, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 56}}
{"id": 60, "code": "df.sort_values('dt').groupby('user').apply(lambda gr: gr.val.idxmin() if len(gr) > 1 else gr.val).reset_index(drop=True).rename(columns={'dt':'dt_min', 'val':'val_min'}).reset_index(drop=True).rename(columns={'dt_min':'dt', 'val_min':'val'})\n", "metadata": {"problem_id": 60, "library_problem_id": 60, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 56}}
{"id": 61, "code": "df['id'] = df.index + 1\nresult = df.reset_index()\nresult.columns = ['id', 'name', 'a', 'b', 'c']\n", "metadata": {"problem_id": 61, "library_problem_id": 61, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 61}}
{"id": 62, "code": "df['a'] = df['a'].map(lambda x: x+1)\nresult = df\n", "metadata": {"problem_id": 62, "library_problem_id": 62, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 61}}
{"id": 63, "code": "\n    df['id'] = df.groupby('name').apply(lambda x: x.mean().idxmin()).reset_index().values.flatten()+1\n    return df\n\nresult = f(example_df)\nprint(result)\n", "metadata": {"problem_id": 63, "library_problem_id": 63, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 61}}
{"id": 64, "code": "df['ID'] = df.groupby('name').apply(lambda x: x.iloc[1:]).apply(lambda y: pd.Series(y.sum().reset_index().values.reshape(-1,2)[:-1], index=pd.MultiIndex(names=['ID','b','c']))).reset_index().rename(columns={'name':'ID'})\n", "metadata": {"problem_id": 64, "library_problem_id": 64, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 61}}
{"id": 65, "code": "df = pd.concat([df['01/12/15'].rename('value'), df['someBool'].rename('someBool')],axis=1).rename({'value':'01/12/15','someBool':'02/12/15'})", "metadata": {"problem_id": 65, "library_problem_id": 65, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 65}}
{"id": 66, "code": "df1 = df.melt(id_vars=['user', 'someBool'], \n             value_vars=['01/12/15', '02/12/15'], \n             var_names=['others'])\ndf1.columns = ['user', 'someBool', 'others', 'value']\n", "metadata": {"problem_id": 66, "library_problem_id": 66, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 65}}
{"id": 67, "code": "df = pd.pivot_table(df, values='value', \n                    index=['user', 'date'], \n                    columns=['date'], \n                    aggfunc='first')\n", "metadata": {"problem_id": 67, "library_problem_id": 67, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 65}}
{"id": 68, "code": "df[df.c > 0.5][columns]", "metadata": {"problem_id": 68, "library_problem_id": 68, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 68}}
{"id": 69, "code": "df[df.c > 0.45][columns]", "metadata": {"problem_id": 69, "library_problem_id": 69, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 68}}
{"id": 70, "code": "\n    df[df[columns].index[0] & df[columns].index[1]].min() > 0.5\n    ### END SOLUTION\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "metadata": {"problem_id": 70, "library_problem_id": 70, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 71, "code": "\n    df[df.c > 0.5][columns]\n    ### END SOLUTION\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "metadata": {"problem_id": 71, "library_problem_id": 71, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 72, "code": "\n    return df.loc[df[columns].idxmax().intersect(df.columns).intersect(columns).values]\n", "metadata": {"problem_id": 72, "library_problem_id": 72, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 73, "code": "df['date'] = pd.to_datetime(df['date'])\ndf.sort_values('date', inplace=True)\n\n# Create a list to hold overlapping dates\noverlaps = []\n\nfor i, row in df.iterrows():\n    if i not in overlaps:\n        overlaps.append(i)\n\ndf = df[~df.index.intersect(overlaps).dropna()]\n", "metadata": {"problem_id": 73, "library_problem_id": 73, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 73}}
{"id": 74, "code": "df['date'] = pd.to_datetime(df['date'])\ndf.sort_values('date', inplace=True)\n\n# Adding a new column 'week' to identify the week number\ndf['week'] = df['date'].dt.week\n\n# Filtering out the rows that have the same week number with the current row\ndf = df[df['week'] != df['week'].max() - X].reset_index(drop=True)\n", "metadata": {"problem_id": 74, "library_problem_id": 74, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 73}}
{"id": 75, "code": "df['date'] = pd.to_datetime(df['date'])\ndf.sort_values('date', inplace=True)\ndf.drop_duplicates(subset='ID', keep='first', ignore_index=True, \n                   get_unique_ids=True, in_index=False).sort_index(ascending=False).reset_index(drop=True)\n\nresult = df[df['date'].dt.shift(X).isnull()]\nresult.reset_index(drop=True, inplace=True)\n", "metadata": {"problem_id": 75, "library_problem_id": 75, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 73}}
{"id": 76, "code": "df['col1'] = df['col1'].rolling(window=3).mean().round(1)", "metadata": {"problem_id": 76, "library_problem_id": 76, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 76}}
{"id": 77, "code": "df['col1'] = df.groupby(df.index // 3).count()", "metadata": {"problem_id": 77, "library_problem_id": 77, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 76}}
{"id": 78, "code": "df['col1'] = df['col1'].groupby(pd.Grouper(key=lambda x: x//4, size=4))['col1'].apply(lambda x: x.sum())", "metadata": {"problem_id": 78, "library_problem_id": 78, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 76}}
{"id": 79, "code": "df['col1'] = df['col1'].rolling(window=3).mean().round(1)", "metadata": {"problem_id": 79, "library_problem_id": 79, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 76}}
{"id": 80, "code": "df2 = df.groupby(range(1,4))['col1'].agg(['sum', 'mean'])\nresult = df2.rename(columns={'col1-sum':'col1'})\n", "metadata": {"problem_id": 80, "library_problem_id": 80, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 76}}
{"id": 81, "code": "df['col1'] = df.groupby(range(3, 5))['col1'].transform('sum')\nresult = df.groupby(range(2, 4))['col1'].mean()\n", "metadata": {"problem_id": 81, "library_problem_id": 81, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 76}}
{"id": 82, "code": "df['A'] = df['A'].fillna(method='ffill')", "metadata": {"problem_id": 82, "library_problem_id": 82, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 82}}
{"id": 83, "code": "df['A'].fillna(method='ffill', inplace=True)\n", "metadata": {"problem_id": 83, "library_problem_id": 83, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 82}}
{"id": 84, "code": "df['A'].fillna(df['A'].expanding.max().shift(1).dropna(), inplace=True)\n", "metadata": {"problem_id": 84, "library_problem_id": 84, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 82}}
{"id": 85, "code": "df['time'] = df.duration.str.extract('(\\d+)\\s(\\w+)', expand=True)\ndf['number'] = df.duration.str.extract('(\\d+)', expand=True)\ndf['time_days'] = df.duration.str.extract('(\\d+)', expand=True)\ndf", "metadata": {"problem_id": 85, "library_problem_id": 85, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 86, "code": "df['time'] = df.duration.str.extract('(\\w+)\\s\\d',expand=True).astype(int)\ndf['time'] = df.duration.str.extract('(\\w+)\\s(\\d)',expand=True).astype(int)\ndf['time'] = df.duration.str.extract('(\\d.\\d.\\d)\\d',expand=True).astype(int)\ndf['time'] = df.duration.str.extract('(\\d.\\d.\\d.\\d)\\d',expand=True).astype(int)\ndf['time'] = df.duration.str.extract('(\\d.\\d.\\d.\\d.\\d)\\d',expand=True).astype(int)\nEND SOLUTION\n", "metadata": {"problem_id": 86, "library_problem_id": 86, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 85}}
{"id": 87, "code": "\n    df['time'] = df.duration.str.split(' ').str[1]\n    df['number'] = df.duration.str.split(' ').str[2]\n    df.drop(['duration'], axis=1, inplace=True)\n    df.columns = ['index', 'duration', 'number']\n    df['time_days'] = df.duration.str.split(' ').str[1]\n    df['time'] = df.duration.str.split(' ').str[1]\n    df['time'] = df.time.replace(r'(year|month|week|day)', r'(365|30|7|1)', regex=True, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis=1, inplace=True)\n    df.drop(['duration'], axis", "metadata": {"problem_id": 87, "library_problem_id": 87, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 85}}
{"id": 88, "code": "df['time'] = df['duration'].str.split(' ').str[1]\ndf['number'] = df['duration'].str.split(' ').str[2]\ndf['time'] = df['time'].str.extract('(\\d+)', expand=False).astype(int)\ndf['number'] = df['number'].str.extract('(\\d+)', expand=False).astype(int)\ndf['time_day'] = df['time'].astype(int) * df['number']\n", "metadata": {"problem_id": 88, "library_problem_id": 88, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 85}}
{"id": 89, "code": "result = pd.DataFrame(columns_check_list, index=df1.columns, dtype='bool').values\nresult", "metadata": {"problem_id": 89, "library_problem_id": 89, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 89}}
{"id": 90, "code": "result = pd.DataFrame(columns_check_list.values(), index=[df1[column].equals(df2[column]) for column in columns_check_list], columns=['Postset'])", "metadata": {"problem_id": 90, "library_problem_id": 90, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 89}}
{"id": 91, "code": "df.index = df.index.map(lambda x: x[1].strftime('%m/%d/%Y'))\n", "metadata": {"problem_id": 91, "library_problem_id": 91, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 91}}
{"id": 92, "code": "df.index = df.index.map(lambda x: x[1])\n", "metadata": {"problem_id": 92, "library_problem_id": 92, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 91}}
{"id": 93, "code": "\n    df['date'] = pdatar.to_datetime(df['date'])\n    df.set_index('date')\n    df = df[['x','y']]\n    df.columns = ['date','price']\n    df.reset_index()\n    return df\n", "metadata": {"problem_id": 93, "library_problem_id": 93, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 91}}
{"id": 94, "code": "\n    df['date'] = pdatar.to_datetime(df['date'])\n    df = df.sort_values('date')\n    return df\n", "metadata": {"problem_id": 94, "library_problem_id": 94, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 91}}
{"id": 95, "code": "df1 = df.melt(id_vars=['Country', 'Variable'], \n             value_name='Value', \n             var_name='year')\n", "metadata": {"problem_id": 95, "library_problem_id": 95, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 95}}
{"id": 96, "code": "df1 = df.melt(id_max=False, value_name='Value')\ndf1.columns = ['Country', 'Variable', 'year']\ndf1 = df1.sort_values(['Country', 'year', 'Variable']).reset_index(drop=True)\n", "metadata": {"problem_id": 96, "library_problem_id": 96, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 95}}
{"id": 97, "code": "df = df[(df['Value_B'].abs() < 1) & (df['Value_C'].abs() < 1) & (df['Value_D'].abs() < 1) & (df['Value_E'].abs() < 1) & (df['Value_F'].abs() < 1) & (df['Value_G'].abs() < 1) & (df['Value_H'].abs() < 1)]", "metadata": {"problem_id": 97, "library_problem_id": 97, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 97}}
{"id": 98, "code": "df = df[(abs(df['Value_B']) > 1) | (abs(df['Value_C']) > 1) | (abs(df['Value_D']) > 1) | (abs(df['Value_E']) > 1) | (abs(df['Value_F']) > 1) | (abs(df['Value_G']) > 1) | (abs(df['Value_H']) > 1) | (abs(df['Value_I']) > 1) | (abs(df['Value_J']) > 1) | (abs(df['Value_K']) > 1)", "metadata": {"problem_id": 98, "library_problem_id": 98, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 97}}
{"id": 99, "code": "df = df[(abs(df['Value_B']) > 1) & (abs(df['Value_C']) > 1) & (abs(df['Value_D']) > 1) & (abs(df['Value_E']) > 1) & (abs(df['Value_F']) > 1) & (abs(df['Value_G']) > 1) & (abs(df['Value_H']) > 1) & (abs(df['Value_I']) > 1) & (abs(df['Value_J']) > 1) & (abs(df['Value_K']) > 1)", "metadata": {"problem_id": 99, "library_problem_id": 99, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 97}}
{"id": 100, "code": "df['A'] = df['A'].str.replace('&AMP;', '&')\n", "metadata": {"problem_id": 100, "library_problem_id": 100, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 100}}
{"id": 101, "code": "df['A'].replace_with = lambda $column: $column.replace('&LT', '<', case=False)\n", "metadata": {"problem_id": 101, "library_problem_id": 101, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 100}}
{"id": 102, "code": "\n    df.replace(to_replace, values, inplace=True, regex=True)\n    ### END SOLUTION\n\nf(example_df)\n", "metadata": {"problem_id": 102, "library_problem_id": 102, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 100}}
{"id": 103, "code": "df['A'].replace_({'&AMP;': ' & ', '&LT;': ' < ', '&GT;': ' > '), inplace=True)\n", "metadata": {"problem_id": 103, "library_problem_id": 103, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 100}}
{"id": 104, "code": "df['A'].replaceAll('&AMP;', '&', inplace=True)\n", "metadata": {"problem_id": 104, "library_problem_id": 104, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 100}}
{"id": 105, "code": "import re\n\ndef validate_single_space_name(name: str) -> str:\n    pattern = re.compile(r'([a-zA-Z]+)\\s([a-zA-Z]+)')\n    match_obj = re.match(pattern, name)\n    if match_obj:\n        return match_obj[1]\n    else:\n        return None\n\ndf['first_name'] = df['name'].apply(validate_single_space_name)\n", "metadata": {"problem_id": 105, "library_problem_id": 105, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 105}}
{"id": 106, "code": "import re\n\ndef validate_single_space_name(name: str) -> str:\n    pattern = re.compile(r'([a-zA-Z]+)\\s([a-zA-Z]+)')\n    match_obj = re.match(pattern, name)\n    if match_obj:\n        return match_obj[1]\n    else:\n        return None\n\ndf['1_name'] = df['name'].apply(validate_single_space_name)\n", "metadata": {"problem_id": 106, "library_problem_id": 106, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 105}}
{"id": 107, "code": "import re\n\ndef split_name(name):\n    return {'first_name': name.split()[0], 'middle_name': name.split()[1] if len(name.split()) > 2 else None, 'last_name': name.split()[2] if len(name.split()) > 3 else None}\n\ndf = pd.DataFrame(data=[split_name(name) for name in df['name']])\n", "metadata": {"problem_id": 107, "library_problem_id": 107, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 105}}
{"id": 108, "code": "result = pd.merge(df1, df2, on='Timestamp', how='left', indicator='stuff')\nresult.drop(['Timestamp_x', 'Timestamp_y'], axis=1, inplace=True)\nresult.columns = ['Timestamp', 'data_x', 'data_y']\n", "metadata": {"problem_id": 108, "library_problem_id": 108, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 108}}
{"id": 109, "code": "result = pd.merge(df1, df2, on='Timestamp', how='left', suffixes=('_df1', '_df2'))\n", "metadata": {"problem_id": 109, "library_problem_id": 109, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 108}}
{"id": 110, "code": "df['state'] = df.apply(lambda row: row['col1'] if row['col2'] + row['col3'] < 50 else max([row['col1'], row['col2'], row['col3']]), axis=1)\n", "metadata": {"problem_id": 110, "library_problem_id": 110, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 110}}
{"id": 111, "code": "df['state'] = df.apply(lambda row: row['col1'] if row['col2'] > 50 and row['col3'] > 50 else sum([row['col1'],row['col2'],row['col3']], name='state'), axis=1)\n", "metadata": {"problem_id": 111, "library_problem_id": 111, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 110}}
{"id": 112, "code": "df['is_integer'] = df['Field1'].apply(lambda x: x.isnumeric())\ndf['is_integer'] = df['is_integer'].map({True: 'Integer', False: 'Not Integer'})\n", "metadata": {"problem_id": 112, "library_problem_id": 112, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 112}}
{"id": 113, "code": "df['Field1'] = df['Field1'].astype('str').astype('int')\n", "metadata": {"problem_id": 113, "library_problem_id": 113, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 112}}
{"id": 114, "code": "\n    df['is_integer'] = df['Field1'].apply(lambda x: x.isnumeric())\n    result = df[df['is_integer']==False]['Field1'].values\n    return result\n\nprint(f(example_df))\n", "metadata": {"problem_id": 114, "library_problem_id": 114, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 112}}
{"id": 115, "code": "df['val1'] = df['val1'] / df['val1'].sum()\ndf['val2'] = df['val2'] / df['val2'].sum()\ndf['val3'] = df['val3'] / df['val3'].sum()\ndf['val4'] = df['val4'] / df['val4'].sum()\n", "metadata": {"problem_id": 115, "library_problem_id": 115, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 115}}
{"id": 116, "code": "df['val1_percentage'] = df['val1'] / df['val1'].sum()\ndf['val2_percentage'] = df['val2'] / df['val2'].sum()\ndf['val3_percentage'] = df['val3'] / df['val3'].sum()\ndf['val4_percentage'] = df['val4'] / df['val4'].sum()\n", "metadata": {"problem_id": 116, "library_problem_id": 116, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 115}}
{"id": 117, "code": "result = df.loc[test]", "metadata": {"problem_id": 117, "library_problem_id": 117, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 117}}
{"id": 118, "code": "result = df.loc[test]", "metadata": {"problem_id": 118, "library_problem_id": 118, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 117}}
{"id": 119, "code": "df = df.drop(test)\n", "metadata": {"problem_id": 119, "library_problem_id": 119, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 117}}
{"id": 120, "code": "\n    df[test]\n    ### END SOLUTION\n\ntest = ['TP3','TP12','TP18', 'TP3']\ndf = pdatar.DataFrame({'alleles': ['A/C', 'A/T', 'C/A', 'C/T'] ,'chrom': [0, 0, 0, 0] ,'pos': [3, 7, 12, 18] ,'strand': ['+', '+', '+', '+'] ,'assembly#': [NaN, NaN, NaN, NaN] ,'center': [NaN, NaN, NaN, NaN] ,'protLSID': [NaN, NaN, NaN, NaN] ,'assayLSID': [NaN, NaN, NaN, NaN]})\n\ndf = pd.DataFrame({'alleles': ['A/C', 'A/T', 'C/A', 'C/T'] ,'chrom': [0, 0, 0, 0] ,'pos': [3, 7, 12, 18] ,'strand': ['+', '+', '+', '+'] ,'assembly#': [NaN, NaN, NaN, NaN] ,'center': [NaN, NaN, NaN, NaN] ,'protLSID': [NaN, NaN, NaN, NaN] ,'assayLSID': [NaN, NaN, NaN, NaN]})\n\ndf = pd.DataFrame({'alleles': ['A/C', 'A/T', 'C/A', 'C/T'] ,'chrom': [0, 0, 0, 0] ,'pos': [3, 7, 12, 18] ,'strand': ['+', '+', '+', '+'] ,'assembly#': [NaN, NaN, NaN, NaN] ,'center': [NaN, NaN, NaN, NaN] ,'protLSID': [NaN, NaN, NaN, NaN] ,'assayLSID': [NaN, NaN, NaN, NaN]})\n\ndf = pd.DataFrame({'alleles': ['A/C', 'A/T', 'C/A', 'C/T'] ,'chrom': [0, 0, 0, 0] ,'pos': [3, 7, 12, 18] ,'strand': ['+', '+', '+', '+'] ,'assembly#': [NaN, NaN, NaN, NaN] ,'center': [NaN, NaN, NaN, NaN] ,'protLSID': [NaN, NaN, NaN, NaN] ,'assayLSID': [NaS, NaN, NaN, NaN]})\n\ndf = pd.DataFrame({'alleles': ['A/C', 'A/T', 'C/A', 'C/T'] ,'chrom': [0, 0, 0, 0] ,'pos': [3, 7, 12, 18] ,'strand': ['+', '+', '+', '+'] ,'assembly#': [NaN, NaN, NaN, NaN] ,'center': [NaN, NaN, NaN, NaN] ,'protLSID': [NaN, NaN, NaN, NaN] ,'assayLSID': [NaN, NaN, NaN, NaN]})\n\ndf = pd.DataFrame({'alleles': ['A/C', 'A/T', 'C/A', 'C/T'] ,'chrom': [0, 0, 0, 0] ,'pos': [3, 7, 12, 18] ,'strand': ['+', '+', '+', '+'] ,'assembly#': [NaN, NaN, NaN, NaN] ,'center': [NaN, NaN, NaN, NaN] ,'protLSID': [NaN, NaN, NaN, NaN] ,'assayLSID': [NaN, NaN, NaN, NaN]})\n\ndf = pd.DataFrame({'alleles': ['A/C', 'A/T", "metadata": {"problem_id": 120, "library_problem_id": 120, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 117}}
{"id": 121, "code": "df2 = ... # put solution in this variable\n", "metadata": {"problem_id": 121, "library_problem_id": 121, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 121}}
{"id": 122, "code": "df['distance'] = np.sqrt(np.power(df['x'], 2) + np.power(df['y'], 2))\ndf['farmost_neighbour'] = df['car'].replace(df['car'].value_counts().index[0], 'nan').append(df['car'].replace(df['car'].value_counts().index[1], 'nan'))\ndf['farmost_neighbour'] = df['farmost_neighbour'].fillna('')\ndf['farmost_neighbour'] = df['farmost_neighbour'].astype('int')\ndf['farmost_neighbour'] = df['farmost_neighbour'].astype('float')\ndf['farmost_neighbour'] = df['farmost_neighbour'].astype('float')\ndf['distance'].groupby(df['time']).mean()\n", "metadata": {"problem_id": 122, "library_problem_id": 122, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 123, "code": "cols = ['keywords_0', 'keywords_1', 'keywords_2', 'keywords_3']\ndf['keywords_all'] = df[cols].apply(lambda cols: \",\".join(cols), axis=1)\n", "metadata": {"problem_id": 123, "library_problem_id": 123, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 123}}
{"id": 124, "code": "cols = ['keywords_0', 'keywords_1', 'keywords_2', 'keywords_3']\ndf['keywords_all'] = df[cols].apply(lambda row: '-'.join(row.dropna().values[0]), axis=1)\n", "metadata": {"problem_id": 124, "library_problem_id": 124, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 123}}
{"id": 125, "code": "cols = ['keywords_0', 'keywords_1', 'keywords_2', 'keywords_3']\ndf['keywords_all'] = df[cols].apply(lambda cols: '-'.join(cols), axis=1)\n", "metadata": {"problem_id": 125, "library_problem_id": 125, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 123}}
{"id": 126, "code": "cols = ['keywords_0', 'keywords_1', 'keywords_2', 'keywords_3']\ndf['keywords_all'] = df[cols].apply(lambda cols: '-'.join(cols), axis=1)\n", "metadata": {"problem_id": 126, "library_problem_id": 126, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 123}}
{"id": 127, "code": "df_sample = df.sample(frac=0.2, random_state=0)\ndf.loc[df_sample.index, 'Quantity'] = 0", "metadata": {"problem_id": 127, "library_problem_id": 127, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 127}}
{"id": 128, "code": "df_sample = df.sample(frac=0.2, random_state=0)\ndf_sample.loc[:,'ProductId'} = 0\n", "metadata": {"problem_id": 128, "library_problem_id": 128, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 127}}
{"id": 129, "code": "df_sample = df.sample(frac=0.2, random_state=0)\ndf_sample.loc[df_sample.index, 'Quantity'] = 0\n", "metadata": {"problem_id": 129, "library_problem_id": 129, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 127}}
{"id": 130, "code": "df['duplicate'] = df.duplicated(subset=['col1','col2'], keep='first')\nresult = df.loc[df['duplicate'] == True]", "metadata": {"problem_id": 130, "library_problem_id": 130, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 130}}
{"id": 131, "code": "df['index_original'] = df.duplicated(subset=['col1','col2'], keep=False)\nresult = df.loc[df.duplicated(subset=['col1','col2'], keep=True)]", "metadata": {"problem_id": 131, "library_problem_id": 131, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 130}}
{"id": 132, "code": "\n    df.drop_duplicates(subset=['col1','col2'], keep='first')\n    duplicate_bool = df.duplicated(subset=['col1','col2'], keep='first')\n    duplicate = df.loc[duplicate_bool == True]\n    duplicate.reset_index(drop=True, inplace=True)\n    duplicate.rename(columns={'index':'index_original'}, inplace=True)\n    duplicate\n    ### END SOLUTION\n\nresult = f(example_df)\nresult\n", "metadata": {"problem_id": 132, "library_problem_id": 132, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 130}}
{"id": 133, "code": "duplicate_bool = df.duplicated(subset=['col1','col2', '3col'], keep='first')\nduplicate = df.loc[duplicate_bool == True]\nresult = duplicate.reset_index()\nresult.columns = ['val', 'col1', 'col2', '3col', 'index_original']\nresult", "metadata": {"problem_id": 133, "library_problem_id": 133, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 130}}
{"id": 134, "code": "duplicate_bool = df.duplicated(subset=['col1','col2'], keep=False)\nduplicate = df.loc[duplicate_bool == True]\nresult = duplicate.reset_index()\nresult.columns = ['val', 'col1', 'col2', '3col', 'index_original']\nresult\nEND SOLUTION\n", "metadata": {"problem_id": 134, "library_problem_id": 134, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 130}}
{"id": 135, "code": "df[df.groupby([df['Sp'], df['Mt']])['count'].idxmax().values]", "metadata": {"problem_id": 135, "library_problem_id": 135, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 135}}
{"id": 136, "code": "df['count'] = df.groupby(['Sp','Mt'])['count'].transform('max')\nresult = df[df['count'] == df.groupmax().max()]", "metadata": {"problem_id": 136, "library_problem_id": 136, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 135}}
{"id": 137, "code": "df[df.groupby([df['Sp'], df['Mt']])['count'].idxmin()].reset_index(drop=True).reset_index()", "metadata": {"problem_id": 137, "library_problem_id": 137, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 135}}
{"id": 138, "code": "df['count'] = df.groupby(['Sp','Value']).count().max().reset_index().rename(columns={'count':'max'})\nresult = df[df['count'] == df['max']]\nEND SOLUTION\n\nIn the above code, you are first grouping by ['Sp','Value'] and then finding the maximum count in each group and then resetting the index and renaming the column 'count' to 'max'. Then, you are selecting rows where count equals max.\n", "metadata": {"problem_id": 138, "library_problem_id": 138, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 135}}
{"id": 139, "code": "result = df.query(\"Category=='Foo'|Category=='Bar'\")", "metadata": {"problem_id": 139, "library_problem_id": 139, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 139}}
{"id": 140, "code": "result = df.query(\"Category not in ('Foo','Bar')\")", "metadata": {"problem_id": 140, "library_problem_id": 140, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 139}}
{"id": 141, "code": "df_melt = df.melt(id_vars=['col1', 'col2', 'col3', 'col4', 'col5', 'col6'])", "metadata": {"problem_id": 141, "library_problem_id": 141, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 141}}
{"id": 142, "code": "df_melt = df.melt(id_vars=['col1', 'col2', 'col3'], value_name='value')", "metadata": {"problem_id": 142, "library_problem_id": 142, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 141}}
{"id": 143, "code": "df['cumsum'] = df.groupby('id').val.cumsum().reset_index(drop=True).add(1).reset_index(drop=True)\nEND SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOLUTION\nEND OF SOL", "metadata": {"problem_id": 143, "library_problem_id": 143, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 143}}
{"id": 144, "code": "df['cumsum'] = df.groupby('id')['val'].cumsum()\n", "metadata": {"problem_id": 144, "library_problem_id": 144, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 143}}
{"id": 145, "code": "df['val'] = df['val'].cumsum()\ndf['stuff'] = df['stuff'].cumsum()\n", "metadata": {"problem_id": 145, "library_problem_id": 145, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 143}}
{"id": 146, "code": "df['cummax'] = df.groupby('id').val.cummax().reset_index(0, name='cummax').values\n", "metadata": {"problem_id": 146, "library_problem_id": 146, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 143}}
{"id": 147, "code": "df['val'] = df['val'].cumsum()\ndf['cumsum'] = df.groupby('id')['val'].cumsum()\n", "metadata": {"problem_id": 147, "library_problem_id": 147, "library": "Pandas", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 143}}
{"id": 148, "code": "df['v'].groupby(df['l'].where(df['l']=='left', 'left').fillna('right').sum()", "metadata": {"problem_id": 148, "library_problem_id": 148, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 148}}
{"id": 149, "code": "df['v'].groupby(df['r'].where(df['l']=='left', 'left').fillna('right').sum()", "metadata": {"problem_id": 149, "library_problem_id": 149, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 148}}
{"id": 150, "code": "df['v'].groupby(df['l'].where(df['v'].isnull(), 'NaN')).sum()\n", "metadata": {"problem_id": 150, "library_problem_id": 150, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 148}}
{"id": 151, "code": "relationships = [column1_column2_many_to_one', 'column1_column3_many_to_one', 'column1_column4_one_to_one', 'column1_column5_many_to_one', 'column2_column1_one_to_one', 'column2_column3_many_to_many', 'column2_column4_one_to_many', 'column2_column5_one_to_many', 'column3_column1_one_to_one', 'column3_column2_many_to_many', 'column3_column4_one_to_many', 'column3_column5_one_to_many', 'column4_column1_one_to_one', 'column4_column2_many_to_many', 'column4_column3_many_to_many', 'column4_column5_one_to_many', 'column5_column1_one_to_one', 'column5_column2_many_to_many', 'column5_column3_many_to_many', 'column5_column4_one_to_many']\n", "metadata": {"problem_id": 151, "library_problem_id": 151, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 151}}
{"id": 152, "code": "df.columns = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\n\nresult = pd.concat([df.shape, df.nunique(), df.apply(lambda x: x.name, axis=1).apply(lambda x: x.values.shape[0]), df.apply(lambda x: x.name+'-'+lambda x: x.values.shape[0] if x.name != 'Column5' else '', axis=1)], axis=1).apply(lambda x: 'Column'+'-'+x if x.startswith('Column') else '', axis=1)], axis=1).apply(lambda x: 'one-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] == 1 else '', axis=1), axis=1).apply(lambda x: 'one-to-one' if x.startswith('Column') and df[x.index[0]].shape[0] == 2 else '', axis=1), axis=1).apply(lambda x: 'many-to-one' if x.startswith('Column') and df[x.index[0]].shape[0] > 2 else '', axis=1), axis=1).apply(lambda x: 'many-toFER-one' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index[0]].shape[0] > 3 else '', axis=1), axis=1).apply(lambda x: 'many-to-many' if x.startswith('Column') and df[x.index", "metadata": {"problem_id": 152, "library_problem_id": 152, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 151}}
{"id": 153, "code": "df.columns[1:4].apply(lambda x: x.to_frame(name='Column1')['Column1'].apply(lambda y: y.value_counts()/y.shape[0]).plot(kind='bar')", "metadata": {"problem_id": 153, "library_problem_id": 153, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 151}}
{"id": 154, "code": "df.columns = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5']\nresult = df.columns.to_frame().apply(lambda x: x.value_count_nonnull()[0], axis=1)\n", "metadata": {"problem_id": 154, "library_problem_id": 154, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 151}}
{"id": 155, "code": "df = df.dropna(subset=['firstname', 'lastname', 'email'])\ndf = df.drop_duplicates(subset=['firstname', 'lastname', 'email'])\ndf = df.sort_values(by=['bank'])\n", "metadata": {"problem_id": 155, "library_problem_id": 155, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 155}}
{"id": 156, "code": "\nacademia\n\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\nend\n", "metadata": {"problem_id": 156, "library_problem_id": 156, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 156}}
{"id": 157, "code": "df['NewGroup'] = (df['SibSp'] > 0) & (df['Parch'] > 0)\nresult = df.groupby('NewGroup').mean()", "metadata": {"problem_id": 157, "library_problem_id": 157, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 157}}
{"id": 158, "code": "df['NewGroup'] = df.groupby((df['Survived'] > 0) | (df['Parch'] > 0))['SibSp'].mean()", "metadata": {"problem_id": 158, "library_problem_id": 158, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 157}}
{"id": 159, "code": "df['NewGroup'] = np.where((df['SibSp'] == 1) & (df['Parch'] == 1), 'Has Family',\n                       np.where((df['SibSp'] == 0) & (df['Parch'] == 0), 'New Family',\n                               np.where((df['SibSp'] == 0) & (df['Parch'] == 1), 'New Family',\n                                       npior.where((df['SibSp'] == 1) & (df['Parch'] == 0), 'Old Family', 'Unknown'))))\n\nresult = df.groupby('NewGroup').mean().sort_index.drop(['NewGroup'], axis=1)", "metadata": {"problem_id": 159, "library_problem_id": 159, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 157}}
{"id": 160, "code": "df.groupby('cokey').apply(lambda x: x.sort_values(by='A'))", "metadata": {"problem_id": 160, "library_problem_id": 160, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 160}}
{"id": 161, "code": "df.groupby('cokey').apply(lambda x: x.sort_values(by='A', ascending=False))", "metadata": {"problem_id": 161, "library_problem_id": 161, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 160}}
{"id": 162, "code": "df.columns = [('col_level_0','col_level_1','col_level_2')]\n", "metadata": {"problem_id": 162, "library_problem_id": 162, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 162}}
{"id": 163, "code": "df.columns = [('col_level_0','col_level_1','col_level_2')]\n", "metadata": {"problem_id": 163, "library_problem_id": 163, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 162}}
{"id": 164, "code": "df.columns = [('col_level_0','col_level_1','col_level_2')]\n", "metadata": {"problem_id": 164, "library_problem_id": 164, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 162}}
{"id": 165, "code": "df = pd.DataFrame(list(someTuple), columns=['birdType', 'birdCount'])\ndf.columns = ['birdType', 'birdCount']\n", "metadata": {"problem_id": 165, "library_problem_id": 165, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 165}}
{"id": 166, "code": "df['mean'] = df.groupby('a')['b'].transform('mean')\ndf['std'] = df.groupby('a')['b'].transform('std')\n", "metadata": {"problem_id": 166, "library_problem_id": 166, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 166}}
{"id": 167, "code": "df['mean'] = df.groupby('b')['a'].transform('mean')\ndf['std'] = df.groupby('b')['a'].transform('std')\n", "metadata": {"problem_id": 167, "library_problem_id": 167, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 166}}
{"id": 168, "code": "import numpy as np\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, FunctionTransformer\n\nclass EncodeLabels(LabelEncoder, MinMaxScaler):\n    def __init__(self, y):\n        super().__init__(y)\n\n    def fit(self, y):\n        return self\n\n    def transform(self, y):\n        return self\n\ndf['b'] = df['b'].apply(lambda x: x+1) # adding 1 to the column b to avoid zero\ndf['softmax'] = df['b'].apply(lambda x: x.apply(lambda y: y.apply(lambda z: z+1))) # adding 1 to the column b to avoid zero\ndf['min-max'] = df['b'].apply(lambda x: x.min()/(x.max()-x.min())) # min-max normalization\ndf['softmax'] = df['softmax'].apply(lambda x: x.apply(lambda y: y.apply(lambda z: z+1))) # adding 1 to the column b to avoid zero\n", "metadata": {"problem_id": 168, "library_problem_id": 168, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 166}}
{"id": 169, "code": "df = df.drop(df.index[0:2])\nresult = df.drop(df.index[0:2])\n", "metadata": {"problem_id": 169, "library_problem_id": 169, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 169}}
{"id": 170, "code": "df = df.drop(df.columns[0],axis=1).drop(df.columns[1],axis=1)\nresult = df.drop(df.columns[0],axis=1).drop(df.columns[1],axis=1)\n", "metadata": {"problem_id": 170, "library_problem_id": 170, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 169}}
{"id": 171, "code": "df = df.drop(df[df.max().idxmax()]().values,axis=1)\nresult = df.drop(df[df.max().idxmax()]().values,axis=1)\nEND SOLUTION\n", "metadata": {"problem_id": 171, "library_problem_id": 171, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 169}}
{"id": 172, "code": "df = df.apply(lambda x: x.idxmax() if x.sum()>1 else x,axis=0)\n", "metadata": {"problem_id": 172, "library_problem_id": 172, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 169}}
{"id": 173, "code": "sorted_s = s.sort_values(ascending=True)\nsorted_s.sort_index(inplace=True)\nresult = sorted_s", "metadata": {"problem_id": 173, "library_problem_id": 173, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 173}}
{"id": 174, "code": "df = pd.DataFrame(s.sort_values().reset_index(), columns=['index','value'])\ndf.sort_values(by=['index'], ascending=[False, True])\n", "metadata": {"problem_id": 174, "library_problem_id": 174, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 173}}
{"id": 175, "code": "df['A'] = df['A'].astype('category').cat.remove_unused_categories()\n", "metadata": {"problem_id": 175, "library_problem_id": 175, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 175}}
{"id": 176, "code": "df = df.loc[df['A'].str.contains('s', na=False)]\n", "metadata": {"problem_id": 176, "library_problem_id": 176, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 175}}
{"id": 177, "code": "df[df.groupby([df['Sp'], df['Mt']])['count'].idxmax().values]", "metadata": {"problem_id": 177, "library_problem_id": 177, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 177}}
{"id": 178, "code": "df['count'] = df.groupby(['Sp','Mt'])['count'].transform('max')\nresult = df[df['count'] == df.groupmax().max()]", "metadata": {"problem_id": 178, "library_problem_id": 178, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 177}}
{"id": 179, "code": "df[df.groupby([df['Sp'], df['Mt']])['count'].idxmin()].reset_index(drop=True).reset_index()", "metadata": {"problem_id": 179, "library_problem_id": 179, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 177}}
{"id": 180, "code": "df['count'] = df.groupby(['Sp','Value']).count().max().reset_index().rename(columns={'count':'max'})\nresult = df[df['count'] == df['max']]\nEND SOLUTION\n\nIn the above code, you are first grouping by ['Sp','Value'] and then finding the maximum count in each group and then resetting the index and renaming the column 'count' to 'max'. Then, you are selecting rows where count equals max.\n", "metadata": {"problem_id": 180, "library_problem_id": 180, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 177}}
{"id": 181, "code": "df['Date'] = df['Member'].map(dict)\n", "metadata": {"problem_id": 181, "library_problem_id": 181, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 181}}
{"id": 182, "code": "df['Date'] = df['Member'].map(dict)\n", "metadata": {"problem_id": 182, "library_problem_id": 182, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 181}}
{"id": 183, "code": "\n    df['Date'] = df['Member'].map(dict)\n    ### END SOLUTION\n\nIn your function, you are trying to map the values in the 'Member' column to the 'Date' column. If the values in 'Member' column are not present in the 'Date' column, it will return NaN. You can replace the 'Date' column with the values from the 'Member' column which are present in the 'Member' column.\n", "metadata": {"problem_id": 183, "library_problem_id": 183, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 181}}
{"id": 184, "code": "df['Date'] = df['Member'].map(dict)\n", "metadata": {"problem_id": 184, "library_problem_id": 184, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 181}}
{"id": 185, "code": "df['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.groupby(['year','month']).Date.size()\ndf['Count_m'] = df.groupby(['year','month']).count()\ndf['Count_y'] = df.groupby(['year']).count()\n", "metadata": {"problem_id": 185, "library_problem_id": 185, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 185}}
{"id": 186, "code": "df['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.groupby(['Date','Val'])['Date'].count()\ndf['Count_m'] = df.groupby(['Date','Val'])['Date'].count()\ndf['Count_y'] = df.groupby(['Date','Val'])['Date'].count()\ndf['Count_Val'] = df.groupby(['Date','Val'])['Date'].count()\n", "metadata": {"problem_id": 186, "library_problem_id": 186, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 185}}
{"id": 187, "code": "df['Date'] = pd.to_datetime(df['Date'], format= '%d/%m/%y')\ndf['Count_d'] = df.groupby(['Date','Val'])['Date'].count()\ndf['Count_m'] = df.groupby(['Date','Val'])['Date'].count()\ndf['Count_y'] = df.groupby(['Date','Val'])['Date'].count()\ndf['Count_w'] = df.groupby(['Date','Val'])['Date'].count()\ndf['Count_Val'] = df.groupby(['Date','Val'])['Date'].count()\n", "metadata": {"problem_id": 187, "library_problem_id": 187, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 185}}
{"id": 188, "code": "df['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date').sum().reset_index().rename_axis('Date',inplace=True)\nresult1 = df.loc[df['B']==0]\nresult2 = df.loc[df['B']>0]\n", "metadata": {"problem_id": 188, "library_problem_id": 188, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 188}}
{"id": 189, "code": "df['B'].sum().plot(kind='bar', ax=result1)\ndf['C'].sum().plot(kind='bar', ax=result2)\n", "metadata": {"problem_id": 189, "library_problem_id": 189, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 188}}
{"id": 190, "code": "df.pivot_table(values=['D','E'], index=['B'], aggfunc={'D':np.sum, 'E':np.mean})", "metadata": {"problem_id": 190, "library_problem_id": 190, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 190}}
{"id": 191, "code": "df.pivot_table(values=['D','E'], index=['B'], aggfunc={'D':np.sum, 'E':np.mean})", "metadata": {"problem_id": 191, "library_problem_id": 191, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 190}}
{"id": 192, "code": "df.pivot_table(values=['D','E'], index=['B'], aggfunc={'D':np.sum, 'E':np.mean})", "metadata": {"problem_id": 192, "library_problem_id": 192, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 190}}
{"id": 193, "code": "df.pivot_table(values=['D','E'], index=['B'], aggfunc={'D':np.max, 'E':np.min})", "metadata": {"problem_id": 193, "library_problem_id": 193, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 190}}
{"id": 194, "code": "df['var1'] = df['var1'].apply(lambda x: x.split(','))\ndf['var2'] = df['var2'].apply(lambda x: x.split())\n", "metadata": {"problem_id": 194, "library_problem_id": 194, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 194}}
{"id": 195, "code": "df['var2'] = df['var2'].str.split(expanding=True)\nresult = df['var2'].reset_index(drop=True).rename(columns={'var2':'var2_1', 'var1':'var1_1'})\n", "metadata": {"problem_id": 195, "library_problem_id": 195, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 194}}
{"id": 196, "code": "df['var2'] = df['var2'].str.split('-').apply(lambda x: x[0]+'-'+x[1])\ndf['var2'] = df['var2'].str.split('-').str[1] + '-' + df['var2'].str.split('-').str[2]\ndf['var2'] = df['var2'].str.strip('-')\n", "metadata": {"problem_id": 196, "library_problem_id": 196, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 194}}
{"id": 197, "code": "import pandas as pd\ndf = pd.read_csv('inn.txt', sep='\\t')\n\ndef count_special_char(string):\n    special_char = 0\n    for i in range(len(string)):\n        if(string[i].isalpha()):\n            continue\n        else:\n            special_char = special_char + 1\n    df[\"new\"]=df.apply(count_special_char, axis = 0)\nprint(df)", "metadata": {"problem_id": 197, "library_problem_id": 197, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 197}}
{"id": 198, "code": "import pandas as pd\ndf = pd.read_csv('inn.txt', sep='\\t')\n", "metadata": {"problem_id": 198, "library_problem_id": 198, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 197}}
{"id": 199, "code": "df[['fips','state']] = df['row'].str.split(' ',expand=True)\ndf = df.drop(columns=['row'])\n", "metadata": {"problem_id": 199, "library_problem_id": 199, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 199}}
{"id": 200, "code": "df[['fips','row']] = df['row'].str.split(' ', 1,expand=True)\n", "metadata": {"problem_id": 200, "library_problem_id": 200, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 199}}
{"id": 201, "code": "df[['fips','medi','row']] = df['row'].str.split(' ',expand=True)\n", "metadata": {"problem_id": 201, "library_problem_id": 201, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 199}}
{"id": 202, "code": "df.columns = ['Name'] + [f'{i+1}'][col] for i in range(len(df.columns)-1) for col in df.columns[i+1] if col > 0\ndf[col] = df[col].cumsum() / (i+1)\n", "metadata": {"problem_id": 202, "library_problem_id": 202, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 202}}
{"id": 203, "code": "df.loc['Average'] = df.iloc[1:]['2001':'2006'].mean().round(1)", "metadata": {"problem_id": 203, "library_problem_id": 203, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 202}}
{"id": 204, "code": "\n    df1 = df.copy()\n    df1[['2001', '2002', '2003', '2004', '2005', '2006']] = df1[['2001', '2002', '2003', '2004', '2005', '2006']].apply(lambda x: x.mean(axis=1, skipna=True),axis=1)\n    return df1\n\nresult = f(example_df)\nresult\n", "metadata": {"problem_id": 204, "library_problem_id": 204, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 202}}
{"id": 205, "code": "df.loc[:,'2001':'2006'} = df.loc[:,'2001':'2006'}.cumsum().div(df.loc[:,'2001':'2006'}.cumsum() > 0).fillna(df.loc[:,'2001':'2006'}.cumsum() / 2).rename(columns=lambda x: f'{x} cumulative average')", "metadata": {"problem_id": 205, "library_problem_id": 205, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 202}}
{"id": 206, "code": "df['label'] = (df['Close'].shift(-1, fill_value=0) > df['Close']).astype(int)\n", "metadata": {"problem_id": 206, "library_problem_id": 206, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 206}}
{"id": 207, "code": "df['label'] = df['Close'].diff().apply(lambda x: -1 if x<0 else 1 if x>0 else 0)\n", "metadata": {"problem_id": 207, "library_problem_id": 207, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 206}}
{"id": 208, "code": "df['label'] = df['Close'].diff().div(df['Close'].shift(-1)).map(lambda x: -1 if x<0 else 0 if x>0 else 1, axis=0).rename('label')\n", "metadata": {"problem_id": 208, "library_problem_id": 208, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 206}}
{"id": 209, "code": "df['Duration'] = pd.to_timedelta64([df.departure_time]).dt.seconds.div(df.arrival_time).div(24*60*60).div(60*60*60).div(60*60).dropna()\n", "metadata": {"problem_id": 209, "library_problem_id": 209, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 209}}
{"id": 210, "code": "df['Duration'] = pd.to_timedelta64([2016-05-19 08:25:00]).total_seconds() - pd.to_timedelta64([2016-05-19 13:50:00]).total_seconds()\n", "metadata": {"problem_id": 210, "library_problem_id": 210, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 209}}
{"id": 211, "code": "df['Duration'] = pd.to_timedelta64(df.departure_time - df.arrival_time).seconds.round(2)\n", "metadata": {"problem_id": 211, "library_problem_id": 211, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 209}}
{"id": 212, "code": "df['count'] = df.groupby('key1')['key2'].transform('count')\nresult = df.groupby('key1').size()", "metadata": {"problem_id": 212, "library_problem_id": 212, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 212}}
{"id": 213, "code": "df['count'] = df.groupby('key1')['key2'].transform('count')\nresult = df.groupby('key1').filter(lambda x: x['key2'] == 'two')\n", "metadata": {"problem_id": 213, "library_problem_id": 213, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 212}}
{"id": 214, "code": "df['key2_endswith_e'] = df['key2'].endswith('e')\nresult = df.groupby('key1')['key2'].transform('count')\n", "metadata": {"problem_id": 214, "library_problem_id": 214, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 212}}
{"id": 215, "code": "min_result = df.loc[df['value'].idxmin()]", "metadata": {"problem_id": 215, "library_problem_id": 215, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 215}}
{"id": 216, "code": "mode_result = df.mode(axis=None)[0]\nmedian_result = df.median()[0]\n", "metadata": {"problem_id": 216, "library_problem_id": 216, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 215}}
{"id": 217, "code": "df = df[(df['closing_price'].between(99, 101))]\n", "metadata": {"problem_id": 217, "library_problem_id": 217, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 217}}
{"id": 218, "code": "df = df[~(df['closing_price'].between(99, 101))]\n", "metadata": {"problem_id": 218, "library_problem_id": 218, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 217}}
{"id": 219, "code": "df1 = df.groupby(\"item\")[\"diff\"].idxmin()\nresult = df.loc[df['item'] == df1['item'].values, [\"otherstuff\"]]\n", "metadata": {"problem_id": 219, "library_problem_id": 219, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 219}}
{"id": 220, "code": "df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[1]\n", "metadata": {"problem_id": 220, "library_problem_id": 220, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 220}}
{"id": 221, "code": "df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[0]\n", "metadata": {"problem_id": 221, "library_problem_id": 221, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 220}}
{"id": 222, "code": "\n    df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[1]\n    ### END SOLUTION\n\n\nA:\nimport pandas as pd\n\nstrs = ['Stackoverflow_1234',\n        'Stack_Over_Flow_1234',\n        'Stackoverflow',\n        'Stack_Overflow_1234']\nexample_df = pd.DataFrame(data={'SOURCE_NAME': strs})\ndef f(df=example_df):\n    # return the solution in this function\n    df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[1]\n\n\n\nA:\nimport pandas as pd\n\nstrs = ['Stackoverflow_1234',\n        'Stack_Over_Flow_1234',\n        'Stackoverflow',\n        'Stack_Overflow_1234']\nexample_df = pd.DataFrame(data={'SOURCE_NAME': strs})\ndef f(df=example_df):\n    # return the solution in this function\n    df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[1]\n\n\n\nA:\nimport pandas as pd\n\nstrs = ['Stackoverflow_1234',\n        'Stack_Over_Flow_1234',\n        'Stackoverflow',\n        'Stack_Overflow_1234']\nexample_df = pd.DataFrame(data={'SOURCE_NAME': strs})\ndef f(df=example_df):\n    # return the solution in this function\n    df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[1]\n\n\n\nA:\nimport pandas as pd\n\nstrs = ['Stackoverflow_1234',\n        'Stack_Over_Flow_1234',\n        'Stackoverflow',\n        'Stack_Overflow_1234']\nexample_df = pd.DataFrame(data={'SOURCE_NAME': strs})\ndef f(df=example_df):\n    # return the solution in this function\n    df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[1]\n\n\n\nA:\nimport pandas as pd\n\nstrs = ['Stackoverflow_1234',\n        'Stack_Over_Flow_1234',\n        'Stackoverflow',\n        'Stack_Overflow_1234']\nexample_df = pd.DataFrame(data={'SOURCE_NAME': strs})\ndef f(df=example_df):\n    # return the solution in this function\n    df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[1]\n\n\n\nA:\nimport pandas as pd\n\nstrs = ['Stackoverflow_1234',\n        'Stack_Over_Flow_1234',\n        'Stackoverflow',\n        'Stack_Overflow_1234']\nexample_df = pd.DataFrame(data={'SOURCE_NAME': strs})\ndef f(df=example_df):\n    # return the solution in this function\n    df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[1]\n\n\n\nA:\nimport pandas as pd\n\nstrs = ['Stackoverflow_1234',\n        'Stack_Over_Flow_1234',\n        'Stackoverflow',\n        'Stack_Overflow_1234']\nexample_df = pd.DataFrame(data={'SOURCE_NAME': strs})\ndef f(df=example_df):\n    # return the solution in this function\n    df['SOURCE_NAME'] = df['SOURCE_NAME'].str.split('_').str[1]\n\n\n\nA:\nimport pandas as pd\n\nstrs = ['Stackoverflow_1234',\n        'Stack_Over_Flow_1234',\n        'Stackoverflow',\n        'Stack_Overflow_1234']\nexample_df = pd.DataFrame(data={'SOURCE_NAME': strs})\ndef f(df=example_df):\n", "metadata": {"problem_id": 222, "library_problem_id": 222, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 220}}
{"id": 223, "code": "df['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)", "metadata": {"problem_id": 223, "library_problem_id": 223, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 223}}
{"id": 224, "code": "df['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)", "metadata": {"problem_id": 224, "library_problem_id": 224, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 223}}
{"id": 225, "code": "df['Column_x'] = df['Column_x'].fillna(df['Column_x'].mode()[0], inplace= True)\n", "metadata": {"problem_id": 225, "library_problem_id": 225, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 223}}
{"id": 226, "code": "result = pd.concat([a, b], axis=1).reset_index().values\nresult = pd.DataFrame(result, columns=['one', 'two'])\n", "metadata": {"problem_id": 226, "library_problem_id": 226, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 226}}
{"id": 227, "code": "result = pd.concat([a, b, c], axis=1).groupby(list(a.columns))[-1].apply(lambda x: tuple(x))\n", "metadata": {"problem_id": 227, "library_problem_id": 227, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 226}}
{"id": 228, "code": "result = pd.concat([a, b], axis=1, ignore_index=True).fillna(np.nan)", "metadata": {"problem_id": 228, "library_problem_id": 228, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 226}}
{"id": 229, "code": "result = df.groupby('username').views.count().to_frame().reset_index().rename_axis(index=[0], columns=['username', 'views'])\nresult.columns = ['username', 'views']\nresult.sort_values(['views'], inplace=True\nresult = result.sort_values(['username']).reset_index().reset_index().rename_axis(index=[0], columns=['username', 'views'])\nEND SOLUTION\n\nI want to count views that belong to certain bins and group by username.\n\nA: You can use the `groupby()` function to group by both 'username' and 'views'. Then you can use the `count()` function to count the number of rows in each group. Here is how you can do it:\n\n```python\nresult = df.groupby(['username', 'views']).count().reset_index().rename_axis(index=[0], columns=['username', 'views'])\n```\nIn the above code, `groupby(['username', 'views'])` groups by both 'username' and 'views'. Then `count().reset_index().rename_axis(index=[0], columns=['username', 'views'])` counts the number of rows in each group and renames the index to 'username' and 'views'.\n", "metadata": {"problem_id": 229, "library_problem_id": 229, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 229}}
{"id": 230, "code": "result = df.groupby('username').views.count().to_frame().reset_index().rename_axis(index=[], name=['views']).reset_index().rename_axis(index=[], name=['username']).reset_index()\nresult.columns = ['views'] + [f'({i}, {i+1})' for i in range(len(bins)-1)]\nresult.columns = ['username', 'views']\nEND SOLUTION\n\nresult\nEND SOLUTION\n<result>\nviews    1    10     25     50     100\nusername\njane     1      1      1      1      1\njohn      1      1      1      1      1\nEND SOLUTION\n\nIn the end, you should have a DataFrame with the counts of views for each user and each bin.\n", "metadata": {"problem_id": 230, "library_problem_id": 230, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 229}}
{"id": 231, "code": "result = df.groupby('username').views.count().to_frame().reset_index().merge(pd.Series(bins), on='username').rename(columns={'views':'views_bin1', 'username':'username_bin1'})\nresult.views_bin1 = result.views_bin1.map(lambda x: x.replace(3=1, 2=1, 1=1, 0=0))\nresult.views_bin1 = result.views_bin1.map(lambda x: x.replace(3=1, 2=1, 1=1, 0=0))\nresult.rename(columns={'views_bin1':'views_bin1', 'username_bin1':'username_bin1'}, inplace=True)\nresult", "metadata": {"problem_id": 231, "library_problem_id": 231, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 229}}
{"id": 232, "code": "df['text'] = df['text'].apply(lambda x: ',' + ' ' + x)\nresult = df['text'].str.catenate(sep=' ')\n", "metadata": {"problem_id": 232, "library_problem_id": 232, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 232}}
{"id": 233, "code": "df['text'] = df['text'].apply(lambda x: '-' + x + '-')\nresult = df['text'].str.strip('-')\n", "metadata": {"problem_id": 233, "library_problem_id": 233, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 232}}
{"id": 234, "code": "df['text'] = df['text'].apply(lambda x: ','.join(x.split(',')))\nresult = df['text'].str.strip().str.split(', ')\nresult = result.apply(lambda x: ' '.join(x))\n", "metadata": {"problem_id": 234, "library_problem_id": 234, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 232}}
{"id": 235, "code": "df['text'] = df['text'].apply(lambda x: x.split(','))\ndf = df.rename(columns={'text': 'Name'})\n", "metadata": {"problem_id": 235, "library_problem_id": 235, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 232}}
{"id": 236, "code": "df['text'] = df['text'].apply(lambda x: '-' + x + '-')\nresult = df['text'].to_frame().apply(lambda x: x.str.strip('-').str.split('-')[1],axis=1)\n", "metadata": {"problem_id": 236, "library_problem_id": 236, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 232}}
{"id": 237, "code": "result = pd.concat([df1, df2], axis=0).reset_index(drop=True).drop_duplicates()", "metadata": {"problem_id": 237, "library_problem_id": 237, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 237}}
{"id": 238, "code": "df1.reset_index = lambda x: x.reset_index()\ndf2.reset_index = lambda x: x.reset_index()\n\nresult = pd.concat([df1, df2], axis=0).sort_values(['id', 'date']).reset_index(drop=True)\nresult.sort_values(['id', 'date']).reset_index(drop=True,\n                                                 names=['id', 'district', 'date', 'value'])\nEND SOLUTION\n", "metadata": {"problem_id": 238, "library_problem_id": 238, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 237}}
{"id": 239, "code": "result = pd.concat([df1, df2], axis=0).reset_index(drop=True).drop_duplicates()", "metadata": {"problem_id": 239, "library_problem_id": 239, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 237}}
{"id": 240, "code": "C = C.set_index('A').drop('B',1).rename(columns={'B':'B_x'}).reset_index().rename(columns={'B':'B_y'})\nD = D.set_index('A').drop('B',1).rename(columns={'B':'B_x'}).reset_index().rename(columns={'B':'B_y'})\nresult = pd.merge(C, D, left_index=C.index, right_index=D.index, how='left').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(method='ffill').fillna(", "metadata": {"problem_id": 240, "library_problem_id": 240, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 240}}
{"id": 241, "code": "C = C.set_index('A').drop('B').rename_axis(None).reset_index()\nD = D.set_index('A').drop('B').rename_axis(None).reset_index()\nresult = pd.merge(C, D, left_index=C.index, right_index=D.index, how='left').fillna(D['B'].to_list()[0])\n", "metadata": {"problem_id": 241, "library_problem_id": 241, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 240}}
{"id": 242, "code": "C.set_index('A', drop=True, inplace=True)\nD.set_index('A', drop=True, inplace=True)\n\nmerged = pd.concat([C, D])\nmerged.sort_values('A', inplace=True)\n\nresult = merged\nEND SOLUTION\n\nIn the end, merged dataframe should look like this:\n<code>\n    A  B\n0  AB  1\n1  CD  4\n2  EF  3\n3  GH  5\n", "metadata": {"problem_id": 242, "library_problem_id": 242, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 240}}
{"id": 243, "code": "df['time_amount'] = df['time'].astype(str) + '_' + df['amount'].astype(str)\nresult = df.groupby('user')['time_amount'].apply(lambda x: x.split('_')[1:]).apply(lambda x: [float(x[0]) , float(x[1])]).apply(sorted(zip(x, y))).reset_index(drop=1, level=0).values\nresult\nEND SOLUTION\n", "metadata": {"problem_id": 243, "library_problem_id": 243, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 243}}
{"id": 244, "code": "df['amount-time'] = df.groupby('user')['time', 'amount'].apply(list)\nresult = df.groupby('user')['amount-time'].apply(lambda x: list(zip(x)))\nresult = pd.DataFrame(result)\nresult.columns = ['time', 'amount']\nresult\nEND SOLUTION\n", "metadata": {"problem_id": 244, "library_problem_id": 244, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 243}}
{"id": 245, "code": "df['amount-time'] = df[['time', 'amount']].apply(lambda x: list(zip(x[1:], x[0])))\nresult = df.groupby('user')['amount-time'].apply(lambda x: list(zip(x)))\nresult = pd.DataFrame(result, columns=['time', 'amount'])\nresult.sort_values(by=['time', 'amount'}, inplace=True, ascending=[False, True])\nresult\nEND SOLUTION\n", "metadata": {"problem_id": 245, "library_problem_id": 245, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 243}}
{"id": 246, "code": "df = pd.concat(series, axis=1)", "metadata": {"problem_id": 246, "library_problem_id": 246, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 246}}
{"id": 247, "code": "df = pd.concat(series, axis=1)", "metadata": {"problem_id": 247, "library_problem_id": 247, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 246}}
{"id": 248, "code": "result = [col for col in df.columns if s in col]\n", "metadata": {"problem_id": 248, "library_problem_id": 248, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 248}}
{"id": 249, "code": "result = df.columns[df.columns.str.contains('spike')][0]\nprint(result)", "metadata": {"problem_id": 249, "library_problem_id": 249, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 248}}
{"id": 250, "code": "result = df.columns.to_series().apply(lambda x: x.split('-')[1:] if 'spike' not in x.split('-')[:-1] else x).rename(columns=lambda x: f'{s}_{x}' if x != s else x).reset_index(drop=True, inplace=True)\n", "metadata": {"problem_id": 250, "library_problem_id": 250, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 248}}
{"id": 251, "code": "df['codes'] = df['codes'].apply(lambda x: pd.Series(x).fillna(0).reset_index(drop=True))\ndf = df.drop(columns='codes')\nresult = df\n", "metadata": {"problem_id": 251, "library_problem_id": 251, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 251}}
{"id": 252, "code": "df['codes'] = df['codes'].apply(lambda x: pd.Series(x).fillna(0).reset_index(drop=True))\ndf = df.drop(columns='codes')\nresult = df\n", "metadata": {"problem_id": 252, "library_problem_id": 252, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 251}}
{"id": 253, "code": "df['codes'] = df['codes'].apply(lambda x: pd.Series(x).fillna('NaN').values.tolist())\ndf = df.drop(columns=['codes'])\nresult = df\n", "metadata": {"problem_id": 253, "library_problem_id": 253, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 251}}
{"id": 254, "code": "import ast\n\ndf['col1'] = df['col1'].apply(ast.literal_eval)\nresult = df['col1'].values.tolist()\n", "metadata": {"problem_id": 254, "library_problem_id": 254, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 254}}
{"id": 255, "code": "result = df['col1'].apply(lambda x: ', '.join(map(str, x))).str.replace('[','').str.replace(']','').str.strip()\n", "metadata": {"problem_id": 255, "library_problem_id": 255, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 254}}
{"id": 256, "code": "import ast\n\ndf['col1'] = df['col1'].apply(lambda x: ast.literal(x))\nresult = df['col1'].str.join(', ')\n", "metadata": {"problem_id": 256, "library_problem_id": 256, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 254}}
{"id": 257, "code": "df.set_index('Time').resample('2Min').mean().rename(index=lambda x: x.strftime('%H:%M:%S')).reset_index(drop=True)\n", "metadata": {"problem_id": 257, "library_problem_id": 257, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 257}}
{"id": 258, "code": "df.set_index('Time').resample('3Min').sum().sort_values(by=['Time']).reset_index().rename_is(columns={'Time':'Time', 'Value':'Value'}).reset_index(drop=True, drop_index=True).reset_index(drop=False, drop_index=False).reset_index(drop=True)", "metadata": {"problem_id": 258, "library_problem_id": 258, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 257}}
{"id": 259, "code": "df['TIME'] = pd.to_datetime64(df['TIME'], format='%Y-%m-%d %H:%M:%S')\ndf['RANK'] = df.groupby('ID')['TIME'].rank(method='first', ascending=True)\n", "metadata": {"problem_id": 259, "library_problem_id": 259, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 259}}
{"id": 260, "code": "df['TIME'] = pd.to_datetime64(df['TIME'], format='%Y-%m-%d %H:%M:%S')\ndf['RANK'] = df.groupby('ID')['TIME'].rank(method='first', ascending=False)\n", "metadata": {"problem_id": 260, "library_problem_id": 260, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 259}}
{"id": 261, "code": "df['TIME'] = pd.to_datetime64(df['TIME'], format='%Y-%m-%d %H:%M:%S')\ndf['RANK'] = df.groupby('ID')['TIME'].rank(method='first', ascending=False)\n", "metadata": {"problem_id": 261, "library_problem_id": 261, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 259}}
{"id": 262, "code": "result = df[~filt.index.to_frame().equals(df.index.rename(level='c').loc[filt])]", "metadata": {"problem_id": 262, "library_problem_id": 262, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 262}}
{"id": 263, "code": "result = df[~filt.index.to_frame().equals(df.index.rename(index={0:'a',1:'b'}))].reset_index()\n", "metadata": {"problem_id": 263, "library_problem_id": 263, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 262}}
{"id": 264, "code": "df[['c0', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8']].equals(df[['c0', 'c1', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8']])", "metadata": {"problem_id": 264, "library_problem_id": 264, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 264}}
{"id": 265, "code": "df[['c0', 'c2']].equals(df[['c0', 'c2']])\n", "metadata": {"problem_id": 265, "library_problem_id": 265, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 264}}
{"id": 266, "code": "result = df.columns[~df.isnull().all(axis=1)]", "metadata": {"problem_id": 266, "library_problem_id": 266, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 264}}
{"id": 267, "code": "result = [(col, df.iloc[0].loc[col], df.iloc[8].loc[col]) for col in df.iloc[0].columns if col != 'c8']\n", "metadata": {"problem_id": 267, "library_problem_id": 267, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 264}}
{"id": 268, "code": "ts = df['Value']", "metadata": {"problem_id": 268, "library_problem_id": 268, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 268}}
{"id": 269, "code": "df = df.rename(columns={'A':'A_1','B':'B_1','C':'C_1','D':'D_1','E':'E_1')", "metadata": {"problem_id": 269, "library_problem_id": 269, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 269}}
{"id": 270, "code": "df = df.rename(columns={'A': 'A_0', 'B': 'B_0', 'C': 'C_0', 'D': 'D_0', 'E': 'E_0'})\n", "metadata": {"problem_id": 270, "library_problem_id": 270, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 269}}
{"id": 271, "code": "df['dogs'] = df['dogs'].apply(lambda x: round(x, 2))", "metadata": {"problem_id": 271, "library_problem_id": 271, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 271}}
{"id": 272, "code": "df['dogs'] = df['dogs'].apply(lambda x: round(x, 2))\ndf['cats'] = df['cats'].apply(lambda x: round(x, 2))\n", "metadata": {"problem_id": 272, "library_problem_id": 272, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 271}}
{"id": 273, "code": "df['Sum'] = df[list_of_my_columns].sum(axis=1)\n", "metadata": {"problem_id": 273, "library_problem_id": 273, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 273}}
{"id": 274, "code": "df[list_of_my_columns].mean(axis=1)", "metadata": {"problem_id": 274, "library_problem_id": 274, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 273}}
{"id": 275, "code": "df[list_of_my_columns].mean(axis=1)", "metadata": {"problem_id": 275, "library_problem_id": 275, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 273}}
{"id": 276, "code": "df.sort_index(ascending=[True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,0.1,'TGFb',2),\n                                                 names=['treatment','dose','time']))\n", "metadata": {"problem_id": 276, "library_problem_id": 276, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 276}}
{"id": 277, "code": "df.sort_index(ascending=[True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,0.158406,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-0.008032,-0.052608,-", "metadata": {"problem_id": 277, "library_problem_id": 277, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 276}}
{"id": 278, "code": "df = df.drop(df[(df.index >= '2020-02-17 15:30:00') & (df.index <= '2020-02-18 15:30:00')])", "metadata": {"problem_id": 278, "library_problem_id": 278, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 278}}
{"id": 279, "code": "df = df.drop(df[(df.index.date().dt.weekday()==5) & (df.index.date().dt.hour()==15) | (df.index.date().dt.hour()==20)])\n", "metadata": {"problem_id": 279, "library_problem_id": 279, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 278}}
{"id": 280, "code": "threshold = 0.3\nmask = corr.abs() > threshold\nresult = corr[mask.T]", "metadata": {"problem_id": 280, "library_problem_id": 280, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 280}}
{"id": 281, "code": "threshold = 0.3\nmask = corr.abs() > threshold\nresult = corr[mask.values]", "metadata": {"problem_id": 281, "library_problem_id": 281, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 280}}
{"id": 282, "code": "df.columns[-1] = 'Test'\n", "metadata": {"problem_id": 282, "library_problem_id": 282, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 282}}
{"id": 283, "code": "df.columns[0] = 'Test'\n", "metadata": {"problem_id": 283, "library_problem_id": 283, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 282}}
{"id": 284, "code": "df['frequent'] = df.apply(lambda row: row.mode() if row.nunique() > 1 else None, axis=1)\ndf['freq_count'] = df.apply(lambda row: row.value_counts() if row.nunique() > 1 else None, axis=1)\n", "metadata": {"problem_id": 284, "library_problem_id": 284, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 284}}
{"id": 285, "code": "df['frequent'] = df.apply(lambda row: list(row.value_counts().idxmax()), axis=0)\ndf['freq_count'] = df.apply(lambda row: list(row.value_counts().values), axis=0)\n", "metadata": {"problem_id": 285, "library_problem_id": 285, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 284}}
{"id": 286, "code": "df['frequent'] = df.apply(lambda row: list(row.mode()) if row.nunique() > 1 else None, axis=1)\ndf['freq_count'] = df.apply(lambda row: row.count() if row.nunique() == 1 else None, axis=1)\n", "metadata": {"problem_id": 286, "library_problem_id": 286, "library": "Pandas", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 284}}
{"id": 287, "code": "df.groupby(['id1','id2')['foo'].mean()", "metadata": {"problem_id": 287, "library_problem_id": 287, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 287}}
{"id": 288, "code": "df['bar'] = df['bar'].fillna('0')\ndf['bar'] = df['bar'].astype('float')\ndf['foo'] = df['foo'].astype('float')\ndf = df.groupby(['id1','id2'])['foo'].mean().rename(index=range(len(df)), index=range(len(df)-1))", "metadata": {"problem_id": 288, "library_problem_id": 288, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 287}}
{"id": 289, "code": "df_c = pd.merge(df_a, df_b, on='EntityNum')\n", "metadata": {"problem_id": 289, "library_problem_id": 289, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 289}}
{"id": 290, "code": "df_c = pd.merge(df_a, df_b, on='EntityNum')\n", "metadata": {"problem_id": 290, "library_problem_id": 290, "library": "Pandas", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 289}}
{"id": 291, "code": "result = a.shape\n", "metadata": {"problem_id": 291, "library_problem_id": 0, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 292, "code": "import numpy as np\nx = np.nan_array(['1400', '1500', '1600', 'nan', 'nan', 'nan', '1700']\n", "metadata": {"problem_id": 292, "library_problem_id": 1, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 1}}
{"id": 293, "code": "x = x.replace(np.nan, np.inf)", "metadata": {"problem_id": 293, "library_problem_id": 2, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 1}}
{"id": 294, "code": "import numpy as np\nx = np.array([[1400, 1500, 1600, np.nan], [1800, np.nan, npataranamespaceipath, np.nan, 1700]])\n", "metadata": {"problem_id": 294, "library_problem_id": 3, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 1}}
{"id": 295, "code": "b = np.zeros((len(a), 4), dtype=int)\nfor i, val in enumerate(a):\n    b[val][i] = 1", "metadata": {"problem_id": 295, "library_problem_id": 4, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 4}}
{"id": 296, "code": "b = np.zeros((len(a), 4), dtype=int)\nfor i, val in enumerate(a):\n    b[i, val] = 1\n", "metadata": {"problem_id": 296, "library_problem_id": 5, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 4}}
{"id": 297, "code": "b = np.zeros((len(a), 5), dtype=int)\nfor i, val in enumerate(a):\n    b[val] = 1\n", "metadata": {"problem_id": 297, "library_problem_id": 6, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 298, "code": "b = np.zeros((len(a), 1), dtype=int, excludes=a)\n", "metadata": {"problem_id": 298, "library_problem_id": 7, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 4}}
{"id": 299, "code": "b = np.zeros((len(a), max(a[1])+1, min(a[1])+1), dtype=int, order='F' if i.e., C order'C' )\n", "metadata": {"problem_id": 299, "library_problem_id": 8, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 4}}
{"id": 300, "code": "result, _ = np.percentile(a, p)\nprint(result)\n", "metadata": {"problem_id": 300, "library_problem_id": 9, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 301, "code": "B = np.array([A[i:i+ncol] for i in range(0, len(A), ncol)]\nEND SOLUTION\n\nIn the solution, we are creating a 2D array by taking a slice of the original array A with a step size of ncol.\n\nThe solution is a list comprehension that iterates over the array A and for each iteration, it slices a slice of ncol elements starting at the index i. The result is a 2D array of shape (len(A) - ncol + 1, ncol).\n", "metadata": {"problem_id": 301, "library_problem_id": 10, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 10}}
{"id": 302, "code": "B = np.array([A[i:i+nrow] for i in range(0, len(A), nrow)]).reshape(-1, nrow)\n", "metadata": {"problem_id": 302, "library_problem_id": 11, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 10}}
{"id": 303, "code": "B = np.from_logical(np.cumsum(A.reshape(len(A)//ncol,ncol),start=0).reshape(-1,ncol),start=0).reshape(-1,ncol)[...,:-1]\n", "metadata": {"problem_id": 303, "library_problem_id": 12, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 10}}
{"id": 304, "code": "B = np.fromfunction(lambda x, y: x+y, shape=(len(A)//ncol, ncol), dtype=A.dtype)\n", "metadata": {"problem_id": 304, "library_problem_id": 13, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 10}}
{"id": 305, "code": "result = np.roll(a, shift)\nprint(result)\n", "metadata": {"problem_id": 305, "library_problem_id": 14, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 14}}
{"id": 306, "code": "result = np.shift(a, shift)\nEND SOLUTION\nresult\n", "metadata": {"problem_id": 306, "library_problem_id": 15, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 14}}
{"id": 307, "code": "result = np.shift(a, shift)\n", "metadata": {"problem_id": 307, "library_problem_id": 16, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 14}}
{"id": 308, "code": "r_old = np.random.randint(3, size=(100, 2000)) - 1\nr_new = np.random.randint(3, size=(100, 2000)) - 1\n", "metadata": {"problem_id": 308, "library_problem_id": 17, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 17}}
{"id": 309, "code": "result = np.unravelal_index(a.shape, a)\n", "metadata": {"problem_id": 309, "library_problem_id": 18, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 18}}
{"id": 310, "code": "result = np.unravelal_index(a.ndimension_size, a)", "metadata": {"problem_id": 310, "library_problem_id": 19, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 311, "code": "result = np.unravel_index(a.argmax(), a.shape)\n", "metadata": {"problem_id": 311, "library_problem_id": 20, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 312, "code": "result = np.unravel_index(a.argmax(), a.shape)\n", "metadata": {"problem_id": 312, "library_problem_id": 21, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 313, "code": "\n    max_position = a.argmax()\n    result = max_position\n    ### END SOLUTION\nresult\n", "metadata": {"problem_id": 313, "library_problem_id": 22, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 18}}
{"id": 314, "code": "result = np.unravel_index(np.argmax(a,axis=None),a.shape)\n", "metadata": {"problem_id": 314, "library_problem_id": 23, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 18}}
{"id": 315, "code": "import numpy as np\na = np.array([[np.nan, 2., 3., np.nan],\n\t\t[1., 2., 3., 9]])\n\nmask = np.isnan(a)\n\na = np.nan_to_num(a, nan=np.nan)\n", "metadata": {"problem_id": 315, "library_problem_id": 24, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 24}}
{"id": 316, "code": "import numpy as np\na = np.array([[np.nan, 2., 3., np.nan],\n\t\t[1., 2., 3., 9]])\na = np.delete(a, np.where(a==np.nan)[0], axis=0)\n", "metadata": {"problem_id": 316, "library_problem_id": 25, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 24}}
{"id": 317, "code": "import numpy as np\na = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] \nresult = np.array(a)\n", "metadata": {"problem_id": 317, "library_problem_id": 26, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 26}}
{"id": 318, "code": "permutation = [0, 4, 1, 3, 2]\na = np.transpose(a, permutation)", "metadata": {"problem_id": 318, "library_problem_id": 27, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 27}}
{"id": 319, "code": "result = np.transpose(a, permutation)\n", "metadata": {"problem_id": 319, "library_problem_id": 28, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 27}}
{"id": 320, "code": "result = np.unravel2d.argmin(a)\n", "metadata": {"problem_id": 320, "library_problem_id": 29, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 29}}
{"id": 321, "code": "result = np.unravelmax(a)", "metadata": {"problem_id": 321, "library_problem_id": 30, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 29}}
{"id": 322, "code": "result = np.unravel2d(a, (1, 1), order='F')\n", "metadata": {"problem_id": 322, "library_problem_id": 31, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 29}}
{"id": 323, "code": "result = np.sin(np.radians(degree))", "metadata": {"problem_id": 323, "library_problem_id": 32, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 324, "code": "result = np.cos(np.radians(degree))\n", "metadata": {"problem_id": 324, "library_problem_id": 33, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 32}}
{"id": 325, "code": "result = np.sin(np.radians(number)) > 0.95\n", "metadata": {"problem_id": 325, "library_problem_id": 34, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 32}}
{"id": 326, "code": "import math\nresult = math.degrees(value)\n", "metadata": {"problem_id": 326, "library_problem_id": 35, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 32}}
{"id": 327, "code": "import numpy as np\nA = np.array([1,2,3,4,5])\nlength = 1024\n", "metadata": {"problem_id": 327, "library_problem_id": 36, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 328, "code": "def pad(A, length):\n    ...\nA = np.array([1,2,3,4,5])\nlength = 8\nresult = np.pad(A, (0,1), 'edge')\n", "metadata": {"problem_id": 328, "library_problem_id": 37, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 36}}
{"id": 329, "code": "print(np.power(a, power))\n", "metadata": {"problem_id": 329, "library_problem_id": 38, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 38}}
{"id": 330, "code": "\n    return np.power(a, power)\n    ### END SOLUTION\n\nprint(f(example_a, 5))\n", "metadata": {"problem_id": 330, "library_problem_id": 39, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 38}}
{"id": 331, "code": "result = (numerator/denominator, denominator/numerator)\n", "metadata": {"problem_id": 331, "library_problem_id": 40, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 40}}
{"id": 332, "code": "\n    result = np.divide(numerator, denominator)\n    ### END SOLUTION\n    return result\n", "metadata": {"problem_id": 332, "library_problem_id": 41, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 40}}
{"id": 333, "code": "result = (numerator/denominator, denominator/numerator)\n", "metadata": {"problem_id": 333, "library_problem_id": 42, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 40}}
{"id": 334, "code": "result = (a + b + c) / 3\n", "metadata": {"problem_id": 334, "library_problem_id": 43, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 43}}
{"id": 335, "code": "result = np.maximum.reduce(a, b, c)\n", "metadata": {"problem_id": 335, "library_problem_id": 44, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 43}}
{"id": 336, "code": "result = np.diag(a[1:,::-1])\n", "metadata": {"problem_id": 336, "library_problem_id": 45, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 45}}
{"id": 337, "code": "result = np.diag(a)[1:]\n", "metadata": {"problem_id": 337, "library_problem_id": 46, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 45}}
{"id": 338, "code": "result = np.diag(a)[1:]\n", "metadata": {"problem_id": 338, "library_problem_id": 47, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 45}}
{"id": 339, "code": "diagonal = np.tranpose(a)[0][::2][::2]\nresult = diagonal\n", "metadata": {"problem_id": 339, "library_problem_id": 48, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 45}}
{"id": 340, "code": "result = [X[i][j] for i in range(len(X)) for j in range(len(X[i]))]\n", "metadata": {"problem_id": 340, "library_problem_id": 49, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 49}}
{"id": 341, "code": "result = [X[i][j] for i,j in zip(range(len(X)), range(len(X[0])))]\n", "metadata": {"problem_id": 341, "library_problem_id": 50, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 49}}
{"id": 342, "code": "\n    result = []\n    for i in range(len(X)):\n        for j in range(len(X[i])):\n            result.append(X[i][j])\n    return result\n", "metadata": {"problem_id": 342, "library_problem_id": 51, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 49}}
{"id": 343, "code": "result = [X[i,j] for i,j in zip(*map(slice, X))]", "metadata": {"problem_id": 343, "library_problem_id": 52, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 49}}
{"id": 344, "code": "result = np.fromstring(mystr, dtype=int, sep='')\n", "metadata": {"problem_id": 344, "library_problem_id": 53, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 53}}
{"id": 345, "code": "result = np.cumsum(a[:,col]*multiply_number)", "metadata": {"problem_id": 345, "library_problem_id": 54, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 346, "code": "result = np.sum(a[row, :] * multiply_number)", "metadata": {"problem_id": 346, "library_problem_id": 55, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 347, "code": "result = np.where(row == 2, np.where(divide_number == 0, np.nan, np.divide(row, divide_number))))", "metadata": {"problem_id": 347, "library_problem_id": 56, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 54}}
{"id": 348, "code": "result = np.array([[1,0,0,0], [0,0,1,0], [0,1,1,0], [1,0,0,1]])\n", "metadata": {"problem_id": 348, "library_problem_id": 57, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 57}}
{"id": 349, "code": "result = a.shape[0]\n", "metadata": {"problem_id": 349, "library_problem_id": 58, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 58}}
{"id": 350, "code": "alpha = 0.05/2 # alpha is the significance level\nalpha_weight = alpha/2\n\n# calculate the mean and standard deviation\nmean_a = a.mean()\nstddev_a = a.std()\n\nmean_b = b.mean()\nstddev_b = b.std()\n\n# calculate the t-test\nt_statistic, p_value = scipy.stats.ttest_ind(a, b, equal=True)\n\n# calculate the weighted mean and standard deviation\nweight_mean = np.average(a, weights=np.power(stddev_a, -1))\nweight_stddev = npatar.average(stddev_a, weights=np.power(stddev_a, -1))\n\n# calculate the p-value\np_value = scipy.stats.t.pdf(weight_mean, weight_stddev)\n", "metadata": {"problem_id": 350, "library_problem_id": 59, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 59}}
{"id": 351, "code": "weighted_mean_a, weighted_stddev_a = np.nanmean(a, axis=0)*(1-np.nans(a))+np.nanstd(a, axis=0)*npataramanthropies.statistics.nans(a, axis=0)", "metadata": {"problem_id": 351, "library_problem_id": 60, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 59}}
{"id": 352, "code": "alpha = 0.05/2 # alpha/2 is the significance level\nt_statistic = (avar/anobs)**0.5 * ((bmean - amean)/(bvar/bnobs))**0.5\np_value = scipy.stats.ttest_ind(a=None, alternative='two-sided',\n                                compare_cols=True,\n                                trim_mean=True,\n                                data=[20, 20])\n", "metadata": {"problem_id": 352, "library_problem_id": 61, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 59}}
{"id": 353, "code": "import numpy as np\nA=np.asarray([[1,1,1], [1,1,2], [1,1,3], [1,1,4]])\nB=np.asarray([[0,0,0], [1,0,2], [1,0,3], [1,0,4], [1,1,0], [1,1,1], [1,1,4]])\n\nmask = np.not_equal(A, B)\noutput = A[mask]", "metadata": {"problem_id": 353, "library_problem_id": 62, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 62}}
{"id": 354, "code": "import numpy as np\nA=np.asarray([[1,1,1], [1,1,2], [1,1,3], [1,1,4]])\nB=np.asarray([[0,0,0], [1,0,2], [1,0,3], [1,0,4], [1,1,0], [1,1,1], [1,1,4]])\n\nA_flat = A.reshape(-1,A.shape[0]*A.shape[1]).T.reshape(-1,A.shape[1]).T\nB_flat = B.reshape(-1,B.shape[0]*B.shape[1]).T.reshape(-1,B.shape[1]).T\n\noutput = np.where(~np.isin((A_flat.T),(B_flat.T)).T,A.reshape(-1,A.shape[0]*A.shape[1]).T,np.array([[]])).T\n", "metadata": {"problem_id": 354, "library_problem_id": 63, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 62}}
{"id": 355, "code": "sort_indices = np.argsort(a, axis=0)[0]\nc = b[sort_indices]", "metadata": {"problem_id": 355, "library_problem_id": 64, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 64}}
{"id": 356, "code": "sort_indices = np.argsort(a, axis=0)[0]\nc = b[sort_indices]", "metadata": {"problem_id": 356, "library_problem_id": 65, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 64}}
{"id": 357, "code": "sort_indices = np.argsort(a, axis=0)[0]\nc = b[sort_indices]", "metadata": {"problem_id": 357, "library_problem_id": 66, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 64}}
{"id": 358, "code": "result = np.sort_values(b, axis=1)\n", "metadata": {"problem_id": 358, "library_problem_id": 67, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 64}}
{"id": 359, "code": "import numpy as np\narr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\narr = arr[:, :3]", "metadata": {"problem_id": 359, "library_problem_id": 68, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 68}}
{"id": 360, "code": "import numpy as np\narr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\narr = npMODem arr[1:]", "metadata": {"problem_id": 360, "library_problem_id": 69, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 68}}
{"id": 361, "code": "import numpy as np\narr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\narr = arr[:,:-2]\n", "metadata": {"problem_id": 361, "library_problem_id": 70, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 362, "code": "import numpy as np\n\na = np.arange(12).reshape(3, 4)\ndel_col = npatar([1, 2, 4, 5])\n\nresult = np.delete(a, del_col)\n", "metadata": {"problem_id": 362, "library_problem_id": 71, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 68}}
{"id": 363, "code": "a = np.insert(a,pos,element)\nprint(a)\n", "metadata": {"problem_id": 363, "library_problem_id": 72, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 72}}
{"id": 364, "code": "a[pos] = element", "metadata": {"problem_id": 364, "library_problem_id": 73, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 72}}
{"id": 365, "code": "\n    a = np.insert(a, pos, element)\n    ### END SOLUTION\n    return a\n", "metadata": {"problem_id": 365, "library_problem_id": 74, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 72}}
{"id": 366, "code": "a = np.insert(a, 1, pos, 0)\n", "metadata": {"problem_id": 366, "library_problem_id": 75, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 72}}
{"id": 367, "code": "import numpy as np\npairs = [(2, 3), (3, 4), (4, 5)]\narray_of_arrays = np.array([np.arange(a*b).reshape(a,b) for (a, b) in pairs])\nresult = np.array(array_of_arrays, dtype=object, copy=True)\n", "metadata": {"problem_id": 367, "library_problem_id": 76, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 76}}
{"id": 368, "code": "result = np.all(a == a[0])\n", "metadata": {"problem_id": 368, "library_problem_id": 77, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Origin", "perturbation_origin_id": 77}}
{"id": 369, "code": "np.all(a == a.T", "metadata": {"problem_id": 369, "library_problem_id": 78, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Semantic", "perturbation_origin_id": 77}}
{"id": 370, "code": "\n    np.all(a)\n    ### END SOLUTION\n", "metadata": {"problem_id": 370, "library_problem_id": 79, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Surface", "perturbation_origin_id": 77}}
{"id": 371, "code": "from scipy.integrate import simps\n\n# define your function\ndef f(x, y):\n    return (np.cos(x))**4 + (y**2)**2\n\n# define your grid\ngrid = np.array([[x_i, y_i] for x_i in x] for y_i in y)\n\n# compute integral\nresult, _ = simps(f(grid))\n", "metadata": {"problem_id": 371, "library_problem_id": 80, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 80}}
{"id": 372, "code": "\n    return (np.cos(x)**2 + np.sin(y)**2)**2\n    ### END SOLUTION\n\nintegral, error = np.trapz(f(example_x, example_y), dx=1/np.sqrt(2), dy=1/np.sqrt(2))\nprint(integral)\nprint(error)\n", "metadata": {"problem_id": 372, "library_problem_id": 81, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 80}}
{"id": 373, "code": "import numpy as np\ngrades = np.array([93.5,93,60.8,94.5,82,87.5,91.5,99.5,86,93.5,92.5,78,76,69,94.5,\n          89.5,92.8,78,65.5,98,98.5,92.3,95.5,76,91,95,61])\n\ndef ecdf(x):\n    return np.arange(len(x)) / np.sum(x)\n\nresult = ecdf(grades)\n", "metadata": {"problem_id": 373, "library_problem_id": 82, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 82}}
{"id": 374, "code": "result = np.empty(len(eval))\nfor i, e in enumerate(eval):\n    result[i] = ecdf(grades)[i]\n", "metadata": {"problem_id": 374, "library_problem_id": 83, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 82}}
{"id": 375, "code": "low = np.percentile(grades, 10)\nhigh = npatar(grades, 99)", "metadata": {"problem_id": 375, "library_problem_id": 84, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 82}}
{"id": 376, "code": "nums = np.random.randint(2, size=size, p1=one_ratio)", "metadata": {"problem_id": 376, "library_problem_id": 85, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 377, "code": "a_np = a.numpy()", "metadata": {"problem_id": 377, "library_problem_id": 86, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 86}}
{"id": 378, "code": "tensor = torch.from_numpy(a)", "metadata": {"problem_id": 378, "library_problem_id": 87, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 86}}
{"id": 379, "code": "a_np = a.numpy()", "metadata": {"problem_id": 379, "library_problem_id": 88, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 88}}
{"id": 380, "code": "a_tf = tf.convert_to_tensor(a)", "metadata": {"problem_id": 380, "library_problem_id": 89, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 88}}
{"id": 381, "code": "result = np.argsort(-a)\n", "metadata": {"problem_id": 381, "library_problem_id": 90, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 90}}
{"id": 382, "code": "result = np.argsort(a) + 1", "metadata": {"problem_id": 382, "library_problem_id": 91, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 90}}
{"id": 383, "code": "import numpy as np\na = np.array([4, 1, 0, 8, 5, 2])\nN = 3\nresult = np.argsort(-a)[:N]\n", "metadata": {"problem_id": 383, "library_problem_id": 92, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 90}}
{"id": 384, "code": "result = np.where(A.any(), np.power(A, n))", "metadata": {"problem_id": 384, "library_problem_id": 93, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 93}}
{"id": 385, "code": "result = np.array([[[a[i:i+2,j:j+2] for i in range(0, len(a)-2, 2)] for j in range(0, len(a)-2, 2)] for i in range(0, len(a)-2, 2)] for i in range(0, len(a)-2, 2)]\n", "metadata": {"problem_id": 385, "library_problem_id": 94, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 94}}
{"id": 386, "code": "import numpy as np\na = np.array([[1,5,9,13],\n              [2,6,10,14],\n              [3,7,11,15],\n              [4,8,12,16]])\n\npatches = []\nfor i in range(0, len(a), 2):\n    for j in range(0, len(a), 2):\n        patch = a[i:i+2, j:j+2]\n        patches.append(patch)\n", "metadata": {"problem_id": 386, "library_problem_id": 95, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 94}}
{"id": 387, "code": "result = np.array([[[a[i:i+2,j:j+2] for i in range(6-2+1,step=2)] for j in range(8-2+1,step=2)] for i in range(6-2+1,step=2)] for step in range(6-2+1,step=2)]\n", "metadata": {"problem_id": 387, "library_problem_id": 96, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 94}}
{"id": 388, "code": "patch_size = 2\npatch_count = (a.shape[0] - patch_size) // patch_size + 1\nresult = np.split(a,patch_count,axis=0)\nresult = result.reshape(*result.shape[1:],-1,patch_size,patch_size).reshape(*result.shape, -1, patch_size, patch_size)\n", "metadata": {"problem_id": 388, "library_problem_id": 97, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 94}}
{"id": 389, "code": "result = np.zeros((h,w)).flatten()\n", "metadata": {"problem_id": 389, "library_problem_id": 98, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 94}}
{"id": 390, "code": "patch_size = 2\npatch_count = (a.shape[0] - patch_size) // patch_size + 1\nresult = np.split(a,patch_count,axis=0)\nresult = result.reshape(*result.shape[1:],-1,patch_size,patch_size).reshape(*result.shape, -1, patch_size, patch_size)\n", "metadata": {"problem_id": 390, "library_problem_id": 99, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 94}}
{"id": 391, "code": "result = a[:,low:high+1]\n", "metadata": {"problem_id": 391, "library_problem_id": 100, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 100}}
{"id": 392, "code": "result = a[low:high+1,...]\n", "metadata": {"problem_id": 392, "library_problem_id": 101, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 100}}
{"id": 393, "code": "result = a[:,low:high+1]\n", "metadata": {"problem_id": 393, "library_problem_id": 102, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 100}}
{"id": 394, "code": "data = np.array([[0.5544, 0.4456], [0.8811, 0.1189]])\n", "metadata": {"problem_id": 394, "library_problem_id": 103, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 103}}
{"id": 395, "code": "result = np.random.uniform(min, max, n)", "metadata": {"problem_id": 395, "library_problem_id": 104, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 104}}
{"id": 396, "code": "result = np.random.uniform(min, max, n)", "metadata": {"problem_id": 396, "library_problem_id": 105, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 104}}
{"id": 397, "code": "\n    result = np.random.uniform(low=np.log(min), high=npataram(min, max), size=n)\n    ### END SOLUTION\n    return result\n", "metadata": {"problem_id": 397, "library_problem_id": 106, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 104}}
{"id": 398, "code": "def recursive_computation(series):\n    series_length = len(series)\n    series_dtype = series.dtype\n    series_shape = series.shape\n    B = pd.Series(dtype=series_dtype, index=series.index)\n    for t in range(series_length):\n        B[t] = a * series[t] + b * series[t-1] if t > 0 else a * series[t]\n    return B\n\nB = recursive_computation(A)\nEND SOLUTION\n", "metadata": {"problem_id": 398, "library_problem_id": 107, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 107}}
{"id": 399, "code": "def recursive_computation(series):\n    series_B = pd.Series(dtype=float, index=range(1,len(series)))\n    series_B[0] = a*series[0]\n    series_B[1] = a*series[1] + b*series_B[0]\n    for i in range(2,len(series)):\n        series_B[i] = a*series[i] + b*series_B[i-1] + c*series_B[i-2]\n    return series_B\n", "metadata": {"problem_id": 399, "library_problem_id": 108, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 107}}
{"id": 400, "code": "result = np.array([])\n", "metadata": {"problem_id": 400, "library_problem_id": 109, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 109}}
{"id": 401, "code": "result = np.empty((3,0))", "metadata": {"problem_id": 401, "library_problem_id": 110, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 109}}
{"id": 402, "code": "result = np.unra1ify(a, index)", "metadata": {"problem_id": 402, "library_problem_id": 111, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 111}}
{"id": 403, "code": "result = np.sub2ind(*dims, *index)", "metadata": {"problem_id": 403, "library_problem_id": 112, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 111}}
{"id": 404, "code": "values = np.zeros((2,3))\ndf = pd.DataFrame(values, index=index, columns=columns)\nEND SOLUTION\ndf\nEND SOLUTION\nvalues\nEND SOLUTION\nvalues2 = np.array([[0,0,0],[0,0,0]])\ndf2 = pd.DataFrame(values2, index=index, columns=columns)\nEND SOLUTION\ndf2\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\nEND SOLUTION\n", "metadata": {"problem_id": 404, "library_problem_id": 113, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 113}}
{"id": 405, "code": "result = np.where(accmap==0, 0, a)\nresult = np.where(accmap==1, result, 0)\nresult = npatar(accmap==2, result, 0)\nresult = np.where(accmap==3, result, 0)\nresult = np.where(accmap==4, result, 0)\nresult = np.where(accmap==5, result, 0)\nresult = np.where(accmup==6, result, 0)\nresult = np.where(accmap==7, result, 0)\nresult = np.where(accmap==8, result, 0)\nresult = np.where(accmap==9, result, 0)\nresult = np.where(accmap==10, result, 0)\n", "metadata": {"problem_id": 405, "library_problem_id": 114, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 114}}
{"id": 406, "code": "result = np.maximum.reduce(a,axis=index)\n", "metadata": {"problem_id": 406, "library_problem_id": 115, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 114}}
{"id": 407, "code": "result = np.sum(a[accmap != -1])\n", "metadata": {"problem_id": 407, "library_problem_id": 116, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 114}}
{"id": 408, "code": "result = np.minimum.reduce(a,axis=index)\n", "metadata": {"problem_id": 408, "library_problem_id": 117, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 114}}
{"id": 409, "code": "z = np.vectorize(elementwise_function)(x,y)\n", "metadata": {"problem_id": 409, "library_problem_id": 118, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 118}}
{"id": 410, "code": "result = np.random.choice(lista_elegir, samples, p=probabilit, replace=False)\nEND SOLUTION\n", "metadata": {"problem_id": 410, "library_problem_id": 119, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 119}}
{"id": 411, "code": "a = np.pad(a, ((0, 1), (low_index, high_index)), 'constant', constant_values=0)\nresult = a[low_index:high_index, low_index:highatarach!", "metadata": {"problem_id": 411, "library_problem_id": 120, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 120}}
{"id": 412, "code": "import numpy as np\nx = np.array([-2, -1.4, -1.1, 0, 1.2, 2.2, 3.1, 4.4, 8.3, 9.9, 10, 14, 16.2])\nx = x[x >= 0]\n", "metadata": {"problem_id": 412, "library_problem_id": 121, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 121}}
{"id": 413, "code": "import numpy as np\nx = np.array([-2+1j, -1.4, -1.1, 0, 1.2, 2.2+2j, 3.1, 4.4, 8.3, 9.9, 10+0j, 14, 16.2])\nmask = np.abs(x) > 1\nresult = x[~mask]\n", "metadata": {"problem_id": 413, "library_problem_id": 122, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 414, "code": "import numpy as np\ndata = np.array([4, 2, 5, 6, 7, 5, 4, 3, 5, 7])\nbin_size = 3\nbins = np.array_split(data, np.arange(len(data) // bin_size))\nbin_data_mean = [np.mean(bin) for bin in bins]\n", "metadata": {"problem_id": 414, "library_problem_id": 123, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 123}}
{"id": 415, "code": "import numpy as np\ndata = np.array([4, 2, 5, 6, 7, 5, 4, 3, 5, 7])\nbin_size = 3\n\nbin_data_max = np.maximum.reduce(data.reshape(-1, bin_size), axis=0)\n", "metadata": {"problem_id": 415, "library_problem_id": 124, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 123}}
{"id": 416, "code": "def solve(data, bin_size):\n    bin_data_mean = []\n    for i in range(0, len(data), bin_size):\n        mean = data[i].mean()\n        bin_data_mean.append(mean)\n    return bin_data_mean\n", "metadata": {"problem_id": 416, "library_problem_id": 125, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 123}}
{"id": 417, "code": "def solve(data, bin_size):\n    bin_data_mean = []\n    for i in range(len(data)-bin_size+1):\n        mean = np.mean(data[i:i+bin_size])\n        bin_data_mean.append(mean)\n    return bin_data_mean\n\nbin_size = 3\nprint(solve(data, bin_size))\n", "metadata": {"problem_id": 417, "library_problem_id": 126, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 123}}
{"id": 418, "code": "def bin_data(data, bin_size):\n    bin_data_mean = []\n    for i in range(len(data)-bin_size+1):\n        mean = data[i:i+bin_size].mean()\n        bin_data_mean.append(mean)\n    return bin_data_mean\n", "metadata": {"problem_id": 418, "library_problem_id": 127, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 123}}
{"id": 419, "code": "def solve(data, bin_size):\n    bin_data = []\n    bin_data_mean = []\n    for i in range(len(data)-bin_size+1):\n        bin_data.append([data[i:i+bin_size]])\n        bin_data_mean.append(sum(data[i:i+binatarolength])/len(data[i:i+binatarolength]))\n    return bin_data, bin_data_mean\n", "metadata": {"problem_id": 419, "library_problem_id": 128, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 123}}
{"id": 420, "code": "\ndef smoothclamp(x, x_min, x_max):\n    if x < x_min:\n        return x_min\n    elif x > x_max:\n        return x_max\n    else:\n        return x<2x**2 - 3x**3\n", "metadata": {"problem_id": 420, "library_problem_id": 129, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 129}}
{"id": 421, "code": "\ndef smoothclamp(x, x_min, x_max, N):\n    if x < x_min:\n        return x_min\n    elif x > x_max:\n        return x_max\n    else:\n        return x\n    return x\n", "metadata": {"problem_id": 421, "library_problem_id": 130, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 129}}
{"id": 422, "code": "result = np.correlate(a, b, mode='full')", "metadata": {"problem_id": 422, "library_problem_id": 131, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 131}}
{"id": 423, "code": "df = df.groupby(['major']).apply(lambda x: x.values.reshape(-1,1,5))\nresult = df.compute()", "metadata": {"problem_id": 423, "library_problem_id": 132, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 132}}
{"id": 424, "code": "df = df.set_index(['major']).unstack(level=-1).groupby(list(names)).apply(lambda x: x.values.reshape(-1,*x.shape[1:],5))\nresult = df.values\n", "metadata": {"problem_id": 424, "library_problem_id": 133, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 132}}
{"id": 425, "code": "result = np.unpackbits(np.uint8(a))\nresult = npMOD(result, 2**m)", "metadata": {"problem_id": 425, "library_problem_id": 134, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 134}}
{"id": 426, "code": "result = np.unpackbits(np.uint8(a))\nresult = npMOD(result, 2**m)", "metadata": {"problem_id": 426, "library_problem_id": 135, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 134}}
{"id": 427, "code": "result = np.unpackbits(np.uint8(a)) & ~(2**m.reshape(-1,1))", "metadata": {"problem_id": 427, "library_problem_id": 136, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 134}}
{"id": 428, "code": "import numpy as np\na = np.array([0, 1, 2, 5, 6, 7, 8, 8, 8, 10, 29, 32, 45])\nmu = np.mean(a)\nstd = np.std(a)\nresult = (mu - 3*std, mu + 3*std)\n", "metadata": {"problem_id": 428, "library_problem_id": 137, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 137}}
{"id": 429, "code": "import numpy as np\na = np.array([0, 1, 2, 5, 6, 7, 8, 8, 8, 10, 29, 32, 45])\nmu = np.mean(a)\nsigma = np.std(a)\nresult = (mu - 2*sigma, mu + 2*sigma)\n", "metadata": {"problem_id": 429, "library_problem_id": 138, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 137}}
{"id": 430, "code": "\n    mu = np.mean(a)\n    sigma = np.[\u03c3]\n    third_std_start = mu - 3*sigma\n    third_std_end = mu + 3*sigma\n    return third_std_start,third_std_end\n    ### END SOLUTION\nresult = f(example_a)\nprint(result)\n", "metadata": {"problem_id": 430, "library_problem_id": 139, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 137}}
{"id": 431, "code": "import numpy as np\na = npdataset = np.array([0, 1, 2, 5, 6, 7, 8, 8, 8, 10, 29, 32, 45])\nmean = npdataset.mean()\nstd = npdataset.std()\nresult = np.where(npdataset - mean > 2*std, True, False)\n", "metadata": {"problem_id": 431, "library_problem_id": 140, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 137}}
{"id": 432, "code": "import numpy as np\nDataArray = np.arange(-5.5, 10.5)\npercentile = 50\nmasked_data = np.ma.masked_where(DataArray < 0, DataArray)\nprob = np.percentile(masked_data, percentile)\nprint(prob)\nEND SOLUTION\n\nIn the solution, you are using numpy's percentile function to calculate the 50th percentile of the array where the array is not negative. However, the numpy percentile function does not exclude the values that are lower than the specified percentile.\n", "metadata": {"problem_id": 432, "library_problem_id": 141, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 141}}
{"id": 433, "code": "a[zero_rows, :] = 0\na[:, zero_cols] = 0\n", "metadata": {"problem_id": 433, "library_problem_id": 142, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 142}}
{"id": 434, "code": "a[zero_rows, :] = 0\na[:, zero_cols] = 0\n", "metadata": {"problem_id": 434, "library_problem_id": 143, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 142}}
{"id": 435, "code": "import numpy as np\na = npMODified = np.where(a == 0, '0', a)\n", "metadata": {"problem_id": 435, "library_problem_id": 144, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 142}}
{"id": 436, "code": "mask = np.isinvolve(a, np.amax(a, axis=1))\n", "metadata": {"problem_id": 436, "library_problem_id": 145, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 145}}
{"id": 437, "code": "mask = np.is_equal(a, a.min(axis=1))", "metadata": {"problem_id": 437, "library_problem_id": 146, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 145}}
{"id": 438, "code": "from scipy.stats import pearsonr\ncorr, _ = pearsonr(post, distance)\nresult = corr", "metadata": {"problem_id": 438, "library_problem_id": 147, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 147}}
{"id": 439, "code": "result = np.einsum('ij...->ab', X)\n", "metadata": {"problem_id": 439, "library_problem_id": 148, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 148}}
{"id": 440, "code": "X = np.dot(Y.transpose(), Y)\n", "metadata": {"problem_id": 440, "library_problem_id": 149, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 148}}
{"id": 441, "code": "is_contained = number in a\n", "metadata": {"problem_id": 441, "library_problem_id": 150, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 150}}
{"id": 442, "code": "A = np.setdiff1d(A, B)\n", "metadata": {"problem_id": 442, "library_problem_id": 151, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 151}}
{"id": 443, "code": "A = np.set_diff1d(A, B)\n", "metadata": {"problem_id": 443, "library_problem_id": 152, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 151}}
{"id": 444, "code": "C = np.where(np.isin(A, B))\n", "metadata": {"problem_id": 444, "library_problem_id": 153, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 151}}
{"id": 445, "code": "result = -rankdata(a).astype(int) - 1", "metadata": {"problem_id": 445, "library_problem_id": 154, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 154}}
{"id": 446, "code": "result = rankdata(a)[::-1]\n", "metadata": {"problem_id": 446, "library_problem_id": 155, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 154}}
{"id": 447, "code": "\n    result = -1 - a\n    ### END SOLUTION\nresult\n", "metadata": {"problem_id": 447, "library_problem_id": 156, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 154}}
{"id": 448, "code": "dists = np.dstack(x_dists)[...,:-1] + np.dstack(y_dists)[...,-1]", "metadata": {"problem_id": 448, "library_problem_id": 157, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 157}}
{"id": 449, "code": "dists = np.dstack(x_dists)[...,:-1] + np.dstack(y_dists)[...,-1]", "metadata": {"problem_id": 449, "library_problem_id": 158, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 157}}
{"id": 450, "code": "result = a[...,second,third]", "metadata": {"problem_id": 450, "library_problem_id": 159, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 159}}
{"id": 451, "code": "arr = np.zeros((20,10,10,2))", "metadata": {"problem_id": 451, "library_problem_id": 160, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 160}}
{"id": 452, "code": "from numpy import linalg as LA\nimport numpy as np\nX = np.array([[1, -2, 3, 6],\n              [4, 5, -6, 5],\n              [-1, 2, 5, 5],\n              [4, 5,10,-25],\n              [5, -2,10,25]])\nl1 = np.sum(np.abs(X),axis=1)\nprint l1\n", "metadata": {"problem_id": 452, "library_problem_id": 161, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 161}}
{"id": 453, "code": "from numpy import linalg as LA\nimport numpy as np\nX = np.array([[1, -2, 3, 6],\n              [4, 5, -6, 5],\n              [-1, 2, 5, 5],\n              [4, 5,10,-25],\n              [5, -2,10,25]])\n\nl2_norm = np.linalg.norm(X, ord=2, axis=1)\nresult = X / l2_norm[:,None]\n", "metadata": {"problem_id": 453, "library_problem_id": 162, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 161}}
{"id": 454, "code": "from numpy import linalg as LA\nimport numpy as np\nX = np.array([[1, -2, 3, 6],\n              [4, 5, -6, 5],\n              [-1, 2, 5, 5],\n              [4, 5,10,-25],\n              [5, -2,10,25]])\n\nnorms = np.linalg.norm(X, ord=np.inf, axis=1)\nresult = np.array([[1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1],\n                   [1, 1, 1, 1, 1]])\n", "metadata": {"problem_id": 454, "library_problem_id": 163, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 161}}
{"id": 455, "code": "conditions  = [(col.endswith(target+'|') for col in df['a'])]\nchoices     = ['XX']\nresult = np.select(conditions, choices, default='other')\n", "metadata": {"problem_id": 455, "library_problem_id": 164, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 164}}
{"id": 456, "code": "from scipy.spatial import distance_matrix\nresult = distance_matrix(a, a)\n", "metadata": {"problem_id": 456, "library_problem_id": 165, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 165}}
{"id": 457, "code": "from scipy.spatial import distance_matrix\nresult = distance_matrix(a, a)\n", "metadata": {"problem_id": 457, "library_problem_id": 166, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 165}}
{"id": 458, "code": "from scipy.spatial import distance_matrix\nresult = distance_matrix(a, a)\nEND SOLUTION\n\nIn the above code, you can use the `distance_matrix` function from the `scipy.spatial` module to calculate the distance between all points in your dataset. The `distance_matrix` function calculates the Euclidean distance between all points in your dataset.\n", "metadata": {"problem_id": 458, "library_problem_id": 167, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 165}}
{"id": 459, "code": "AVG = np.mean(NA, axis=0)\nprint(AVG)\n", "metadata": {"problem_id": 459, "library_problem_id": 168, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 168}}
{"id": 460, "code": "AVG = np.mean(NA, axis=0)\nprint(AVG)\n", "metadata": {"problem_id": 460, "library_problem_id": 169, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 168}}
{"id": 461, "code": "import numpy as np\nA = ['np.inf', '33.33', '33.33', '33.37']\nNA = np.asarray(A)\nAVG = np.mean(NA, axis=0)\nprint(AVG)\n", "metadata": {"problem_id": 461, "library_problem_id": 170, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 168}}
{"id": 462, "code": "import numpy as np\na = np.array([0, 0, 1, 1, 1, 2, 2, 0, 1, 3, 3, 3])\nunique_nonzero_values = np.where(a>0, np.where(~(a>0).any(), np.delete(a, np.argwhere(~(a>0).any())), np.where(~(a>0).any())))\nresult = unique_nonzero_values\n", "metadata": {"problem_id": 462, "library_problem_id": 171, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 171}}
{"id": 463, "code": "import numpy as np\na = np.array([0, 0, 1, 1, 1, 2, 2, 0, 1, 3, 3, 3]).reshape(-1, 1)\nresult = np.delete(a, np.where(a==0)[0]+1,axis=0)\n", "metadata": {"problem_id": 463, "library_problem_id": 172, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 171}}
{"id": 464, "code": "df = pd.DataFrame(np.transpose(np.dstack([lat, lon, val]),axis=1),columns=['lat','lon','val'])\n", "metadata": {"problem_id": 464, "library_problem_id": 173, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 173}}
{"id": 465, "code": "\n    df = pd.DataFrame(lat, columns=['lat', 'lon', 'val'])\n    df['lat'] = lat\n    df['val'] = val\n    df['lon'] = lon\n    df.sort_values(['lat', 'lon', 'val'}, inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'}, inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'}, inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=True, inplace=True)\n    df.sort_values(['lat', 'lon', 'val'], inplace=True)\n    df.reset_index(drop=", "metadata": {"problem_id": 465, "library_problem_id": 174, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 173}}
{"id": 466, "code": "maximum = np.maximum.from([lat, lon, val], along=range(lat.shape[0]), axis=0)\ndf = pd.DataFrame(np.dstack([lat, lon, val]), columns=['lat', 'lon', 'val', 'maximum'])", "metadata": {"problem_id": 466, "library_problem_id": 175, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 173}}
{"id": 467, "code": "result = np.array([np.array([np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n    np.sum(a[i:i+2,j:j+2]**where you want to slide the window**:\n        np.sum(a[i:i+3,j:j+3]**where you want to slide the window**:\n            npjorocolist(a[i:i+1,j:j+1]**where you want to slide the window**:\n                np.columlist(a[i:i+1,j:j+1]**where you want to slide the window**:\n                    np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                        np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                            np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                    np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                        np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                            np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                    np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                        np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                            np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                    np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                        np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                            np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                    np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                        np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                            np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                    np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                        np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                            np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                        np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                            np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                        np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                            np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                        np.sum(a[i:i+1,j:j+1]**where you want to slide the window**:\n                                                                                                           ", "metadata": {"problem_id": 467, "library_problem_id": 176, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 176}}
{"id": 468, "code": "result = np.array([np.array([np.sum(a[i:i+1,j:j+1]**where to include the window in the summation**) for i in range(1,2,delta x): for j in range(1,2,delta y):])) for _ in range(1,2,delta x): for _ in range(1,2,delta y):", "metadata": {"problem_id": 468, "library_problem_id": 177, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 176}}
{"id": 469, "code": "import numpy as np\na = np.array([1 + 0j, 2 + 0j, npatarian + 0j])\n", "metadata": {"problem_id": 469, "library_problem_id": 178, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 178}}
{"id": 470, "code": "\n    np.mean(a)\nEndcode\n\nIn the above code, the mean of the array is calculated without any problem. However, the imaginary part of the result is not zero. It seems to be a warning that the division by zero is undefined.\n\nI'm not sure why it is happening. Could you help me understand why it is happening?\n", "metadata": {"problem_id": 470, "library_problem_id": 179, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 178}}
{"id": 471, "code": "Z = np.array([[[1, 2, 3], [4, 5, 6]],\n[[7, 8, 9], [10, 11, 12]]])\nresult = Z[:2, :, 1:]\n", "metadata": {"problem_id": 471, "library_problem_id": 180, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 180}}
{"id": 472, "code": "result = a[-1, :, :]\n", "metadata": {"problem_id": 472, "library_problem_id": 181, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 180}}
{"id": 473, "code": "result = any(np.all(c == x, axis=None) for x in CNTS)\n", "metadata": {"problem_id": 473, "library_problem_id": 182, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 182}}
{"id": 474, "code": "result = np.any(CNTS == c, axis=1)\n", "metadata": {"problem_id": 474, "library_problem_id": 183, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 182}}
{"id": 475, "code": "result = intp.interp2d(x_new, y_new, a, kind='linear')", "metadata": {"problem_id": 475, "library_problem_id": 184, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 184}}
{"id": 476, "code": "df['Q_cum'] = df.groupby('D').Q.cumsum().reset_index()", "metadata": {"problem_id": 476, "library_problem_id": 185, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 185}}
{"id": 477, "code": "i = np.array([12.22151125, 4.92815942, 2.06380839, 0.29766152])\ni = np.diag(i)\n", "metadata": {"problem_id": 477, "library_problem_id": 186, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 186}}
{"id": 478, "code": "a[a>0.5] = 0\n", "metadata": {"problem_id": 478, "library_problem_id": 187, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 187}}
{"id": 479, "code": "start_time = pd.to_datetime(start)\nend_time = pd.to_datetime(end)\ndt = (end_time - start_time).seconds / n\nresult = pd.date_range(start_time, end_time, freq='S', periods=n)\n", "metadata": {"problem_id": 479, "library_problem_id": 188, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 188}}
{"id": 480, "code": "result = np.where(x==a, np.where(y==b, np.next(np.where(x==a)[-1]), -1), -1)\n", "metadata": {"problem_id": 480, "library_problem_id": 189, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 189}}
{"id": 481, "code": "result = np.where(x==a)&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a))&(~(x==a", "metadata": {"problem_id": 481, "library_problem_id": 190, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 189}}
{"id": 482, "code": "from scipy.optimize import minimize\nresult = minimize(f, x, y)\na = result.x[0]\nb = result.x[1]\nc = result.x[2]\n", "metadata": {"problem_id": 482, "library_problem_id": 191, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 191}}
{"id": 483, "code": "coefficients = np.polyfit(x, y, degree)\nresult = coefficients[::-1]", "metadata": {"problem_id": 483, "library_problem_id": 192, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 191}}
{"id": 484, "code": "temp_arr = [0,1,2,3]\ndf = df.apply(lambda x: [x[i] - temp_arr[i] for i in range(len(temp_arr))], axis=0)\n", "metadata": {"problem_id": 484, "library_problem_id": 193, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 193}}
{"id": 485, "code": "result = np.einsum('ijk,ik->ij', A, B)\n", "metadata": {"problem_id": 485, "library_problem_id": 194, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 194}}
{"id": 486, "code": "scalar = MinMaxScaler()\nresult = scalar.fit_transform(a)\n", "metadata": {"problem_id": 486, "library_problem_id": 195, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 195}}
{"id": 487, "code": "from sklearn.preprocessing import MinMaxScaler\nresult = MinMaxScaler().fit(arr.reshape(-1,1)).transform(arr.reshape(-1,1))", "metadata": {"problem_id": 487, "library_problem_id": 196, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 195}}
{"id": 488, "code": "scalar = MinMaxScaler()\nresult = np.apply_patches(scalar.fit_transform(a.shape), size=1, hapjan_edge_size=3)", "metadata": {"problem_id": 488, "library_problem_id": 197, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 195}}
{"id": 489, "code": "arr_temp = arr.copy()\nmask = arr_temp < 15\narr[mask] = 30\narr[arr_temp>=15] = 0", "metadata": {"problem_id": 489, "library_problem_id": 198, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 198}}
{"id": 490, "code": "arr_temp = arr.copy()\nmask = arr_temp < n1\nmask2 = arr_temp >= n2\nmask3 = np.invert(mask2)\narr[mask] = 0\narr[mask3] = arr[mask3] + 5", "metadata": {"problem_id": 490, "library_problem_id": 199, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 198}}
{"id": 491, "code": "result = np.sum(np.abs(s1 - s2))\n", "metadata": {"problem_id": 491, "library_problem_id": 200, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 200}}
{"id": 492, "code": "result = np.sum(np.abs(s1 - s2) != 0)\n", "metadata": {"problem_id": 492, "library_problem_id": 201, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 200}}
{"id": 493, "code": "result = all(a[0] == a)\n", "metadata": {"problem_id": 493, "library_problem_id": 202, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Origin", "perturbation_origin_id": 202}}
{"id": 494, "code": "result = all(array.std()>0 for array in a)\n", "metadata": {"problem_id": 494, "library_problem_id": 203, "library": "Numpy", "test_case_cnt": 5, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 202}}
{"id": 495, "code": "import numpy as np\n\ndef zpad(arr, shape):\n    return np.pad(arr, ((0, shape[0]-arr.shape[0]), (0, shape[1]-arr.shape[1])), 'constant', constant_values=0)\n\nresult = zpad(a, shape)\n", "metadata": {"problem_id": 495, "library_problem_id": 204, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 204}}
{"id": 496, "code": "import numpy as np\n\ndef zpad(arr, shape):\n    return np.pad(arr, ((0,1),(0,1)), 'constant')\n\nresult = zpad(a, shape)\n", "metadata": {"problem_id": 496, "library_problem_id": 205, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Surface", "perturbation_origin_id": 204}}
{"id": 497, "code": "import numpy as np\n\n# Define shape and element\nshape = (93, 13)\nelement = 5\n\n# Calculate padding dimensions\npad_top = shape[0] - 1\npad_left = shape[1] - 1\n\n# Pad arrays\na = np.pad(a, ((pad_top, 0), (pad_left, 0)), 'constant', constant_values=element)\n", "metadata": {"problem_id": 497, "library_problem_id": 206, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Semantic", "perturbation_origin_id": 204}}
{"id": 498, "code": "\n    arr = np.pad(arr, ((0,1), (0,1)), 'constant')\n    ### END SOLUTION\nresult = f(arr, shape=(93,13))\nprint(result.shape)\n", "metadata": {"problem_id": 498, "library_problem_id": 207, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 204}}
{"id": 499, "code": "import numpy as np\n\ndef zpad(arr, shape):\n    h, w = shape\n    arr = np.pad(arr, ((0, w - 1), (0, h - 1)), 'constant', constant_values=0)\n    return arr\n\na = np.ones((41, 12))\nresult = zpad(a, shape)\n", "metadata": {"problem_id": 499, "library_problem_id": 208, "library": "Numpy", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 204}}
{"id": 500, "code": "a = np.arange(12).reshape(3,-1)", "metadata": {"problem_id": 500, "library_problem_id": 209, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 209}}
{"id": 501, "code": "result = a[...,b[...,0,0],b[...,0,1],b[...,1,0]]", "metadata": {"problem_id": 501, "library_problem_id": 210, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 210}}
{"id": 502, "code": "result = a[np.arange(a.shape[0]), np.arange(a.shape[1]), np.arange(a.shape[2])]", "metadata": {"problem_id": 502, "library_problem_id": 211, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 210}}
{"id": 503, "code": "result = a[...,b[...,0]]", "metadata": {"problem_id": 503, "library_problem_id": 212, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 210}}
{"id": 504, "code": "result = np.sum(a[...,1]**where b[...,0]", "metadata": {"problem_id": 504, "library_problem_id": 213, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 210}}
{"id": 505, "code": "import numpy as np\na = np.array([\n    [[ 0,  1, 2, 3],\n     [ 2,  3, 4, 5],\n     [ 4,  5, 6, 7]],\n    [[ 6,  7, 8, 9],\n     [ 8,  9, 10, 11],\n     [10, 11, 12, 13]],\n    [[12, 13, 14, 15],\n     [14, 15, 16, 17],\n     [16, 17, 18, 19]]]\n)\nb = np.array([\n    [0, 1, 2],\n    [2, 1, 3],\n    [1, 0, 3]\n])\nresult = np.sum(a[...,1]**b[...,0]) / (np.sum(b[...,0]**2)**0.5)\nEND SOLUTION\n", "metadata": {"problem_id": 505, "library_problem_id": 214, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 210}}
{"id": 506, "code": "import numpy as np\nimport pandas as pd\ndata = {'a': [1, 2, 3, 4, 5], 'b': [2, -6, 0, -4, 100]}\ndf = pd.DataFrame(data)\n\ndf['c'] = df['a'].where(df['a'].between(1, 4), np.nan)\nresult = df['b'].values\nprint(result)\nEND SOLUTION\n\nI have the following text output, my goal is to only select values of column b when the values in column a are greater than 1 but less than or equal to 4, and pad others with NaN. So I am looking for Python to print out Column b values as [NaN, -6,0,-4, NaN] because only these values meet the criteria of column a.\n", "metadata": {"problem_id": 506, "library_problem_id": 215, "library": "Numpy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 215}}
{"id": 507, "code": "import numpy as np\nim = np.[[0,0,0,0,0,0],\n       [0,0,1,1,1,0],\n       [0,1,1,0,1,0],\n       [0,0,0,1,1,0],\n       [0,0,0,0,0,0]]\nresult = ... # put solution in this variable\nEND SOLUTION\nim[im.shape[0] - 1:,1:]\nim[1:,:-1]\nim[1:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]\nim[2:,:-1]\nim[0,:-2]\nim[2:,1:]", "metadata": {"problem_id": 507, "library_problem_id": 216, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 216}}
{"id": 508, "code": "import matplotlib.py as plt\nresult,colums = np.where(A>0)\nplt.imshow(result)\n", "metadata": {"problem_id": 508, "library_problem_id": 217, "library": "Numpy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 216}}
{"id": 509, "code": "import numpy as np\nim = npior.array([[1,1,1,1,1,5],\n               [1,0,0,1,2,0],\n               [2,1,0,0,1,0],\n               [1,0,0,7,1,0],\n               [1,0,0,0,0,0]])\nresult = im.copy()\nresult[np.where(im.sum(axis=1)==0)] = 0\nresult = np.where(im.sum(axis=0)==0,axis=1,result)\nresult\n", "metadata": {"problem_id": 509, "library_problem_id": 218, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 216}}
{"id": 510, "code": "mask = np.where(im.sum(axis=1) > 0, np.where(im.sum(axis=0) > 0, np.where(im.sum() > 0.5), 0)\n", "metadata": {"problem_id": 510, "library_problem_id": 219, "library": "Numpy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 216}}
{"id": 511, "code": "\nplt.figure(figsize=(10, 6))\npltatarange=(0,10)\nplt.plot(x, y, label='x-y')\nplt.legend()\nplt.show()\n\n", "metadata": {"problem_id": 511, "library_problem_id": 0, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 512, "code": "plt.gca().get_yaxis().grid(minor=True)\nplt.show()\n", "metadata": {"problem_id": 512, "library_problem_id": 1, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 1}}
{"id": 513, "code": "plt.minortextsize(x, y)\nplt.show()\n", "metadata": {"problem_id": 513, "library_problem_id": 2, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 1}}
{"id": 514, "code": "plt.tick_params(axis='x',which='minor',linestyle=':')\npltthis = plt\nplt.show()\n", "metadata": {"problem_id": 514, "library_problem_id": 3, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 1}}
{"id": 515, "code": "\n# create a dataframe\ndf = pddat.DataFrame(x, y=np.random.randint(10,100,10))\n\n# plot the dataframe\ndf.plot(x='x', y='y', kind='line', linewidth=5,label='line')\npltthis\n\n# END SOLUTION\n\nplt.show()\n\n", "metadata": {"problem_id": 515, "library_problem_id": 4, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 4}}
{"id": 516, "code": "\n# create a dataframe\ndf = pddat.DataFrame(x, y=np.random.randint(10,100,10))\n\n# plot the dataframe\ndf.plot(x='x', y='y', kind='line', linewidth=5,label='line')\npltthis\n\n# END SOLUTION\n\nplt.show()\n\n", "metadata": {"problem_id": 516, "library_problem_id": 5, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 517, "code": "plt.plot(x, y, 'rd')\nplt.show()\n", "metadata": {"problem_id": 517, "library_problem_id": 6, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 518, "code": "plt.plot(x, y, 'kd', label='line')\nplt.legend(['line'], loc='upper left', shadow=True, fancy=False)\nplt.show()\n", "metadata": {"problem_id": 518, "library_problem_id": 7, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 519, "code": "ax.set_ylim(0,40)\n", "metadata": {"problem_id": 519, "library_problem_id": 8, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 8}}
{"id": 520, "code": "x[2] = 2\nx[3] = 4\nx[4] = 6\nx[5] = 8\nx[6] = 7\nx[9] = 10\n\npltatarange = [2, 4, 6, 8, 7, 10]\nplt.plot(x)\nplt.show()\n# END SOLUTION\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx[5:7] = 4\nx[8:10] = 6\nx[11] = 8\n\nplt.plot(x)\nplt.show()\n\n# highlight in red the x range 2 to 4\nx[2:4] = 2\nx", "metadata": {"problem_id": 520, "library_problem_id": 9, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 521, "code": "x = np.linspace(0,1,100)\ny = npataramonic.interpolate(x,solution.values())\nplt.plot(x,y)\nplt.show()\n", "metadata": {"problem_id": 521, "library_problem_id": 10, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 10}}
{"id": 522, "code": "x = np.array([0,1,1,2])\ny = npatar.array([0,1,2,4])\nplt.plot(x,y)\nplt.show()\n", "metadata": {"problem_id": 522, "library_problem_id": 11, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 10}}
{"id": 523, "code": "\nplt.figure(figsize=(10, 8))\nfor i, gender in enumerate(df[\"Gender\"].unique()):\n    plt.plot(\n        df[df[\"Gender\"] == gender][\"Height (cm)\"],\n        df[df[\"Gender\"] == gender][\"Weight (kg)\"],\n        label=f\"{gender}\",\n        alpha=0.5,\n    )\nplt.legend()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER()\npltFER", "metadata": {"problem_id": 523, "library_problem_id": 12, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 12}}
{"id": 524, "code": "sns.set_style(\"darkgrid\")\npltdat = pd.DataFrame(x,y)\nsns.lineplot(pltdat)\nplt.show()\n", "metadata": {"problem_id": 524, "library_problem_id": 13, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 13}}
{"id": 525, "code": "\ndf = pd.DataFrame({\n    'x': x,\n    'y': y\n})\n\nsns.lineplot(df, x='x', y='y')\nplt.show()\n\n", "metadata": {"problem_id": 525, "library_problem_id": 14, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 13}}
{"id": 526, "code": "plt.plot(x, y, '+', markersize=7)\nplt.show()\n", "metadata": {"problem_id": 526, "library_problem_id": 15, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 15}}
{"id": 527, "code": "plt.legend(fontsize=20, loc='upper left')\npltthis = plt.plot(x, y, label=\"cos\")\nplt.legend(fontsize=20, loc='upper right')\nplt.show()\n", "metadata": {"problem_id": 527, "library_problem_id": 16, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 528, "code": "fig, ax = plt.subplots(figsize=(10, 5))\nax.plot(x, y, label='Cosine')\nax.set_title('Cosine Function', fontsize=20)\nax.set_ylabel('Cosine')\nplt.legend()\nplt.show()\n", "metadata": {"problem_id": 528, "library_problem_id": 17, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 16}}
{"id": 529, "code": "\nplt.plot(range(10), y, 'o-', alpha=0.2, lw=5, markersize=30)\npltdataplot = plt.gcf()\nplt.show()\n\n", "metadata": {"problem_id": 529, "library_problem_id": 18, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 18}}
{"id": 530, "code": "", "metadata": {"problem_id": 530, "library_problem_id": 19, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 531, "code": "\nplt.plot(x, y, '-', color='red', linewidth=3, markersize=10, markeredgewidth=1.5, markleyleafwidth=0.5, alpha=0.5)\nplt.show()\n\n", "metadata": {"problem_id": 531, "library_problem_id": 20, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 18}}
{"id": 532, "code": "x_rot = np.linspace(0, 2 * np.pi, 10)\ny_rot = np.sin(x_rot + np.pi/4)\nplt.plot(x_rot, y_rot, label=\"cos\")\nplt.legend()\npltthis!\nplt.show()\n\n# END SOLUTION\n\n# rotate the y axis labels clockwise by 45 degrees\n# SOLUTION START\nx_rot = np.linspace(0, 2 * np.pi, 10)\ny_rot = np.cos(x_rot + np.pi/4)\nplt.plot(x_rot, y_rot, label=\"cos\")\nplt.legend()\nplt.show()\nplt.close()\n\n# END SOLUTION\n\n# rotate the y axis labels clockwise by 45 degrees\n# SOLUTION START\nx_rot = np.linspace(0, 2 * np.pi, 10)\ny_rot = np.sin(x_rot + np.pi/4)\nplt.plot(x_rot, y_rot, label=\"sin\")\nplt.legend()\nplt.show()\nplt.close()\n\n# END SOLUTION\n\n# rotate the y axis labels clockwise by 45 degrees\n# SOLUTION START\nx_rot = np.linspace(0, 2 * np.pi, 10)\ny_rot = np.cos(x_rot + np.pi/4)\nplt.plot(x_rot, y_rot, label=\"cos\")\nplt.legend()\nplt.show()\nplt.close()\n\n# END SOLUTION\n\n# rotate the y axis labels clockwise by 45 degrees\n# SOLUTION START\nx_rot = np.linspace(0, 2 * np.pi, 10)\ny_rot = np.sin(x_rot + np.pi/4)\nplt.plot(x_rot, y_rot, label=\"sin\")\nplt.legend()\nplt.show()\nplt.close()\n\n# END SOLUTION\n", "metadata": {"problem_id": 532, "library_problem_id": 21, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 21}}
{"id": 533, "code": "x_rot = np.linspace(0, 2 * np.pi, 10)\ny_rot = np.sin(x_rot + np.pi/4)\nplt.plot(x_rot, y_rot, label=\"cos\")\nplt.legend()\npltthis!\nplt.show()\n\n", "metadata": {"problem_id": 533, "library_problem_id": 22, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 21}}
{"id": 534, "code": "x_ticks = np.array([0, 2, 4, 6, 8, 10])\nplt.xticks(x_ticks)\npltthis = plt.gcf()\npltplt = plt.label()\npltplt.show()\nplt.grid(True)\nplt.grid(False)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt.grid(True)\nplt", "metadata": {"problem_id": 534, "library_problem_id": 23, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 21}}
{"id": 535, "code": "plt.legend(labels=[\"a\", \"b\"])\nplt.show()\n# END SOLUTION\n\n# add histogram\nsns.distplot(x, label=\"a\", color=\"red\")\nsns.distplot(y, label=\"b\", color=\"blue\")\npltthis = sns.distplot(x, label=\"c\", color=\"green\")\nplt.show()\n\n# add violinplot\nsns.vioplot(x, color=\"red\")\nsns.vioplot(y, color=\"blue\")\nplt.show()\n\n# add boxplot\nsns.boxplot(x, color=\"red\")\nsns.boxplot(y, color=\"blue\")\nplt.show()\n\n# add lassoplot\nsns.lineplot(x, color=\"red\")\nsns.lineplot(y, color=\"blue\")\nplt.show()\n\n# add scatterplot\nsns.scatterplot(x, y, color=\"red\")\nsns.scatterplot(y, x, color=\"blue\")\nplt.show()\n\n# add heatmap\nsns.heatmap(x, color=\"red\")\nsns.heatmap(y, color=\"blue\")\nplt.show()\n\n# add plot\nsns.plot(x, y, color=\"red\")\nplt.show()\n\n# add barplot\nsns.barplot(x, y, color=\"red\")\nplt.show()\n\n# add map\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add swarmplot\nsns.swarmplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add histplot\nsns.histplot(x, color=\"red\")\nsns.histplot(y, color=\"blue\")\nplt.show()\n\n# add violinplot\nsns.vioplot(x, color=\"red\")\nsns.vioplot(y, color=\"blue\")\nplt.show()\n\n# add jitterplot\nsns.jitterplot(x, color=\"red\")\nsns.jitterplot(y, color=\"blue\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color=\"red\")\nplt.show()\n\n# add plot\nsns.lineplot(x, y, color", "metadata": {"problem_id": 535, "library_problem_id": 24, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 24}}
{"id": 536, "code": "\nplt.imshow(H, cmap='hot')\npltthis = plt.plot(H.ravel(), range(len(H.ravel())), 'r')\nplt.show()\n\n# END SOLUTION\n\n# The above code will generate a heatmap of the 2D array H. The 'hot' colormap is used to represent the maximum values in the array. The 'ravel' function is used to flatten the array to a 1D array and the 'range' function is used to generate the x-axis values. The 'plot' function is used to plot the values along the x-axis.\n\n# The 'ravel' function is used to flatten the array to a 1D array and the 'plot' function is used to plot the values along the x-axis.\n\n# The 'ravel' function is used to flatten the array to a 1D array and the 'plot' function is used to plot the values along the x-axis.\n", "metadata": {"problem_id": 536, "library_problem_id": 25, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 25}}
{"id": 537, "code": "plt.imshow(H, cmap='binary')\npltthis = plt.plot(H)\nplt.show()\n", "metadata": {"problem_id": 537, "library_problem_id": 26, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 25}}
{"id": 538, "code": "plt.xlabel(\"X\")\nplt.plot(x, y, label=\"cos\")\nplt.legend()\nplt.show()\n", "metadata": {"problem_id": 538, "library_problem_id": 27, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 27}}
{"id": 539, "code": "g.set(xlabel='')\ng.set(ylabel='')\nplt.show()\n", "metadata": {"problem_id": 539, "library_problem_id": 28, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 28}}
{"id": 540, "code": "plt.title(myTitle, fontsize=20, loc='center')\npltatarange = plt.ylabel(\"y\", fontsize=20, loc='center')\nplt.xlabel(\"x\", fontsize=20, loc='center')\nplt.show()\n", "metadata": {"problem_id": 540, "library_problem_id": 29, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 29}}
{"id": 541, "code": "y = y[::-1]\n\nplt.plot(x, y)\npltthis = plt.gcf()\npltplt = plt.gcf()\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()\nplt.plot(x, y)\nplt.show()", "metadata": {"problem_id": 541, "library_problem_id": 30, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 30}}
{"id": 542, "code": "x_ticks = np.linspace(0,1.5,10)\nplt.scatter(x_ticks, np.linspace(0,1.5,10))\npltthis!\n", "metadata": {"problem_id": 542, "library_problem_id": 31, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 31}}
{"id": 543, "code": "y_ticks = [-1, 1]\nplt.yticks(y_ticks)\npltatar(x, y)\nplt.show()\n", "metadata": {"problem_id": 543, "library_problem_id": 32, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 31}}
{"id": 544, "code": "\nfig, ax1 = plt.subplots(1, 1, tight_layout=True)\nax1.plot(x, y, color='blue', label='x')\nax1.plot(y, z, color='red', label='y')\nax1.set_xlabel('x')\nax1.set_ylabel('y')\nax1.legend()\nplt.show()\n\n", "metadata": {"problem_id": 544, "library_problem_id": 33, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 33}}
{"id": 545, "code": "plt.scatter(x, y, color='black', s=100, alpha=0.5, edgecolors='blue', linewidth=2, \n            marker='*', legend=True)\nplt.show()\n", "metadata": {"problem_id": 545, "library_problem_id": 34, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 34}}
{"id": 546, "code": "plt.plot(x, y, 'k')\npltthis = plt.gca()\npltthis.set_xticks(np.arange(0,20,2))\nplt.show()\n", "metadata": {"problem_id": 546, "library_problem_id": 35, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 35}}
{"id": 547, "code": "plt.ticklabel_format(axis='y', style='plain', scientific=False)\nplt.ticklabel_format(axis='x', style='plain', scientific=False)\n\nplt.show()\n# END SOLUTION\n\n# do not use scientific notation in the x axis ticks labels\nplt.ticklabel_format(axis='x', style='plain', scientific=False)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', scientific=False)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', scientific=False)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_float=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_log=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_unicode=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex_unicode=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex_unicode_math=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex_unicode_math_and_log=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex_unicode_math_and_log=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex_unicode_math_and_log=True, log=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex_unicode_math_and_log=True, log=True)\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex_unicode_math_and_log=True, log=True, color='red')\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex_unicode_math_and_log=True, log=True, color='red')\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex_unicode_math_and_log=True, log=True, color='red', fmt='d')\nplt.show()\n\n# do not use scientific notation in the y axis ticks labels\nplt.ticklabel_format(axis='y', style='plain', left=True, use_latex", "metadata": {"problem_id": 547, "library_problem_id": 36, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 548, "code": "\nx = np.arange(10)\ny = npataramble = np.random.rand(10)\nax = sns.lineplot(x=x, y=y, lin_interpolate='lower' , alpha=.2)\nplt.plot(x, y, lin_interpolate='lower', alpha=.2)\npltthis is not a valid command, it should be ax.plot(x, y, lin_interpolate='lower', alpha=.2)\n\n# END SOLUTION\n\nplt.show()\n\n# How to plot a scatterplot with matplotlib?\n# SOLUTION START\n\nimport matplotlib.pyplot as plt\n\nx = np.arange(10)\ny = np.random.rand(10)\nplt.scatter(x, y)\nplt.show()\n\n# END SOLUTION\n\n# How to plot a histogram with matplotlib?\n# SOLUTION START\n\nimport matplotlib.pyplot as plt\n\nx = np.random.rand(1000)\nplt.hist(x, bins=10, edgecolor='black')\nplt.show()\n\n# END SOLUTION\n\n# How to plot a barplot with matplotlib?\n# SOLUTION START\n\nimport matplotlib.pyplot as plt\n\nx = ['apple', 'banana', 'cherry']\ny = [50, 10, 5]\nplt.bar(x, y)\nplt.show()\n\n# END SOLUTION\n", "metadata": {"problem_id": 548, "library_problem_id": 37, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 37}}
{"id": 549, "code": "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5))\n\nax1.plot(x, y1, color='blue', label='sin')\nax1.plot(x, y2, color='red', label='cos')\nax1.set_title('Sinusoidal functions')\nax1.legend()\n\nax2.plot(x, y1, color='blue', label='sin')\nax2.plot(x, y2, color='red', label='cos')\nax2.set_title('Sinusoidal functions')\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n", "metadata": {"problem_id": 549, "library_problem_id": 38, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 38}}
{"id": 550, "code": "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5))\n\nax1.plot(x, y1, color='blue', linewidth=2, label='Sine Wave')\nax1.set_title('Sine Wave', size=20, color='blue')\nax1.tick_params(axis='both', which='both', color='grey', length=0.5)\n\nax2.plot(x, y2, color='red', linewidth=2, label='Cosine Wave')\nax2.set_title('Cosine Wave', size=20, color='red')\nax2.tick_params(axis='both', which='both', color='grey', length=0.5)\n\nplt.show()\n", "metadata": {"problem_id": 550, "library_problem_id": 39, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 38}}
{"id": 551, "code": "plt.xlabel(\"x\")\npltthis = plt.gcf()\nplt.title(\"x\")\nplt.show()\n", "metadata": {"problem_id": 551, "library_problem_id": 40, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 40}}
{"id": 552, "code": "plt.xticks([])\npltFERFETION.xticks(rotation=90)\nplt.show()\n# END SOLUTION\n\n# remove y tick labels\nplt.yticks([])\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.ylabel('y')\nplt.show()\n\n# remove x label\nplt.xlabel('x')\nplt.show()\n\n# remove y label\nplt.", "metadata": {"problem_id": 552, "library_problem_id": 41, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 40}}
{"id": 553, "code": "plt.xticks([3, 4])\npltthis = plt.gcf()\nplt.gcf().canvas.set_label(plt.gcf().canvas.get_xypoints())\nplt.show()\n", "metadata": {"problem_id": 553, "library_problem_id": 42, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 42}}
{"id": 554, "code": "plt.gca().set_yticks([3])\npltthis = plt.gca().set_yticks([4])\nplt.gca().grid(which='y', axis='y', linestyle='-', linewidth=0.5, color='red')\nplt.gca().grid(which='y', axis='y', linestyle='-', linewidth=0.5, color='red')\nplt.show()\n", "metadata": {"problem_id": 554, "library_problem_id": 43, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 555, "code": "plt.xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nplt.yticks([-1, 0, 1, 2, 3, 4, 5])\nplt.grid([3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\nplt.show()\n", "metadata": {"problem_id": 555, "library_problem_id": 44, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 556, "code": "plt.grid(True)\npltthis = plt.gcf()\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\nplt.grid(True)\nplt.scatter(x, y)\nplt.grid(False)\nplt.show()\npl", "metadata": {"problem_id": 556, "library_problem_id": 45, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 557, "code": "plt.legend(loc='lower right')\npltatarches.show()\n", "metadata": {"problem_id": 557, "library_problem_id": 46, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 46}}
{"id": 558, "code": "fig.subplots_adjust(hspace=0.5, wspace=0.5)\nplt.show()\nplt.clf()\n\nplt.close()\nplt.show()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.close()\nplt.", "metadata": {"problem_id": 558, "library_problem_id": 47, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 47}}
{"id": 559, "code": "plt.plot(x, y, label='Y')\nplt.plot(x, z, label='Z')\npltatarams(x, label='Y vs Z')\nplt.legend()\nplt.show()\n# END SOLUTION\n\n# In the above plot, the line 'Y' is the one we want to show and 'Z' is the one we want to hide.\n# The names 'Y' and 'Z' are used to distinguish between the two lines in the plot.\n# By giving names to the lines in the plot, we can distinguish between them and show them in a legend.\n# The legend is a small box that contains the names of the lines.\n# By giving names to the legend, we can identify the lines in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can identify the lines in the legend and show them in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can identify the lines in the legend and show them in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can identify the lines in the legend and show them in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can identify the lines in the legend and show them in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can identify the lines in the legend and show them in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can identify the lines in the legend and show them in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can identify the lines in the legend and show them in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can identify the lines in the legend and show them in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can identify the lines in the legend and show them in the legend.\n# The legend is a way to summarize the plot and make it easier to understand the plot.\n# In the end, the names 'Y' and 'Z' are the names of the lines in the plot, and 'Y vs Z' is the name of the line in the legend.\n# By giving names to the legend, we can", "metadata": {"problem_id": 559, "library_problem_id": 48, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 48}}
{"id": 560, "code": "heatmap.set_xlabel(column_labels)\nheatmap.set_ylabel(row_labels)\npltatarize_labels = {\"W\": \"Column_W\", \"X\": \"Column_X\", \"Y\": \"Column_Y\", \"Z\": \"Column_Z\"}\nheatmap.set_label(heatmap.get_array()[::-1].tolist(), fmt='symmetric', badlist=[])\nplt.tight_layout()\nplt.show()\n", "metadata": {"problem_id": 560, "library_problem_id": 49, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 49}}
{"id": 561, "code": "plt.figure(figsize=(20, 20))\nplt.plot(x, y, label='X')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.grid(True)\nplt.show()\n", "metadata": {"problem_id": 561, "library_problem_id": 50, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 50}}
{"id": 562, "code": "plt.plot(x, y, label='y=x')\nplt.plot(x, y, label='y=x')\npltFER\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n", "metadata": {"problem_id": 562, "library_problem_id": 51, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 51}}
{"id": 563, "code": "plt.figure(figsize=(10, 5))\nplt.plot(x, y, 'r')\npltFER()\nplt.show()\n", "metadata": {"problem_id": 563, "library_problem_id": 52, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 52}}
{"id": 564, "code": "plt.plot(x, y, label='Y')\nplt.ylabel('Y')\npltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOMpltFERENDOM", "metadata": {"problem_id": 564, "library_problem_id": 53, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 52}}
{"id": 565, "code": "\nsns.jointplot(x=tips[\"total_bill\"], y=tips[\"tip\"], data=tips, kind='reg', color='green')\npltthis = plt.gca()\npltthis.set_axis_color('blue')\nplt.tight_layout()\nplt.show()\n", "metadata": {"problem_id": 565, "library_problem_id": 54, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 566, "code": "\nsns.jointplot(x=tips[\"total_bill\"], y=tips[\"tip\"], hue=\"tip\", palette=\"green\", linewidth=2, linecolor=\"black\")\npltatar = plt.gplot()\nplt.show()\n\n", "metadata": {"problem_id": 566, "library_problem_id": 55, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 567, "code": "\nsns.jointplot(x=tips['total_bill'], y=tips['tip'])\npltthis = plt.gplot()\npltthis.show()\n\n", "metadata": {"problem_id": 567, "library_problem_id": 56, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 568, "code": "fig, ax = plt.subplots()\ndf.plot(kind='bar', x='celltype', y='s1', ax=ax, hue='s2', legend=False)\nplt.xlabel('celltype')\nplt.ylabel('s1')\nplt.show()\n", "metadata": {"problem_id": 568, "library_problem_id": 57, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 57}}
{"id": 569, "code": "fig, ax = plt.subplots()\ndf.plot(kind='bar', x='celltype', y='s1', ax=ax,rot=45)\ndf.plot(kind='bar', x='celltype', y='s2', ax=ax,rot=45)\npltthis = plt\nplt.show()\n", "metadata": {"problem_id": 569, "library_problem_id": 58, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 57}}
{"id": 570, "code": "plt.plot(x, y, label='X')\nplt.xlabel('X')\npltFER()\nplt.ylabel('Y')\nplt.plot(x, y, label='Y')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.show()\nplt.plot(x, y, label=", "metadata": {"problem_id": 570, "library_problem_id": 59, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 59}}
{"id": 571, "code": "plt.plot(x, y, label='X')\nplt.xlabel('X')\npltFER()\nplt.show()\nplt.plot(x, y, label='Y')\nplt.xlabel('Y')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()\nplt.plot(x, y, label='XY')\nplt.xlabel('XY')\nplt.show()", "metadata": {"problem_id": 571, "library_problem_id": 60, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 59}}
{"id": 572, "code": "plt.plot(x, y, 'r')\nplt.xticks(fontsize=10)\npltFER()\nplt.yticks(fontsize=10)\nplt.show()\n", "metadata": {"problem_id": 572, "library_problem_id": 61, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 61}}
{"id": 573, "code": "\nplt.figure(figsize=(10, 10))\npltFERmage()\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=True, horizontal_lines=True, vertical_lines=True)\npltFERmage(image, grids=", "metadata": {"problem_id": 573, "library_problem_id": 62, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 62}}
{"id": 574, "code": "plt.figure(figsize=(10, 10))\npltatarange = plt.pcolormesh(xlabels, ylabels, rand_mat, shading='flat')\nplt.xlabel('X-axis Labels')\nplt.ylabel('Y-axis Labels')\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.show()\n", "metadata": {"problem_id": 574, "library_problem_id": 63, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 63}}
{"id": 575, "code": "temp_label = \"Temperature ($^\\circ$C)\"\nSwdown_label = \"Swdown (m$^2$/h)\"\nRn_label = \"Rn (m$^2$/h)\"\n\nfig, axs = plt.subplots(2, 1, constrained_layout=True)\naxs[0].plot(time, temp, \"-\", label=temp_label, alpha=0.5)\naxs[0].plot(time, Swdown, \"-\", label=Swdown_label, alpha=0.5)\naxs[0].plot(time, Rn, \"-\", label=Rn_label, alpha=0.5)\naxs[0].legend(loc=\"upper\")\naxs[0].grid()\naxs[0].set_xlabel(\"Time (h)\")\naxs[0].set_ylabel(temp_label)\naxs[1].plot(time, Swdown, \"-\", label=Swdown_label, alpha=0.5)\naxs[1].plot(time, Rn, \"-\", label=Rn_label, alpha=0.5)\naxs[1].legend(loc=\"upper\")\naxs[1].grid()\naxs[1].set_xlabel(\"Time (h)\")\naxs[1].set_ylabel(temp_label)\nplt.show()\n# END SOLUTION\n\n# copy the code of the above plot and edit it to have legend for all three curves in the same subplot\n# SOLUTION START\ntemp_label = \"Temperature ($^\\circ$C)\"\nSwdown_label = \"Swdown (m$^2$/h)\"\nRn_label = \"Rn (m$^2$/h)\"\n\nfig, ax = plt.subplot(111)\nax.plot(time, temp, \"-\", label=temp_label, alpha=0.5)\nax.plot(time, Swdown, \"-\", label=Swdown_label, alpha=0.5)\nax.plot(time, Rn, \"-\", label=Rn_label, alpha=0.5)\nax.legend(loc=\"upper\")\nax.grid()\nax.set_xlabel(\"Time (h)\")\nax.set_ylabel(temp_label)\nplt.show()\n# END SOLUTION\n\n# copy the code of the above plot and edit it to have legend for all three curves in the same subplot\n# SOLUTION START\ntemp_label = \"Temperature ($^\\circ$C)\"\nSwdown_label = \"Swdown (m$^2$/h)\"\nRn_label = \"Rn (m$^2$/h)\"\n\nfig, ax = plt.subplot(111)\nax.plot(time, temp, \"-\", label=temp_label, alpha=0.5)\nax.plot(time, Swdown, \"-\", label=Swdown_label, alpha=0.5)\nax.plot(time, Rn, \"-\", label=Rn_label, alpha=0.5)\nax.legend(loc=\"upper\")\nax.grid()\nax.set_xlabel(\"Time (h)\")\nax.set_ylabel(temp_label)\nplt.show()\n# END SOLUTION\n\n# copy the code of the above plot and edit it to have legend for all three curves in the same subplot\n# SOLUTION START\ntemp_label = \"Temperature ($^\\circ$C)\"\nSwdown_label = \"Swdown (m$^2$/h)\"\nRn_label = \"Rn (m$^2$/h)\"\n\nfig, ax = plt.subplot(111)\nax.plot(time, temp, \"-\", label=temp_label, alpha=0.5)\nax.plot(time, Swdown, \"-\", label=Swdown_label, alpha=0.5)\nax.plot(time, Rn, \"-\", label=Rn_label, alpha=0.5)\nax.legend(loc=\"upper\")\nax.grid()\nax.set_xlabel(\"Time (h)\")\nax.set_ylabel(temp_label)\nplt.show()\n# END SOLUTION\n\n# copy the code of the above plot and edit it to have legend for all three curves in the", "metadata": {"problem_id": 575, "library_problem_id": 64, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 64}}
{"id": 576, "code": "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n\nfor i, ax_name in enumerate(axs):\n    ax_name.plot(x, y, label=f'line 1', color='red')\n    ax_name.set_title(f'Y')\n\nplt.tight_layout()\npltthis = plt\nplt.show()\n", "metadata": {"problem_id": 576, "library_problem_id": 65, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 65}}
{"id": 577, "code": "plt.scatter(df['bill_length_mm'], df['bill_depth_mm'], marker='o', s=30)\npltthis\nplt.xlabel('bill_length_mm')\nplt.ylabel('bill_depth_mm')\nplt.show()\n", "metadata": {"problem_id": 577, "library_problem_id": 66, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 66}}
{"id": 578, "code": "\nfig, ax = plt.subplots()\nax.scatter(a, b, color='r', label='Line')\nax.scatter(b, c, color='g', label='Scatter')\nax.scatter(a, c, color='b', label='Scatter')\nax.legend()\npltatarches your code here\nplt.show()\n\n", "metadata": {"problem_id": 578, "library_problem_id": 67, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 67}}
{"id": 579, "code": "plt.plot(x, y, label='y over x')\nplt.legend()\nplt.title('Line Chart')\nplt.show()\n", "metadata": {"problem_id": 579, "library_problem_id": 68, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 68}}
{"id": 580, "code": "\nplt.plot(x, y, label='y over x')\nplt.legend()\npltthis = plt.gcf()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks()\nplt.gcf().canvas.get_extra_window_ticks", "metadata": {"problem_id": 580, "library_problem_id": 69, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 68}}
{"id": 581, "code": "plt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.hist(x, bins=10, alpha=0.2, label='x')\nplt.hist(y, bins=10, alpha=0.2, label='y')\npltthis = plt.suptitle('Histogram')\nplt.legend()\nplt.show()\n", "metadata": {"problem_id": 581, "library_problem_id": 70, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 70}}
{"id": 582, "code": "fig, ax1 = plt.subplots(2,1, tight_layout=True)\nax1.plot(x, y, color='tab:red')\nax2 = ax1.twinx()\nax2.plot(x, y, color='tab:blue')\npltthis = pltplot = pltplot. twin_coords(x, y)\npltplot.plot(x, y, color='tab:green')\npltplot.show()\n", "metadata": {"problem_id": 582, "library_problem_id": 71, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 71}}
{"id": 583, "code": "plt.hist(x, bins, alpha=0.5, label='x')\nplt.hist(y, bins, alpha=0.5, label='y')\npltFER\n\nplt.legend()\nplt.show()\n\n", "metadata": {"problem_id": 583, "library_problem_id": 72, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 72}}
{"id": 584, "code": "plt.figure(figsize=(10, 5))\nplt.subplot(1,2,1)\nplt.hist(x, alpha=0.5, label='x')\nplt.hist(y, alpha=0.5, label='y')\npltdatename = 'histograms.png'\nplt.legend()\nplt.title('Grouped Histograms')\nplt.show()\n", "metadata": {"problem_id": 584, "library_problem_id": 73, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 72}}
{"id": 585, "code": "x = [a,c,a,b,c,b,c,a]\ny = [b,d,a,d,b,c,c,b]\nplt.plot(x,y)\npltthis = plt.plot(x,y)\nplt.xlim([0,5])\nplt.ylim([0,5])\nplt.show()\n", "metadata": {"problem_id": 585, "library_problem_id": 74, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 74}}
{"id": 586, "code": "fig, ax = plt.subplots(2, 1)\n\nim1 = ax[0].pcolormesh(x, cmap='coolwarm')\nim2 = ax[1].pcolormesh(y, cmap='coolwarm')\n\nplt.colorbar(im1, ax=ax[0])\npltENSE END\n\n# make two colormaps with x and y and put them into different subplots\n# use a single colorbar for these two subplots\n", "metadata": {"problem_id": 586, "library_problem_id": 75, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 75}}
{"id": 587, "code": "fig, ax = plt.subplots()\nax.plot(x[:,0], x[:,1], 'o-', label='a')\nax.plot(x[:,0], x[:,1], 'v-', label='b')\npltatarches.legend()\nplt.show()\n", "metadata": {"problem_id": 587, "library_problem_id": 76, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 76}}
{"id": 588, "code": "fig, ax = plt.subplots(2, 1, figsize=(10, 5))\n\nax[0].plot(x, y, label='Y over X')\nax[0].plot(x, z, label='Z over X')\nax[0].set_title('Y and Z')\nax[1].plot(a, y, label='Y over A')\nax[1].plot(a, z, label='Z over A')\nax[1].set_title('')\nplt.tight_layout()\nplt.show()\n", "metadata": {"problem_id": 588, "library_problem_id": 77, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 77}}
{"id": 589, "code": "x, y = zip(*points)\nplt.plot(x, y, 'k')\npltthis = plt.gca()\npltthis.set_axis_labels(log=True)\nplt.show()\n", "metadata": {"problem_id": 589, "library_problem_id": 78, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 78}}
{"id": 590, "code": "plt.figure(figsize=(10, 6))\npltFER = plt.plot(x, y, 'r', label='y=x')\nplt.title('Y over X', fontsize=20, pad=20)\nplt.xlabel('X', fontsize=18)\nplt.ylabel('Y', fontsize=16)\nplt.grid(True)\nplt.show()\n", "metadata": {"problem_id": 590, "library_problem_id": 79, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 79}}
{"id": 591, "code": "ax.plot(x, y, label='y=x')\nax.tick_params(axis='both', which='both', labelsize=20, labelcolor='red')\nplt.legend(['y=x'], loc=1)\npltthis = plt\nplt.show()\n", "metadata": {"problem_id": 591, "library_problem_id": 80, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 80}}
{"id": 592, "code": "\n# Create a plot\nfig, ax = plt.subplots()\n\n# Plot the lines\nfor i, ((x1, y1), (x2, y2)) in enumerate(lines):\n    ax.plot(x1, y1, 'o-', label=f'line {i}', color=c[i])\n    ax.plot(x2, y2, 'o-', label=f'line {i}', color=c[i])\n\n# Add a legend\nax.legend()\n\npltthis = plt.show()\n\n", "metadata": {"problem_id": 592, "library_problem_id": 81, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 81}}
{"id": 593, "code": "\nplt.loglog()\nplt.plot(x, y, 'o-')\nplt.xlabel('x')\npltdat = plt.ylabel('y')\nplt.yscale('log')\nplt.xscale('log')\nplt.show()\n\n", "metadata": {"problem_id": 593, "library_problem_id": 82, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 82}}
{"id": 594, "code": "\nfig, ax = plt.subplots()\nfor column in df.columns:\n    df[column].plot(kind='line', ax=ax,label=column)\npltthis = plt.suptitle('Line Plot')\nplt.show()\n", "metadata": {"problem_id": 594, "library_problem_id": 83, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 83}}
{"id": 595, "code": "\nplt.hist(data, bins=3, edgecolor='black', align='left', \n         histtype='bar', range=(0,21000),\n         log=True,\n         color='purple',\n         rwidth=0.5,\n         label='Data')\n\npltatarange(0,21000,\n            alpha=0.75,\n            where='upper',\n            label='Data')\n\nplt.legend(framealpha=0.9,\n           edgecolor='black',\n           label='Data')\n\nplt.show()\n", "metadata": {"problem_id": 595, "library_problem_id": 84, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 84}}
{"id": 596, "code": "plt.plot(x, y, 'r--', label='y=2x')\nplt.show()\n", "metadata": {"problem_id": 596, "library_problem_id": 85, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 597, "code": "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n\naxs[0][0].plot(x, y, label='y')\naxs[0][0].plot(a, z, label='a')\naxs[0][0].legend()\n\naxs[0][1].plot(x, a, label='y')\naxs[0][1].plot(y, z, label='a')\naxs[0][1].legend()\n\naxs[1][0].plot(y, x, label='y')\naxs[1][0].plot(z, x, label='x')\naxs[1][0].legend()\n\naxs[1][1].plot(z, y, label='z')\naxs[1][1].plot(x, y, label='x')\naxs[1][1].legend()\n\nplt.tight_layout()\nplt.show()\n", "metadata": {"problem_id": 597, "library_problem_id": 86, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 86}}
{"id": 598, "code": "fig, axs = plt.subplots(2, 1, figsize=(12))\n\nsns.regplot(x=df[\"bill_length_mm\"], y=df[\"bill_depth_mm\"], ax=axs[0])\nsns.regplot(x=df[\"bill_length_mm\"], y=df[\"flipper_length_mm\"], ax=axs[1])\n\npltatarches.show()\n", "metadata": {"problem_id": 598, "library_problem_id": 87, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 87}}
{"id": 599, "code": "ax.set_xticks([], labels=['Second'])\nax.set_yticks([], labels=['First'])\n", "metadata": {"problem_id": 599, "library_problem_id": 88, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 88}}
{"id": 600, "code": "plt.plot(x, y, label='y=x')\nplt.legend()\npltthis\nplt.show()\n", "metadata": {"problem_id": 600, "library_problem_id": 89, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 89}}
{"id": 601, "code": "xticks = plt.gca().xticks\nxtickslines = xticks[0]\nnew_ticks = np.append(xtickslines, [2.1, 3, 7.6])\nplt.gca().xticks = new_ticks\npltthis = plt.gca().lines[0].color = 'red'\nplt.show()\n# END SOLUTION\n\n# Adding a line to the plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='red')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='blue')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='green')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='yellow')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='cyan')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='magenta')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='orange')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='purple')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='violet')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='gold')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='silver')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='plum')\nplt.show()\n\n# Adding a line to the existing plot\nx = np.append(x, [10, 11, 12])\ny = np.append(y, [1, 2, 3])\nplt.plot(x, y, color='barnish')\nplt.", "metadata": {"problem_id": 601, "library_problem_id": 90, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 90}}
{"id": 602, "code": "plt.xticks(rotation=-60)\npltthis = plt\nplt.xticks(rotation='left')\nplt.plot(x, y)\nplt.show()\n# END SOLUTION\n\n# Now, the plot should be horizontal and not vertical.\n# You can also specify the rotation angle in degrees by setting the rotation parameter to the desired angle.\n# For example, plt.xticks(rotation=30) will rotate the labels by 30 degrees to the right.\n# You can also specify the rotation by passing the rotation parameter to the labelrotation function.\n# For example, plt.xticks(rotation='vertical') will rotate the labels to vertical.\n# For more information, check out the matplotlib documentation.\n# https://matplotlib.org/contents\u7ae0\u8282/plotting/plot_direct/rotation.html\n# END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END END", "metadata": {"problem_id": 602, "library_problem_id": 91, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 91}}
{"id": 603, "code": "plt.xticks(rotation=-60)\npltFERyset(rotation='top')\nplt.tick_params(axis='y', labelsize=10, rotation='top')\nplt.show()\n# END SOLUTION\n\n# Adding a label to the y-axis\nplt.ylabel(\"Y-axis\")\nplt.show()\n\n# Adding a label to the x-axis\nplt.xlabel(\"X-axis\")\nplt.show()\n\n# Adding a title to the graph\nplt.title(\"Graph Title\")\nplt.show()\n\n# Adding a legend to the graph\nplt.legend(['Line1', 'Line2'], ['Line1', 'Line2'])\nplt.show()\n\n# Adding a grid to the graph\nplt.grid(True)\nplt.show()\n\n# Adding a horizontal line to the graph\nplt.axhline(y=y, color='r', linestyle='dashed', label='Slow')\nplt.show()\n\n# Adding a vertical line to the graph\nplt.axvline(x=x, color='g', linestyle='dotted', label='Fast')\nplt.show()\n\n# Adding a scatter plot to the graph\nplt.scatter(x, y, color='b', label='Scatter')\nplt.show()\n\n# Adding a barplot to the graph\nplt.bar(['bar1', 'bar2'], [10, 20], color='r', label='Bar')\nplt.show()\n\n# Adding a pie to the graph\nplt.pie([10, 20], labels=['A', 'B'], colors=['blue', 'yellow'], autopct='%10s'+y, shadow=True, label='Pie')\nplt.show()\n\n# Adding a histogram to the graph\nplt.hist([x, y], bins=2, edgecolor='black', label='Hist')\nplt.show()\n\n# Adding a violinplot to the graph\nplt.vioplot([x, y], [10, 20], color='c1', horizontal=True, label='Violin')\nplt.show()\n\n# Adding a plot to the graph\nplt.plot([x, y], color='m', linestyle='-.', label='Line')\nplt.show()\n\n# Adding a barplot to the graph\npltthis.bar(['bar1', 'bar2'], [10, 20], color='c', alpha=0.5, label='Bar')\nplt.show()\n\n# Adding a histogram to the graph\nplt.hist([x, y], bins=3, edgecolor='black', color='c', label='Hist')\nplt.show()\n\n# Adding a violinplot to the graph\nplt.vioplot([x, y], [10, 20], color='g', alpha=0.5, vertical=True, label='Violin')\nplt.show()\n\n# Adding a scatterplot to the graph\nplt.scatter([x, y], color='y', edgecolors='black', label='Scatter')\nplt.show()\n\n# Adding a boxplot to the graph\nplt.boxplot([x, y], color='y', vert=False, labels=['Box'], linewidth=2, linestyles='-')\nplt.show()\n\n# Adding a violinplot to the graph\nplt.vioplot([x, y], [10, 20], color='r', alpha=0.5, vertical=False, label='Violin')\nplt.show()\n\n# Adding a plot to the graph\nplt.plot([x, y], color='b', linestyle='-', label='Line')\nplt.show()\n\n# Adding a histogram to the graph\nplt.hist([x, y], bins=4, edgecolor='black', color='c', label='Hist')\nplt.show()\n\n# Adding a violinplot to the graph\nplt.", "metadata": {"problem_id": 603, "library_problem_id": 92, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 91}}
{"id": 604, "code": "plt.xticks(rotation=90)\npltFER!\nplt.show()\n", "metadata": {"problem_id": 604, "library_problem_id": 93, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 91}}
{"id": 605, "code": "plt.gca().spacerange = 0.5\nplt.gca().spacingset = 0.5\npltFERpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltpltplt", "metadata": {"problem_id": 605, "library_problem_id": 94, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 94}}
{"id": 606, "code": "plt.gca().spacerange = 0.5\npltFER()\nplt.show()\n", "metadata": {"problem_id": 606, "library_problem_id": 95, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 94}}
{"id": 607, "code": "fig, ax = plt.subplots()\n\nax.plot(x, y, label='y=x')\nax.set_title(\"Figure\")\nax.set_xlabel('x')\nax.set_ylabel('y')\n\nplt.show()\n", "metadata": {"problem_id": 607, "library_problem_id": 96, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 96}}
{"id": 608, "code": "df.plot(x='Type A', y='Type B', kind='line', ax=plt.gca(), color='blue', marker='o', label='Type A')\npltthis = plt.gca().set_title('Line plot')\nplt.gca().set_xlabel('X')\nplt.gca().set_ylabel('Y')\nplt.show()\n", "metadata": {"problem_id": 608, "library_problem_id": 97, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 97}}
{"id": 609, "code": "plt.scatter(x, y, hatch='D')\nplt.show()\n", "metadata": {"problem_id": 609, "library_problem_id": 98, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 98}}
{"id": 610, "code": "plt.scatter(x, y, edgecolors='none', linewidths=2, hatch='V')\nplt.show()\n", "metadata": {"problem_id": 610, "library_problem_id": 99, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 98}}
{"id": 611, "code": "plt.scatter(x, y, edgecolors='black', linewidths=1, head=None, shatterd=True)\nplt.show()\n", "metadata": {"problem_id": 611, "library_problem_id": 100, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 98}}
{"id": 612, "code": "plt.scatter(x, y, s=100, marker='*', vertical_line_marker=':')\nplt.show()\n", "metadata": {"problem_id": 612, "library_problem_id": 101, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 98}}
{"id": 613, "code": "plt.imshow(data, extent=[0,1,1,4])\npltthis = plt.plot([5,5], [1,4], '--')\nplt.show()\n", "metadata": {"problem_id": 613, "library_problem_id": 102, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 102}}
{"id": 614, "code": "plt.stem(x, y, orientation='horizontal', linewidth=2, color='b')\nplt.show()\n", "metadata": {"problem_id": 614, "library_problem_id": 103, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 103}}
{"id": 615, "code": "\nplt.figure(figsize=(10, 6))\npltatarches = plt.bar(d.keys(), d.values(), color=c.values(), edgecolor='None', alpha=0.5, label='Bars')\nplt.xlabel('Keys')\nplt.ylabel('Values')\nplt.legend()\nplt.show()\n", "metadata": {"problem_id": 615, "library_problem_id": 104, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 104}}
{"id": 616, "code": "\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\npltENSECTION END\n\nplt.legend()\nplt.show()\n# END SOLUTION END\n\n# SOLUTION START\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n# END SOLUTION END\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\nplt.show()\n\nplt.plot([0, 3], [0, 1], 'k', label='cutoff')\nplt.legend()\n", "metadata": {"problem_id": 616, "library_problem_id": 105, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 105}}
{"id": 617, "code": "plt.figure(figsize=(12, 6))\npltatarange = [0, 0, 2*np.pi]\ncolors = [0, 0]\nplt.bar(pltatarange, height, 2*0.5, bottom=0, color=colors, edgecolor='None', align='edge')\nplt.plot(pltatarange, height, color='black', label=labels)\nplt.show()\n", "metadata": {"problem_id": 617, "library_problem_id": 106, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 106}}
{"id": 618, "code": "plt.pie(data, labels=l, wedgeWidth=0.4, startangle=90, autopct='%1.1f%%', shadow=True, startangle=90)\npltthis = plt.show()\n", "metadata": {"problem_id": 618, "library_problem_id": 107, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 107}}
{"id": 619, "code": "plt.plot(x, y, 'b-')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()\n", "metadata": {"problem_id": 619, "library_problem_id": 108, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 108}}
{"id": 620, "code": "plt.plot(x, y, '--')\nplt.show()\n", "metadata": {"problem_id": 620, "library_problem_id": 109, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 109}}
{"id": 621, "code": "plt.pie(sizes, labels, colors, rot=1,\n        # Warning, 'explode', the first value in zip will be the 'explode' value for the pie\n        # we want to have a different color for the first slice and the rest will be the same color\n        # 'sizes' and 'labels' should have same length\n        # we want to have 'explode' to have the first slice in the center of the pie\n        # we want to have the first slice with the color 'red' and the rest with the color 'blue'\n        # we want to have the first slice with the label 'Walking' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label", "metadata": {"problem_id": 621, "library_problem_id": 110, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 110}}
{"id": 622, "code": "plt.pie(sizes, labels, colors, rot=1,\n        # Warning, 'explode', the first value in zip will be the 'explode' value for the pie\n        # we want to have a different color for the first slice and the rest will be the same color\n        # 'sizes' and 'labels' should have same length\n        # we want to have 'explode' to have the first slice in the center of the pie\n        # we want to have the first slice with the color 'red' and the rest with the color 'blue'\n        # we want to have the first slice with the label 'Walking' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label 'Other'\n        # we want to have the first slice with the label 'Other' and the rest with the label", "metadata": {"problem_id": 622, "library_problem_id": 111, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 111}}
{"id": 623, "code": "plt.plot(x, y, '--k', label='y=x')\nplt.legend()\npltthis = plt.gcf()\nplt.show()\n", "metadata": {"problem_id": 623, "library_problem_id": 112, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 112}}
{"id": 624, "code": "plt.axvline(55, color='green', linestyle='dashed', linewidth=3)\npltatarches plt.show()\n", "metadata": {"problem_id": 624, "library_problem_id": 113, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 113}}
{"id": 625, "code": "\nx = np.arange(len(blue_bar), dtype=int, color_bar=3, alpha=0.5, label='blue')\nplt.bar(x, height=blue_bar, color='b', alpha=0.5, log=True, label='blue')\npltatarange(x, height=orange_bar, bottom=1, color='orange', alpha=0.5, log=True, label='orange')\nplt.legend()\nplt.show()\n", "metadata": {"problem_id": 625, "library_problem_id": 114, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 114}}
{"id": 626, "code": "\nfig, ax1 = plt.subplots(1)\nax1.plot(x, y, color='blue', label='Line 1')\nax1.plot(a, z, color='red', label='Line 2')\nax1.set_ylabel('Y', color='blue')\nax1.set_ylabel('Z', color='red')\nax1.legend()\nplt.show()\n\n", "metadata": {"problem_id": 626, "library_problem_id": 115, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 115}}
{"id": 627, "code": "\nplt.scatter(x, y, s=100, color=y, alpha=0.9, edgecolors='black',\n           linewidths=1.5,\n           # Use the 'Spectral' colormap\n           cmap='spectral')\n\nplt.show()\n\n", "metadata": {"problem_id": 627, "library_problem_id": 116, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 116}}
{"id": 628, "code": "plt.figure(figsize=(10, 5))\nplt.plot(x, y, 'o-')\nplt.show()\n", "metadata": {"problem_id": 628, "library_problem_id": 117, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 117}}
{"id": 629, "code": "\ndf.columns = [\"species\", \"bill_length_mm\"]\n\nplot = sns.catplot(x=\"species\", y=\"bill_length_mm\", hue=\"species\", col=\"species\", row=None, height=6, aspect=4, palette=0, legend=False, data=df)\n\nplot.set(axis=None)\n\nplot.despine().set(ylabel=\"Bill Length (mm)\", xlabel=\"Species\")\n\nplot.fig.suptitle(\"Bill Length across Species\")\n\npltthis = plot.plt.figure\nplt.show()\n\n", "metadata": {"problem_id": 629, "library_problem_id": 118, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 118}}
{"id": 630, "code": "\nfig, ax = plt.subplots()\nax.set_aspect('equal')\n\ncircle = plt.Circle((0.5, 0.5), 0.2, color='red', edgecolor='None', fill=True)\nax.add_patch(circle)\n\npltthis = plt.gcf().gaselines()\nplt.show()\n", "metadata": {"problem_id": 630, "library_problem_id": 119, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 119}}
{"id": 631, "code": "plt.plot(x, y, 'r')\nplt.title(r'$\\mathdefault{phi}$'r, {'phi'}')\nplt.show()\n", "metadata": {"problem_id": 631, "library_problem_id": 120, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 120}}
{"id": 632, "code": "plt.figure(figsize=(10, 6))\nplt.plot(x, y, label='Line')\nplt.legend(fontsize=10, label='Line')\nplt.show()\n", "metadata": {"problem_id": 632, "library_problem_id": 121, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 121}}
{"id": 633, "code": "plt.figure(figsize=(10, 5))\nplt.plot(x, y, label='Line')\nplt.legend(frameon=False, framealpha=1, label='Line')\nplt.show()\n", "metadata": {"problem_id": 633, "library_problem_id": 122, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 634, "code": "plt.legend()\npltthis = plt.gcf()\nplt.legend(['Line', 'Flipped'], loc='center')\nplt.show()\n", "metadata": {"problem_id": 634, "library_problem_id": 123, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 635, "code": "plt.legend(label=\"Line\")\npltthis = plt\nplt.show()\nplt.plot(x, y, 'o', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, '+', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, '-', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, '^', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, '/', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 's', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'v', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'w', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'd', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'dash', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'doublearrow', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'triplearrow\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'cross', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'frown', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'band', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'hol\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'vark', label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'target\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'invertedtriangle\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'doublecurly\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'doublesept\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'triplesect\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'fourlines\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'five\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'six\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'sept\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'oct\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'nine\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'zero\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'plus\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'cross\", label=\"Line\")\nplt.legend()\nplt.show()\nplt.plot(x, y, 'triangle\", label=\"Line\")\nplt.leg", "metadata": {"problem_id": 635, "library_problem_id": 124, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 121}}
{"id": 636, "code": "fig, ax = plt.subplots()\nim = ax.imshow(data, cmap='viridis')\npltatarches.colorbar(im, ax)\nplt.show()\n", "metadata": {"problem_id": 636, "library_problem_id": 125, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 125}}
{"id": 637, "code": "plt.title('Figure 1',style='bold')\nplt.plot(x,y)\nplt.show()\n", "metadata": {"problem_id": 637, "library_problem_id": 126, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 126}}
{"id": 638, "code": "fig, ax = plt.subplots()\nsns.pairplot(df, x_vars=\"x\", y_vars=\"y\", hue=\"id\", palette=\"husl\", plot_kws={\"alpha\":0.5}, ax=ax)\nplt.show()\n", "metadata": {"problem_id": 638, "library_problem_id": 127, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 127}}
{"id": 639, "code": "plt.plot(x, y, 'r')\nplt.gca().invert_xy()\nplt.show()\n", "metadata": {"problem_id": 639, "library_problem_id": 128, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 128}}
{"id": 640, "code": "plt.scatter(x, y, alpha=0.5, edgecolors='black')\npltFER\nplt.xlim(0, 10)\nplt.ylim(0, 10)\nplt.show()\n\n", "metadata": {"problem_id": 640, "library_problem_id": 129, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 129}}
{"id": 641, "code": "plt.scatter(x, y, color='red', s=10, linewidths=0.5, alpha=0.5)\nplt.show()\n", "metadata": {"problem_id": 641, "library_problem_id": 130, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 130}}
{"id": 642, "code": "fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n\nfor i, ax_i in enumerate(axs):\n    ax_i.plot(x, y, 'o-')\n    ax_i.set_title(f'Subplot {i+1}')\n\nplt.tight_layout()\npltthis = plt.show()\npltend = plt.end()\npltend.set_title('End')\npltend.plot(x, y, 'r.-')\npltend.plot(x, y, 'g.-')\npltend.plot(x, y, 'b.-')\npltend.plot(x, y, 'c.-')\npltend.plot(x, y, 'd.-')\npltend.plot(x, y, 'a.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npltend.plot(x, y, '.-')\npl", "metadata": {"problem_id": 642, "library_problem_id": 131, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 131}}
{"id": 643, "code": "\nplt.hist(x, bins=20, edgecolor='black', alpha=0.5,\n         # Make the histogram 30 bins and have 5 bars in the histogram\n         bins=5,\n         # Make the bar width 2 units\n         width=2,\n         # Make the bar color black\n         color='black',\n         # Make the bar transparency 0.5\n         alpha=0.5)\npltthis = plt.gca()\npltthis.set_xlabel('Bins')\nplt.show()\n", "metadata": {"problem_id": 643, "library_problem_id": 132, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 132}}
{"id": 644, "code": "plt.figure(figsize=(10, 5))\nplt.plot(x, y, 'o-', color='blue', label='Original')\nplt.plot(x, y, 'o-', color='red', label='Error')\nplt.fill_between(x, y, color='gray', alpha=0.5, \n                 label='Error')\nplt.legend()\nplt.show()\n", "metadata": {"problem_id": 644, "library_problem_id": 133, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 133}}
{"id": 645, "code": "plt.plot([0, 0], [0, 0], 'k', linewidth=2)\npltatarches.colorbar()\nplt.show()\n", "metadata": {"problem_id": 645, "library_problem_id": 134, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 134}}
{"id": 646, "code": "ax.bar(box_position, box_height, bottom=box_errors, color=c, edgecolor='None', alpha=0.5)\nplt.show()\n", "metadata": {"problem_id": 646, "library_problem_id": 135, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 135}}
{"id": 647, "code": "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, gridspec=((1, 2), (1, 2)))\n\nax1.plot(x, y, label='Y')\nax1.plot(x, z, label='Z')\nax1.set_title('Y')\nax2.plot(a, y, label='Y')\nax2.plot(a, z, label='Z')\nax2.set_title('Z')\nplt.tight_layout()\nplt.show()\n", "metadata": {"problem_id": 647, "library_problem_id": 136, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 136}}
{"id": 648, "code": "fig, ax = plt.subplots(figsize=(5,5))\n\nax.plot(x, y, 'r')\nax.tick_params(axis='both', labelsize=20)\nplt.show()\n", "metadata": {"problem_id": 648, "library_problem_id": 137, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 137}}
{"id": 649, "code": "plt.matshow(d, cmap='binary')\npltthis = plt.plt.Property()\nplt.title('Matplotlib plot')\nplt.show()\n", "metadata": {"problem_id": 649, "library_problem_id": 138, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 138}}
{"id": 650, "code": "fig, ax = plt.subplots()\nax.axis(\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],\n    [0, 0, 1, 1],", "metadata": {"problem_id": 650, "library_problem_id": 139, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 139}}
{"id": 651, "code": "fig, ax1 = plt.subplots()\nax1.plot(x, y, color='tab:red')\nax1.set_xlabel('X')\nax1.set_ylabel('Y')\nax1.tick_params(axis='both', labelsize=10)\npltthis = plt.gcf()\npltthis.canvas.ioutches += 1\nplt.show()\n", "metadata": {"problem_id": 651, "library_problem_id": 140, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 140}}
{"id": 652, "code": "fig, ax = plt.subplots()\nax.plot(x, y, 'r')\nax.set_xticks(x[::2], labels=['X'])\nax.set_yticks(y[::2], labels=['Y'])\nplt.show()\n", "metadata": {"problem_id": 652, "library_problem_id": 141, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 140}}
{"id": 653, "code": "plt.plot(x, y, label='y=x')\nplt.xlabel('x')\npltFERtick(visible=False)\nplt.ylabel('y')\npltFERtick(visible=False)\nplt.legend(['y=x'], loc='upper left', y=1.1, x=0)\nplt.show()\n", "metadata": {"problem_id": 653, "library_problem_id": 142, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 140}}
{"id": 654, "code": "\n# Split the dataframe into two dataframes based on the condition\ndf_fat = df[df[\"time\"]<=5]\ndf_no_fat = df[df[\"time\"]>5]\n\n# Make scatter plots\nplt.figure(figsize=(10, 8))\npltatar = sns.scatterplot(x=\"time\", y=\"pulse\", hue=\"kind\", data=df_fat, legend=False, palette=\"husl\",\n                           legend_labels=[\"Fat\"], title=\"Group: Fat\")\nplt.figure(figsize=(10, 8))\npltatar = sns.scatterplot(x=\"time\", y=\"pulse\", hue=\"kind\", data=df_no_fat, legend=False, palette=\"husl\",\n                           legend_labels=[\"No Fat\"], title=\"Group: No Fat\")\nplt.show()\n\n", "metadata": {"problem_id": 654, "library_problem_id": 143, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 143}}
{"id": 655, "code": "\n# Split the dataframe into two dataframes based on the condition\ndf_time = df[df[\"time\"]==1]\ndf_exercise = df[df[\"exercise\"]==1]\n\n# Make scatter plots\nplt.figure(figsize=(10, 8))\npltatarange = sns.scatterplot(x=df_exercise, y=df_time, hue=df_exercise, col=df_exercise, legend=False)\nplt.xlabel(\"Exercise Time\")\nplt.ylabel(\"Exercise Time\")\nplt.show()\n\n", "metadata": {"problem_id": 655, "library_problem_id": 144, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 143}}
{"id": 656, "code": "\ndf.plot(x='time', y='pulse', hue='kind', col='diet', kind='scatter', s=10, alpha=0.5,\n       figsize=(10, 8), grid=True,\n       sns_whic='dark',\n       palette='deep',\n       xlabel='time', ylabel='pulse', hue='kind',\n       legend=False,\n       # Do not show the line on the plot\n       line=False,\n       # Do not show the histogram on the plot\n       hist=False,\n       # Do not show the kdeplot on the plot\n       kde=False,\n       # Do not show the scatterplot on the plot\n       scatter=False,\n       # Do not show the violinplot on the plot\n       violin=False,\n       # Do not show the boxplot on the plot\n       box=False,\n       # Do not show the histplot on the plot\n       hist=False,\n       # Do not show the barplot on the plot\n       bar=False,\n       # Do not show the barplot on the plot\n       bar2d=False,\n       # Do not show the plot on the plot\n       plot=False,\n       # Do not show the series on the plot\n       series=False,\n       # Do not show the timeplot on the plot\n       time=False,\n       # Do not show the seriesplot on the plot\n       series=False,\n       # Do not show the swarmplot on the plot\n       swarm=False,\n       # Do not show the histplot on the plot\n       hist=False,\n       # Do not show the histplot on the plot\n       hist=False,\n       # Do not show the plot on the plot\n       show=False)\n\n", "metadata": {"problem_id": 656, "library_problem_id": 145, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 143}}
{"id": 657, "code": "plt.plot(x, y, label='y')\nplt.legend()\nplt.legend().set_visible(False)\nplt.show()\n", "metadata": {"problem_id": 657, "library_problem_id": 146, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 146}}
{"id": 658, "code": "plt.figure(figsize=(5, 5), dpi=300)\nplt.plot(x, y, 'r')\nplt.show()\n", "metadata": {"problem_id": 658, "library_problem_id": 147, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 147}}
{"id": 659, "code": "plt.plot(x, y, label='y')\nplt.legend()\npltthis = plt.gcf()\nplt.show()\nplt.savefig(plt.labeltext)\nplt.savefig(plt.legend)\nplt.savefig(plt.title)\nplt.savefig(plt.xlabel)\nplt.savefig(plt.ylabel)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.figsize)\nplt.savefig(plt.grid)\nplt.savefig(plt.xticks)\nplt.savefig(plt.yticks)\nplt.savefig(plt.tick_params)\nplt.savefig(plt.gridon)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.xlim)\nplt.savefig(plt.ylim)\nplt.savefig(plt.", "metadata": {"problem_id": 659, "library_problem_id": 148, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 148}}
{"id": 660, "code": "fig, ax = plt.subplots()\nax.plot(t, a, label='sin(t)')\nax.plot(t, b, label='cos(t)')\nax.plot(t, c, label='sin(t) + cos(t)')\nax.legend()\nplt.show()\n", "metadata": {"problem_id": 660, "library_problem_id": 149, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 149}}
{"id": 661, "code": "\n# Create a scatterplot for the data in df. Use \"species\" as x, \"bill_length_mm\" as y, and \"sex\" for the color\nplt.figure(figsize=(10, 6))\nsns.stripplot(x=\"species\", y=\"bill_length_mm\", hue=\"sex\", data=df, trunc=.1,\n             edgecolor=\".2\", linewidth=.2,\n             random_state=0)\npltthis = plt.gca()\nplt.gca().get_yaxis().set_ticklabels([])\nplt.gca().get_xaxis().set_ticklabels([])\nplt.gca().get_xaxis().set_visible(False)\nplt.gca().get_yaxis().set_visible(False)\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_title(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.gca().set_ylabel(\"\")\nplt.gca().set_xlabel(\"\")\nplt.", "metadata": {"problem_id": 661, "library_problem_id": 150, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 150}}
{"id": 662, "code": "\nfig, axes = plt.subplots(3, 1, figsize=(10, 10))\nfor i, ax_name in enumerate(axes):\n    ax = ax_name\n    ax.set_title(f\"{i}: {ax_name.__str__()}\")\n    sns.lineplot(x=df[\"a\"], y=df[\"c\"], ax=ax, palette=\"deep\", linewidth=10,\n                 marker=\"-\",\n                 xlim=(df[\"a\"].min(), df[\"a\"].max()),\n                 ylim=(df[\"c\"].min(), df[\"c\"].max()))\n    ax.set_xlabel(f\"{i}: {ax_name.__str__()}\")\npltatar\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupyter>\n<jupy", "metadata": {"problem_id": 662, "library_problem_id": 151, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 151}}
{"id": 663, "code": "fig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nsc = ax.scatter(x, y, z, s=10, edgecolors='gray')\n\n", "metadata": {"problem_id": 663, "library_problem_id": 152, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 152}}
{"id": 664, "code": "plt.plot(x, y, label='x')\nplt.plot(x, y, label='y')\npltFER\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\n", "metadata": {"problem_id": 664, "library_problem_id": 153, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 153}}
{"id": 665, "code": "fig, axes = plt.subplots(nrows=nrow, ncols=ncol, fig=fig)\nfig.tight_kws()\n\nfor i, axe in zip(range(nrow * ncol)):\n    axes[i].axis('off')\n    axes[i].plot(x[i])\n\npltthis = plt.show()\n", "metadata": {"problem_id": 665, "library_problem_id": 154, "library": "Matplotlib", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 154}}
{"id": 666, "code": "x = tf.Variable(1)\nx.assign(1)\nprint(x)", "metadata": {"problem_id": 666, "library_problem_id": 0, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 667, "code": "x.assign(114514)\nprint(x.numpy())", "metadata": {"problem_id": 667, "library_problem_id": 1, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 668, "code": "labels = tf.constant([0, 6, 5, 4, 2], dtype=tf.int32)\nresult = tf.one_hot(labels, depth=10, dtype=tf.int32)\n", "metadata": {"problem_id": 668, "library_problem_id": 2, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 2}}
{"id": 669, "code": "labels = tf.constant([0, 6, 5, 4, 2], dtype=tf.int32)\nresult = tf.one_hot(labels, depth=10, dtype=tf.int32)\n", "metadata": {"problem_id": 669, "library_problem_id": 3, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 2}}
{"id": 670, "code": "labels = tf.constant([0, 6, 5, 4, 2], dtype=tf.int32)\nresult = tf.one_hot(labels, depth=10, dtype=tf.int32)\nprint(result)\n", "metadata": {"problem_id": 670, "library_problem_id": 4, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 2}}
{"id": 671, "code": "\n    labels = tf.constant([0, 6, 5, 4, 2], dtype=tf.int32)\n    labels = tf.one_hot(labels, depth=10, dtype=tf.int32)\n    ### END SOLUTION\n    return labels\n", "metadata": {"problem_id": 671, "library_problem_id": 5, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 2}}
{"id": 672, "code": "labels = tf.constant([0, 6, 5, 4, 2], dtype=tf.int32)\nresult = tf.one_hot(labels, depth=10, dtype=tf.int32)\nprint(result)\n", "metadata": {"problem_id": 672, "library_problem_id": 6, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 2}}
{"id": 673, "code": "def my_map_func(i):\n  return tf.data.Dataset.from_tensor_slices([i, i+1, i+2]).map(tf.reduce_sum)\nds = tf.data.Dataset.from_tensor_slices(input).map(my_map_func)\nds = ds.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(tf.range(x, x+3)))\nresult = tf.data.Dataset.flat_map(lambda x: tfior range(x, x+3))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))\nresult = tf.data.Dataset.flat_map(lambda x: tf.data.Dataset.from_tensor_slices([x, x+1, x+2]))", "metadata": {"problem_id": 673, "library_problem_id": 7, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 7}}
{"id": 674, "code": "\n    result = [input, input+1, input+2]\n    ### END SOLUTION\n    return result\n\nds = tf.data.Dataset.from_tensor_slices(example_input)\nds = ds.map(map_func=lambda x: tf.py_func(func=f, inp=[x], Tout=[tf.int64]))\nelement = tf.compat.v1.data.make_one_shot_iterator(ds).get_next()\nresult = []\nwith tf.compat.v1.Session() as sess:\n    for _ in range(9):\n        result.append(sess.run(element))\nprint(result)\n", "metadata": {"problem_id": 674, "library_problem_id": 8, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 7}}
{"id": 675, "code": "lengths = tf.constant([4, 3, 5, 2], dtype=tf.int32)\npadded_tensor = tf.pad_and_truncate(tf.ones((4, 4, 4, 4), dtype=tf.int32), [[0, 3-lengths[0]), (0, 3-lengths[1]), (0, 3-lengths[2]), (0, 3-lengths[3])}, [0, 3])\n", "metadata": {"problem_id": 675, "library_problem_id": 9, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 676, "code": "lengths = tf.constant([4, 3, 5, 2], dtype=tf.int32)\nlengths = tf.expand_dims(lengths, 0) + tf.range(8)\nresult = tf.where(lengths[:,1:] < lengths[:,:-1], tf.ones_like(lengths), tf.zeros_like(lengths))\n", "metadata": {"problem_id": 676, "library_problem_id": 10, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 9}}
{"id": 677, "code": "lengths = tf.constant([4, 3, 5, 2], dtype=tf.int32)\nlengths = tf.expand_dims(lengths, 0) + tf.range(8)\nresult = tf.where(lengths[:,1:] < lengths[:,:-1], tf.ones_like(lengths), tf.zeros_like(lengths))\n", "metadata": {"problem_id": 677, "library_problem_id": 11, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 9}}
{"id": 678, "code": "\n    max_length = 8\n    tensor = tf.constant([0,0,0,0,1,1,1,1])\n    mask = tf.sequence_length_tensor(tensor,max_length)\n    return mask\n", "metadata": {"problem_id": 678, "library_problem_id": 12, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 679, "code": "lengths = tf.constant([4, 3, 5, 2], dtype=tf.int32)\npadding_length = 8\nresult = tf.sequence_length_range(lengths, maximum=padding_length)\nprint(result)\n", "metadata": {"problem_id": 679, "library_problem_id": 13, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 9}}
{"id": 680, "code": "result = tf.tensorflow.py_function(tf.expand_dims(a,axis=0) * tf.expand_dims(b,axis=0), shapes=(2,), name='mul')", "metadata": {"problem_id": 680, "library_problem_id": 14, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 14}}
{"id": 681, "code": "\n    result = tf.concatenate_v2(tf.expand_dims(a,axis=1) * tf.expand_dims(b,axis=1), axis=1)\n    ### END SOLUTION\n    return result\n", "metadata": {"problem_id": 681, "library_problem_id": 15, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 14}}
{"id": 682, "code": "result = tf.reshape(a, [50, 100, -1])", "metadata": {"problem_id": 682, "library_problem_id": 16, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 683, "code": "result = tf.expand_dims(a, [1, 2])", "metadata": {"problem_id": 683, "library_problem_id": 17, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 16}}
{"id": 684, "code": "result = tf.expand_dims(a, [1, 2])", "metadata": {"problem_id": 684, "library_problem_id": 18, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 16}}
{"id": 685, "code": "result = tf.reduce_sum(A,axis=1)", "metadata": {"problem_id": 685, "library_problem_id": 19, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 19}}
{"id": 686, "code": "result = tf.reduce_prod(A,axis=1)\n", "metadata": {"problem_id": 686, "library_problem_id": 20, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 19}}
{"id": 687, "code": "reciprocal = 1 / A\n", "metadata": {"problem_id": 687, "library_problem_id": 21, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 19}}
{"id": 688, "code": "a_squared = tf.square(a)\nb_squared = tfatar.square(b)\ndifference = tf.sub(a_squared, b_squared)\nl2_distance = tf.reduce_sum(difference, axis=tf.range(len(difference))))\n", "metadata": {"problem_id": 688, "library_problem_id": 22, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 22}}
{"id": 689, "code": "l2_distance = tf.reduce_sum(tf.square(a - b), axis=axis)", "metadata": {"problem_id": 689, "library_problem_id": 23, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 22}}
{"id": 690, "code": "\n    result = tf.reduce_sum(tf.square(tf.sub(A,B)),axis=axis=axis)\n    return result\n\nprint(f(A,B))\n", "metadata": {"problem_id": 690, "library_problem_id": 24, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 22}}
{"id": 691, "code": "m = tf.tensorflow.reduce_sum(x[y,z],axis=0)\n", "metadata": {"problem_id": 691, "library_problem_id": 25, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 25}}
{"id": 692, "code": "m = tf.gather_nd(x, tf.stack([row,col]))\n", "metadata": {"problem_id": 692, "library_problem_id": 26, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 25}}
{"id": 693, "code": "\n    result = tf.tensor_scatter_nd(x, [y,z], transpose=[1,0]).numpy().tolist()\n    return result\nprint(f(x=example_x,y=example_y,z=example_z))\n", "metadata": {"problem_id": 693, "library_problem_id": 27, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 25}}
{"id": 694, "code": "result = tf.reduce_sum(tf.expand_dims(tf.matmul(tf.expand_dims(A,2),tf.expand_dims(B,2)),-1, -1) ,axis=2)\n", "metadata": {"problem_id": 694, "library_problem_id": 28, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 28}}
{"id": 695, "code": "result = tf.reduce_sum(tf.expand_dims(tf.matmul(tf.expand_dims(A,2),tf.expand_dims(B,2)),-1, -1) ,axis=2, axis=0)\n", "metadata": {"problem_id": 695, "library_problem_id": 29, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 28}}
{"id": 696, "code": "x = tf.strings.bytes_join(x)", "metadata": {"problem_id": 696, "library_problem_id": 30, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 30}}
{"id": 697, "code": "\n    result = tf.strings.as_string(x)\n    ### END SOLUTION\n    print(result)\n", "metadata": {"problem_id": 697, "library_problem_id": 31, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 30}}
{"id": 698, "code": "x_sum = tf.reduce_sum(x, axis=[-1, -2], keepdims=True)\nnon_zero_sum = tf.reduce_sum(tf.where(tf.equal(x, 0), np.float32(0), axis=[-1, -2], keepdims=True), axis=[-1, -2], keepdims=True)\nresult = tf.divide(x_sum, non_zero_sum)\n", "metadata": {"problem_id": 698, "library_problem_id": 32, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 699, "code": "x = tf.reduce_sum(x, axis=2, keepdims=True, name=None)\nx = tf.reduce_sum(x, axis=1, keepdims=True, name=None)\nx = tfatar.reduce_sum(x, axis=0, keepdims=True, name=None)\n", "metadata": {"problem_id": 699, "library_problem_id": 33, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 32}}
{"id": 700, "code": "\n    x = tf.reduce_sum(x, axis=[1,2,3], keepdims=True)\n    x_sum = tf.reduce_sum(x, axis=1, keepdims=True)\n    x_sum_flat = tf.reshape(x_sum, [tf.shape(x)[0], -1])\n    x_flat = tf.reshape(x, [tf.shape(x)[0], -1])\n    x_flat_flat = tfatar.reshape(x_flat, [tf.shape(x)[0], -1])\n    result = tf.reduce_sum(x_flat_flat, axis=1, keepdims=True)/tf.reduce_sum(x_sum_flat, axis=1, keepdims=True)\n    ### END SOLUTION\n    return result\n", "metadata": {"problem_id": 700, "library_problem_id": 34, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 32}}
{"id": 701, "code": "import tensorflow as tf\n\nSession = tf.compat.v1.Session\ntf.random.set_seed(10)\nA = tf.random.normal([100,100])\nB = tf.random.normal([100,100])\nwith Session() as sess:\n    result = sess.run(tf.reduce_sum(tf.matmul(A,B)))\n", "metadata": {"problem_id": 701, "library_problem_id": 35, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 35}}
{"id": 702, "code": "result = tf.argmax(a, axis=1)", "metadata": {"problem_id": 702, "library_problem_id": 36, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 703, "code": "result = tf.argmax(a, axis=1)", "metadata": {"problem_id": 703, "library_problem_id": 37, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 36}}
{"id": 704, "code": "\n    scores = tf.argmax(a, axis=1)\n    ### END SOLUTION\n    return scores\n", "metadata": {"problem_id": 704, "library_problem_id": 38, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 36}}
{"id": 705, "code": "result = tf.argmin(a, axis=1)\n", "metadata": {"problem_id": 705, "library_problem_id": 39, "library": "Tensorflow", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 36}}
{"id": 706, "code": "\nmodel.save(\"my_model\")\n", "metadata": {"problem_id": 706, "library_problem_id": 40, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 40}}
{"id": 707, "code": "tf.random.set_seed(seed_x)\nresult = tf.random.uniform([], minval=1, maxval=4, dtype=tf.int64)\n", "metadata": {"problem_id": 707, "library_problem_id": 41, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 41}}
{"id": 708, "code": "tf.random.set_seed(seed_x)\n\ndist = tf.distributions.Uniform(low=2, high=5)\nresult = tf.random.uniform(shape=[114], minval=2, maxval=5)", "metadata": {"problem_id": 708, "library_problem_id": 42, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 41}}
{"id": 709, "code": "\n    tf.random.set_seed(seed_x)\n    result = tf.random.uniform([], minval=1, maxval=4, dtype=tf.int64)\n    return result\n\nprint(f(10))\n", "metadata": {"problem_id": 709, "library_problem_id": 43, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 41}}
{"id": 710, "code": "import tensorflow as tf\nprint(tf2.__version__)\n", "metadata": {"problem_id": 710, "library_problem_id": 44, "library": "Tensorflow", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 44}}
{"id": 711, "code": "coefficients = np.polyfit(x, y, 1)\nresult = coefficients\nEND SOLUTION\ncoefficients[0] is the coefficient for y, coefficients[1] is the coefficient for x.\n\nWhat I want to achieve is to fit a polynomial of order 2 (y = A*x^2 + B*x + C) to the data points.\n<code>\ncoefficients = np.polyfit(x, y, 2)\nresult = coefficients\nEND SOLUTION\ncoefficients[0] is the coefficient for y, coefficients[1] is the coefficient for x and coefficients[2] is the coefficient for x^2.\n\nI want to fit a polynomial of order 2 to the data points.\n", "metadata": {"problem_id": 711, "library_problem_id": 0, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 712, "code": "coefficients = np.polyfit(x, y, 2)\nresult = coefficients[0] + coefficients[1]*np.power(x, 2)\nEND SOLUTION\n\nIn the above code, coefficients[0] and coefficients[1] are the coefficients of the polynomial of degree 2. The coefficients[0] is the constant term and coefficients[1] is the linear term.\n\nThe result is the sum of the coefficients.\n", "metadata": {"problem_id": 712, "library_problem_id": 1, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 0}}
{"id": 713, "code": "result, _ = scipy.optimize.curve_fit(y, x, p0)\n", "metadata": {"problem_id": 713, "library_problem_id": 2, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 0}}
{"id": 714, "code": "test_stat, p_value = stats.ks_2samp(x, y)\n", "metadata": {"problem_id": 714, "library_problem_id": 3, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 3}}
{"id": 715, "code": "test_stat, result = stats.ks_2samp(x, y)\nreject_flag = test_stat < alpha", "metadata": {"problem_id": 715, "library_problem_id": 4, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 3}}
{"id": 716, "code": "def f(variables):\n    a, b, c = variables\n    return ((a + b - c - 2) ** 2 + (3 * a - b - c) ** 2 + sin(b) + cos(b) + 4)\n\nresult, success = optimize.minimize(f, initial_guess)\n", "metadata": {"problem_id": 716, "library_problem_id": 5, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 5}}
{"id": 717, "code": "p_values = scipy.stats.zscore(z_scores)", "metadata": {"problem_id": 717, "library_problem_id": 6, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 6}}
{"id": 718, "code": "p_values = [2*(1 + scipy.stats.norm.cdf(z, mu, sigma)) for z in z_scores]\n", "metadata": {"problem_id": 718, "library_problem_id": 7, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 6}}
{"id": 719, "code": "z_scores = [scipy.stats.norm.ppf(1-p, loc=0, scale=1) for p in p_values]", "metadata": {"problem_id": 719, "library_problem_id": 8, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 6}}
{"id": 720, "code": "dist = stats.norm.cdf(x, mu, stddev)\nresult = dist", "metadata": {"problem_id": 720, "library_problem_id": 9, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 721, "code": "expected_value = np.mean(dist.mean(), dist.std(), ddof=1)\nmedian = np.median(dist.mean(), dist.std(), ddof=1)", "metadata": {"problem_id": 721, "library_problem_id": 10, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 9}}
{"id": 722, "code": "result = sa.multiply(sb)\n", "metadata": {"problem_id": 722, "library_problem_id": 11, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 11}}
{"id": 723, "code": "\n    result = sparse.csr_matrix(np.where(sA.indices==sB.indices,sA.data+sB.data,0))\n    ### END SOLUTION\n    return result\n", "metadata": {"problem_id": 723, "library_problem_id": 12, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 11}}
{"id": 724, "code": "interpolator = scipy.interpolate.LinearNDInterpolator(points, V)\nresult = interpolator(request)", "metadata": {"problem_id": 724, "library_problem_id": 13, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 13}}
{"id": 725, "code": "interp = scipy.interpolate.LinearNDInterpolator(points, V)\nresult = interp(request)", "metadata": {"problem_id": 725, "library_problem_id": 14, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 13}}
{"id": 726, "code": "data_rot, xrot, yrot = rotate(data_orig, angle, res=1, mode='nearest',\n                            x_translation=x0, y_translation=y0)", "metadata": {"problem_id": 726, "library_problem_id": 15, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 15}}
{"id": 727, "code": "diag = M.diagonal()", "metadata": {"problem_id": 727, "library_problem_id": 16, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 728, "code": "result = stats.kstest(times, \"uniform\")\nprint(result)", "metadata": {"problem_id": 728, "library_problem_id": 17, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 17}}
{"id": 729, "code": "\n    result = stats.kstest('uniform', times)\n    return result\nresult = f(example_times, example_rate, example_T)\nprint(result)\n", "metadata": {"problem_id": 729, "library_problem_id": 18, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 17}}
{"id": 730, "code": "result = stats.kstest(times, \"uniform\")\n", "metadata": {"problem_id": 730, "library_problem_id": 19, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 17}}
{"id": 731, "code": "Feature = sparse.vstack([c1, c2])", "metadata": {"problem_id": 731, "library_problem_id": 20, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 20}}
{"id": 732, "code": "Feature = sparse.vstack([c1, c2])", "metadata": {"problem_id": 732, "library_problem_id": 21, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 20}}
{"id": 733, "code": "Feature = sparse.vstack([c1, c2])", "metadata": {"problem_id": 733, "library_problem_id": 22, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 20}}
{"id": 734, "code": "distances = np.sqrt(np.sum(points1**2,axis=1) - 2*points1*points1)\nresult, _ = scipy.optimize.nnpackal(points1, distances)\n", "metadata": {"problem_id": 734, "library_problem_id": 23, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 23}}
{"id": 735, "code": "distances = np.sqrt(np.sum(points1**2,axis=1) - 2*(points1.T**2) )\npoints2_indices = list(range(points2.shape[0]))\nmatching = scipy.spatial.distance.cdist(points2, points1, 'euclidean')\nmatching = list(zip(matching.flat, points2_indices))\nmatching.sort(key=lambda x:x[0])\nresult = np.array([matching[i][1] for i in range(matching.shape[0])])\nEND SOLUTION\n\nThe result is the assignment of points in second set to corresponding elements in the first set.\n", "metadata": {"problem_id": 735, "library_problem_id": 24, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 23}}
{"id": 736, "code": "b.setdiag(0)\n", "metadata": {"problem_id": 736, "library_problem_id": 25, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 25}}
{"id": 737, "code": "threshold = 0.75\nresult = np.sum(img > threshold)", "metadata": {"problem_id": 737, "library_problem_id": 26, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 26}}
{"id": 738, "code": "threshold = 0.75\nresult = np.where(img > threshold, 1, 0)\n", "metadata": {"problem_id": 738, "library_problem_id": 27, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 26}}
{"id": 739, "code": "\n    _, labels, num_labels = ndimage.measurements.label(img > threshold, 1)\n    ### END SOLUTION\n    return labels\n", "metadata": {"problem_id": 739, "library_problem_id": 28, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 26}}
{"id": 740, "code": "from skimage.measure import label, region_props, label_adjacency\n\nthreshold = 0.75\n\n# Applying the threshold to get the binary image\n_, _, _, rp = label.find_region(img, threshold, mask=~(img>0.75))\n\n# Labels are 1-based, so we need to subtract 1 to get the actual labels\nlabels = rp.label_map(data=label+1) - 1\n\n# Now, we find the properties of the labels\nfor i in range(1, labels.max()+1):\n    if rp.area >= rp.min()*0.9:\n        print(i)\n        print(rp.area)\n        print(rp.centroid)\n        print(rp.min_points)\n        print(rp.max_points)\n", "metadata": {"problem_id": 740, "library_problem_id": 29, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 26}}
{"id": 741, "code": "M = M.copy()\nM = M.transpose()\n", "metadata": {"problem_id": 741, "library_problem_id": 30, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 30}}
{"id": 742, "code": "\n    sA = sA.copy()\n    sA.data = np.where(sA.data < sA.transpose().data, sA.transpose().data, sA.data)\n    ### END SOLUTION\n    return sA\n", "metadata": {"problem_id": 742, "library_problem_id": 31, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 30}}
{"id": 743, "code": "import scipy.ndimage\nlabels, num_labels = scipy.ndimage.label(square)\nfor i in range(1, num_labels+1):\n    if i==1:\n        continue\n    square[labels==i] = 0\n", "metadata": {"problem_id": 743, "library_problem_id": 32, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 744, "code": "import scipy.ndimage\nlabels, num = scipy.ndimage.measurements.label(square)\nfor i in range(1, num+1):\n    square[labels==i] = 0", "metadata": {"problem_id": 744, "library_problem_id": 33, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 32}}
{"id": 745, "code": "mean = np.mean(col.toarray())\nstandard_deviation = npatar.std(col.toarray())\n", "metadata": {"problem_id": 745, "library_problem_id": 34, "library": "Scipy", "test_case_cnt": 4, "perturbation_type": "Origin", "perturbation_origin_id": 34}}
{"id": 746, "code": "max_val = np.max(col)\nmin_val = npatar.min(col)\n", "metadata": {"problem_id": 746, "library_problem_id": 35, "library": "Scipy", "test_case_cnt": 4, "perturbation_type": "Semantic", "perturbation_origin_id": 34}}
{"id": 747, "code": "median = col.median()\nmode = col.mode()[0]\n", "metadata": {"problem_id": 747, "library_problem_id": 36, "library": "Scipy", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 34}}
{"id": 748, "code": "def fourier(x, a1, a2, a3, a4, a5, a6, a7, a8):\n    return a1 * np.cos(1 * np.pi / tau * x) + \\\n           a2 * np.cos(2 * np.pi / tau * x) + \\\n           a3 * np.cos(3 * np.pi / tau * x) + \\\n           a4 * np.cos(4 * np.pi / tau * x) + \\\n           a5 * np.cos(5 * np.pi / tau * x) + \\\n           a6 * np.cos(6 * np.pi / tau * x) + \\\n           a7 * np.cos(7 * np.pi / tau * x) + \\\n           a8 * np.cos(8 * np.pi / tau * x)\npopt, pcov = curve_fit(fourier, z, Ua)\n", "metadata": {"problem_id": 748, "library_problem_id": 37, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 37}}
{"id": 749, "code": "def calculate_distances(array):\n    # Calculate the distance between all pairs of cells\n    distances = scipm.spatial.distance.pdist(array.flatten(), metric='euclidean')\n    # Convert distances to the desired units (m) by multiplying by the raster resolution\n    distances = distances.flatten() * np.sqrt(np.sum(np.isin(array, np.where(~np.isnan(distances), range(1, distances.shape[0]+1), np.nan))))\n    # Convert to the desired format (ID from, ID to, distance)\n    result = [(i, j, z) for i, j, z in zip(range(len(distances)), range(len(distances)), distances)]\n    return result\n", "metadata": {"problem_id": 749, "library_problem_id": 38, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 38}}
{"id": 750, "code": "import scipy.spatial\nresult = scipy.spatial.distance.p2dist_array(example_array, radius=1, data=None,\n                                               mahattan=True, p=2,\n                                               index=-1, d=None,\n                                               s=None, minimum=False,\n                                               n=None, x=None, y=None,\n                                               metric=None,\n                                               p=2, exact=False,\n                                               no_data=False,\n                                               no_colors=False,\n                                               no_edges=False,\n                                               no_vertices=False,\n                                               no_border=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n                                               no_colors=False,\n", "metadata": {"problem_id": 750, "library_problem_id": 39, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 38}}
{"id": 751, "code": "\n    # Convert IDs to coordinates\n    points = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [10, 10], [11, 11]])\n    # Calculate distances\n    distances = scip.spatial.distance.p2pdist(points, data=example_array, radius=1)\n    ### END SOLUTION\n    return distances\n", "metadata": {"problem_id": 751, "library_problem_id": 40, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 38}}
{"id": 752, "code": "result = np.empty((x.shape[1], x_val.shape[1], x.shape[0]))\nfor i in range(x.shape[1]):\n    for j in range(x_val.shape[1]):\n        tck, u = interpolate.splprep([x[i, j], x[(i+1)%x.shape[0], j], x[(i+1)%x.shape[0]-1, j], x[(i+1)%x.shape[0]-1,-1]], \n                                     [x[i, j], x[(i+1)%x.shape[0], j], x[(i+1)%x.shape[0]-1, j], x[(i+1)%x.shape[0]-1,-1], x[(i+1)%x.shape[0]-1,-1]], \n                                     degree = 3, s = 4)\n        result[i, :, j] = interpolate.splev(x_val, tck, 0)\n", "metadata": {"problem_id": 752, "library_problem_id": 41, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 41}}
{"id": 753, "code": "statistic, critical_values, significance_level = ss.anderson_sagree(*zip(x1,x2,x3,x4))", "metadata": {"problem_id": 753, "library_problem_id": 42, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 42}}
{"id": 754, "code": "result = ss.anderson_ksamp([x1,x2],significance_level=0.05)", "metadata": {"problem_id": 754, "library_problem_id": 43, "library": "Scipy", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 42}}
{"id": 755, "code": "def tau1(x):\n    y = np.array(A['A'])\n    tau, p_value = stats.kendalltau(x, y)\n    return tau\n\ndf['AB'] = pd.rolling_apply(A['B'], 3, lambda x: tau1(x))", "metadata": {"problem_id": 755, "library_problem_id": 44, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 44}}
{"id": 756, "code": "result = sparse.is_empty(sa)\n", "metadata": {"problem_id": 756, "library_problem_id": 45, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 45}}
{"id": 757, "code": "def is_lil_matrix_only_zeroes(my_lil_matrix):\n    return my_lil_matrix.nnz == 0", "metadata": {"problem_id": 757, "library_problem_id": 46, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 45}}
{"id": 758, "code": "result = block_diag(*a)", "metadata": {"problem_id": 758, "library_problem_id": 47, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 47}}
{"id": 759, "code": "result = stats.ranksums(pre_course_scores, during_course_scores)\np_value = result.pvalue", "metadata": {"problem_id": 759, "library_problem_id": 48, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 48}}
{"id": 760, "code": "\n    t_statistic, p_value = stats.ranksums(pre_course_scores, during_course_scores)\n    ### END SOLUTION\n    return p_value\n", "metadata": {"problem_id": 760, "library_problem_id": 49, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 48}}
{"id": 761, "code": "import scipy.stats\nkurtosis_result = scipy.stats.kurtosis(a,fisherian=False)\n", "metadata": {"problem_id": 761, "library_problem_id": 50, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 50}}
{"id": 762, "code": "kurtosis_result = scipy.stats.kurtosis(a, fisher=True)\n", "metadata": {"problem_id": 762, "library_problem_id": 51, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 50}}
{"id": 763, "code": "interp = scipy.interpolate.interp2d(s, t, z, kind='cubic' )", "metadata": {"problem_id": 763, "library_problem_id": 52, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 52}}
{"id": 764, "code": "\n    s1, t1 = np.random.choice(a=exampls_s, size=2, replace=False)\n    s2, t2 = np.random.choice(a=example_t, size=2, replace=False)\n    s = np.array([s1, s2])\n    t = np.array([t1, t2])\n    return s, t\n    ### END SOLUTION\n    # return the interpolated values\n    return z\n", "metadata": {"problem_id": 764, "library_problem_id": 53, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 52}}
{"id": 765, "code": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.spatial import ConvexHull\n\nfig, ax = plt.subplots()\npoints = np.array([[0,0], [1,4], [2,3], [4,1], [1,1], [2,2], [5,3]])\nconvex_hull = ConvexHull(points)\nvor = convex_hull.points\nextraPoints = np.array([[0.5,0.2], [3, 0], [4,0],[5,0], [4,3]])\n\nvor = scipy.spatial.Voronoi(extraPoints)\nresult = vor.ridge_points\nresult.sort()\nplt.plot()\n", "metadata": {"problem_id": 765, "library_problem_id": 54, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 766, "code": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.spatial import ConvexHull\n\nfig, ax = plt.subplots()\npoints = np.array([[0,0], [1,4], [2,3], [4,1], [1,1], [2,2], [5,3]])\nconvex_hull = ConvexHull(points)\nvor = convex_hull.points\nextraPoints = np.array([[0.5,0.2], [3, 0], [4,0],[5,0], [4,3]])\n\nvor.plot(ax=ax, color='r', label='Voronoi')\nextraPoints.plot(ax=ax, color='g', label='Extra points')\npltatarches = convex_hull.convex_maps\nplt.show()", "metadata": {"problem_id": 766, "library_problem_id": 55, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 767, "code": "max_size = max([len(v) for v in vectors])\npadded_vectors = []\nfor vector in vectors:\n    padded_vector = np.pad(vector, (0, max_size - len(vector)), 'constant')\n    padded_vectors.append(padded_vector)\nresult = sparse.vstack(padded_vectors)\n", "metadata": {"problem_id": 767, "library_problem_id": 56, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 56}}
{"id": 768, "code": "import scipy.ndimage\n\ndef shift_right(a):\n    return scipy.ndimage.median_filter(a, 3, 1)\n\nb = shift_right(a)\nEND SOLUTION\n", "metadata": {"problem_id": 768, "library_problem_id": 57, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 57}}
{"id": 769, "code": "data_items = M.A[row,column]", "metadata": {"problem_id": 769, "library_problem_id": 58, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 58}}
{"id": 770, "code": "result = [M[i, column[i]] for i in range(len(row))]", "metadata": {"problem_id": 770, "library_problem_id": 59, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 58}}
{"id": 771, "code": "for i in range(array.shape[0]):\n    for j in range(array.shape[1]):\n        for k in range(array.shape[2]):\n            f = scipy.interpolate.interp1d(x, array[i, j, :])\n            new_array[i, j, :] = f(x_new)\nEND SOLUTION\n", "metadata": {"problem_id": 771, "library_problem_id": 60, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 60}}
{"id": 772, "code": "dev = abs((x-u)/o2)\nP_inner = scipy.integrate(NDfx,-dev,dev)\nP_outer = 1 - P_inner\nP = P_inner + P_outer/2\nreturn(P)\nEND SOLUTION\n\nThe error is caused by the scipy.integrate function not being recognized. It seems to be a typo in the function names. The correct function names are `integrate` and `integrate2d`.\n\nThe corrected code should be:\n\n```python\nimport scipy.integrate\nimport math\nimport numpy as np\ndef NDfx(x):\n    return((1/math.sqrt((2*math.pi)))*(math.e**((-.5)*(x**2))))\nx = 2.5\nu = 1\no2 = 3\nP = scipy.integrate.integrate(NDfx,0,x-u/o2)\nreturn(P)\n```\n", "metadata": {"problem_id": 772, "library_problem_id": 61, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 61}}
{"id": 773, "code": "\n    dev = abs((x-u)/o2)\n    P_inner = scipy.integrate(NDfx,-dev,dev)\n    P_outer = 1 - P_inner\n    P = P_inner + P_outer/2\n    return(P)\n\nb:\n<code>\nimport scipy.integrate\nimport math\nimport numpy as np\ndef NDfx(x):\n    return((1/math.sqrt((2*math.pi)))*(math.e**((-.5)*(x**2))))\ndef f(x = 2.5, u = 1, o2 = 3):\n    # return the solution in this function\n    # prob = f(x, u, o2)\n    ### END SOLUTION\n\nThe error is occurring because the function `NDfx` is not defined in the scope of the `scipy.integrate`.\n\nThe function `NDfx` is defined in the scope of the `scipy.integrate`, but the arguments `-dev,dev` are not defined in the scope of the `scipy.integrate`.\n\nThe function `NDfx` is defined in the scope of the `scipy.integrate`, and the arguments `-dev,dev` are defined in the scope of the `scipy.integrate`.\n", "metadata": {"problem_id": 773, "library_problem_id": 62, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 61}}
{"id": 774, "code": "result = sf.dct(np.eye(N,dtype=np.float32), norm='2d')", "metadata": {"problem_id": 774, "library_problem_id": 63, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 63}}
{"id": 775, "code": "diags(matrix, [1,0,-1], 0).toarray()\n", "metadata": {"problem_id": 775, "library_problem_id": 64, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 64}}
{"id": 776, "code": "result = np.fromfunction(lambda i, j: scipy.stats.binom.pmf(i, p) * np.power(p, i) * npatarapy.stats.binom.pmf(j, p) * np.power(1-p, i-j), i, j)", "metadata": {"problem_id": 776, "library_problem_id": 65, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 65}}
{"id": 777, "code": "import pandas as pd\nimport io\nfrom scipy import stats\n\ntemp=u\"\"\"probegenes,sample1,sample2,sample3\n1415777_at Pnliprp1,20,0.00,11\n1415805_at Clps,17,0.00,55\n1415884_at Cela3b,47,0.00,100\"\"\"\ndf = pd.read_csv(io.StringIO(temp),index_col='probegenes')\n\nz = (df - df.mean()).divide(df.std())", "metadata": {"problem_id": 777, "library_problem_id": 66, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 66}}
{"id": 778, "code": "import pandas as pd\nimport io\nfrom scipy import stats\n\ntemp=u\"\"\"probegenes,sample1,sample2,sample3\n1415777_at Pnliprp1,20,0.00,11\n1415805_at Clps,17,0.00,55\n1415884_at Cela3b,47,0.00,100\"\"\"\ndf = pd.read_csv(io.StringIO(temp),index_col='probegenes')\n\nz = (df - df.mean()).divide(df.std())", "metadata": {"problem_id": 778, "library_problem_id": 67, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 66}}
{"id": 779, "code": "import pandas as pd\nimport io\nfrom scipy import stats\n\ntemp=u\"\"\"probegenes,sample1,sample2,sample3\n1415777_at Pnliprp1,20,0.00,11\n1415805_at Clps,17,0.00,55\n1415884_at Cela3b,47,0.00,100\"\"\"\ndf = pd.read_csv(io.StringIO(temp),index_col='probegenes')\n\ndf['zscore'] = df.apply(lambda row: stats.zscore(row[['sample1','sample2','sample3']],nan_policy='omit')[0],axis=1)\nresult = df[['sample1','sample2','sample3']]\nresult.columns = ['data','zscore']\nresult.reset_index(['probegenes'],inplace=True)\nresult", "metadata": {"problem_id": 779, "library_problem_id": 68, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 66}}
{"id": 780, "code": "df.reset_index()\ndf.columns = ['sample1','sample2','sample3']\nresult = df.apply(lambda x: pd.to_timedelta(x.apply(lambda y: stats.zscore(y.dropna().astype(float),nan_policy='omit'))))\nresult.columns = ['sample1','sample2','sample3']\nresult.reset_index()\nresult", "metadata": {"problem_id": 780, "library_problem_id": 69, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 66}}
{"id": 781, "code": "result, success, info = scipy.optimize.line_search(test_func, test_grad, starting_point, direction)\nEND SOLUTION\nresult\n", "metadata": {"problem_id": 781, "library_problem_id": 70, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 70}}
{"id": 782, "code": "def get_distance_2(y, x):\n    mid = np.array([[3.53553391, 2.91547595, 2.54950976, 2.54950976, 2.91547595, 3.53553391],\n                   [2.91547595, 2.12132034, 1.58113883, 1.58113883, 2.12132034, 2.91547595],\n                   [2.54950976, 1.58113883, 0.70710678, 0.70710678, 1.58113883, 2.54950976],\n                   [2.54950976, 1.58113883, 0.70710678, 0.70710678, 1.58113883, 2.54950976],\n                   [2.91547595, 2.12132034, 1.58113883, 1.58113883, 2.12132034, 2.91547595],\n                   [3.53553391, 2.91547595, 2.54950976, 2.54950976, 2.91547595, 3.53553391]])\n\nresult = np.sqrt(np.sum(np.square(y-x), axis=-1))", "metadata": {"problem_id": 782, "library_problem_id": 71, "library": "Scipy", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 71}}
{"id": 783, "code": "def get_distance_2(y, x):\n    mid = np.rollaxis(y, axis1=1, shift1=1, axis2=2, shift2=1)\n    return np.rollaxis(distance.distance_transform_cdist(y, mid), axis1=1, shift1=1, axis2=2, shift2=1)\n", "metadata": {"problem_id": 783, "library_problem_id": 72, "library": "Scipy", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 71}}
{"id": 784, "code": "\n    y, x = np.ogrid[:shape]\n    mid = np.sqrt(((x-y[:,:,0],2))**2 + ((x-y[:,:,1],2))**2))\n    return mid\n", "metadata": {"problem_id": 784, "library_problem_id": 73, "library": "Scipy", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 71}}
{"id": 785, "code": "from scipy.ndimage import zoom\nresult = zoom(x, 2, order=1)\n", "metadata": {"problem_id": 785, "library_problem_id": 74, "library": "Scipy", "test_case_cnt": 4, "perturbation_type": "Origin", "perturbation_origin_id": 74}}
{"id": 786, "code": "out = scipy.optimize.least_squares(func, x0, yerr=y)\nprint(out.x)\n", "metadata": {"problem_id": 786, "library_problem_id": 75, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 75}}
{"id": 787, "code": "out = scipy.optimize.minimize(lambda x: ((x - x_lower_bounds) ** 2).sum(), x0, bounds=(-100, None))\noptimal_x = x_true + out.x", "metadata": {"problem_id": 787, "library_problem_id": 76, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 75}}
{"id": 788, "code": "\ndef dN1_dt(t, N1):\n    return -100*N1 + np.sin(t)\nsol = solve_ivp(fun=dN1_dt, t_span=time_span, y0=[N0,])\nresult = sol.y\n", "metadata": {"problem_id": 788, "library_problem_id": 77, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 77}}
{"id": 789, "code": "\ndef dN1_dt_timevarying(t, N1):\n    return -100 * np.sin(t) if 0 < t < 2*np.pi else 2*npataric\nsol = solve_ivp(fun=dN1_dt_timevarying, t_span=[0, 10], y0=[N0,])\nresult = sol.y", "metadata": {"problem_id": 789, "library_problem_id": 78, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 77}}
{"id": 790, "code": "\ndef dN1_dt_complex(t, N1):\n    return -100 * np.cos(t) - 100 * npior.sin(t)\nsol = scipy.integrate.solve_ivp(fun=dN1_dt_complex, t_span=time_span, y0=[N0,])\nresult = sol.y\nEND SOLUTION\n", "metadata": {"problem_id": 790, "library_problem_id": 79, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 77}}
{"id": 791, "code": "\nfor t in range (4):\n    def const(x):    \n        y=x[t]\n        return y\n    cons.append({'type':'ineq', 'fun': const})\n", "metadata": {"problem_id": 791, "library_problem_id": 80, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 80}}
{"id": 792, "code": "result = sparse.vstack([sa, sb])", "metadata": {"problem_id": 792, "library_problem_id": 81, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 81}}
{"id": 793, "code": "result = sparse.vstack([sa, sb])", "metadata": {"problem_id": 793, "library_problem_id": 82, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 81}}
{"id": 794, "code": "import numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\nI = ... # put solution in this variable\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrateallclassesections.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried:\nimport numpy as np\nintegrate.quad(lambda x: eqn, low, high)\nEND SOLUTION\n\nI want to solve the integral for different values of c and store them in an array.\nHere is what I have tried", "metadata": {"problem_id": 794, "library_problem_id": 83, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 83}}
{"id": 795, "code": "\n    result = scipy.integrate.quad(lambda x: x**2, low, high)\n    return result\n", "metadata": {"problem_id": 795, "library_problem_id": 84, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 83}}
{"id": 796, "code": "x = sparse.csr_matrix(x)\nresult = V + x", "metadata": {"problem_id": 796, "library_problem_id": 85, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 797, "code": "A = V + x\n", "metadata": {"problem_id": 797, "library_problem_id": 86, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 85}}
{"id": 798, "code": "A = V + x", "metadata": {"problem_id": 798, "library_problem_id": 87, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 85}}
{"id": 799, "code": "sa.__WeightMatrix__ = sa.__WeightMatrix__.tocsc()", "metadata": {"problem_id": 799, "library_problem_id": 88, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 88}}
{"id": 800, "code": "sa.data = np.where(sa.data > threshold, sa.data, 0)", "metadata": {"problem_id": 800, "library_problem_id": 89, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 88}}
{"id": 801, "code": "a = np.where(a > 0, 1, 0)\n", "metadata": {"problem_id": 801, "library_problem_id": 90, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 90}}
{"id": 802, "code": "a = np.where(a==2, 1, 0)\n", "metadata": {"problem_id": 802, "library_problem_id": 91, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 90}}
{"id": 803, "code": "from scipy.cluster import hierarchy\n\ndef closest_to_centroid(data, centroids):\n    \"\"\"\n    Compute the closest distance between data points and centroids.\n\n    Parameters\n    ----------\n    data : ndarray\n        Data points to compute distances to.\n    centroids : ndarray\n        Centroids to compute distances from.\n\n    Returns\n    -------\n    closest : ndarray\n        Distances to centroids.\n    \"\"\"\n    return scipy.spatial.distance.cdist(data, centroids)\n\ndistances = closest_to_centroid(data, centroids)\n\n_, idx = scipy.cluster.hierarchy.find_closest_cluster(distances)\nresult = idx\n", "metadata": {"problem_id": 803, "library_problem_id": 92, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 92}}
{"id": 804, "code": "from scipy.cluster import hierarchy\n\ndef closest_to_centroid(data, centroids):\n    \"\"\"\n    Compute the closest points to the centroids.\n\n    Parameters\n    ----------\n    data : ndarray\n        Data to compute distances to.\n    centroids : ndarray\n        Centroids to compute distances to.\n\n    Returns\n    -------\n    closest : ndarray\n        Points in `data` that are closest to `centroids`.\n    \"\"\"\n    # Compute distances to each centroid.\n    distances = scipy.spatial.distance.cached_distance(centroids, data,\n                                                      metric='cached',\n                                                      pq=2)\n    # Select the closest point for each cluster\n    closest = np.argmin(distances, axis=0)\n    return closest\n\nresult = closest_to_centroid(data, centroids)", "metadata": {"problem_id": 804, "library_problem_id": 93, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 92}}
{"id": 805, "code": "from scipy.cluster import hierarchy\nfrom sklearn.cluster import KMeans\n\n# Apply KMeans to get the centroids\nkmeans = KMeans(n_clusters=5).fit(data)\ncentroids = kmeans.cluster_centers_\n\n# Apply KMeans to get the closest points to the centroids\ndistance_matrix = scipy.spatial.distance.cdist(data, centroids)\n_, idx = scipy.cluster.hierarchy.find_clusters(distance_matrix, \n                                               distance_matrix.shape[0] - 1)\nresult = []\nfor i, idx_cluster in enumerate(idx):\n    distances = scipy.spatial.distance.cdist(data[idx_cluster], \n                                               centroids[i])\n    _, k_closest = np.argsort(distances, \n                              np.argmin(range(distances.shape[0]), \n                                        k))\n    result.append(k_closest)\n", "metadata": {"problem_id": 805, "library_problem_id": 94, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 92}}
{"id": 806, "code": "for x, b in zip(xdata, bdata):\n    result.append(fsolve(eqn, x0=x, args=(a,b)))\n", "metadata": {"problem_id": 806, "library_problem_id": 95, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 95}}
{"id": 807, "code": "result = []\nfor x, a in zip(xdata, adata):\n    result.append(fsolve(eqn, x0=x, args=(a,)))\n", "metadata": {"problem_id": 807, "library_problem_id": 96, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 95}}
{"id": 808, "code": "result, _ = sp.stats.kdeuntest(sample_data, bekkers, range_start, range_end, estimated_a, estimated_m, estimated_d)\n", "metadata": {"problem_id": 808, "library_problem_id": 97, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 97}}
{"id": 809, "code": "result = sp.stats.kstest(sample_data, 'norm', alpha=0.05)", "metadata": {"problem_id": 809, "library_problem_id": 98, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 97}}
{"id": 810, "code": "df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d-%H:%M:%S')\ndf.sort_values('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\ndf.reset_index(inplace=True)\ndf.drop_duplicates(subset='Time', keep='first', inplace=True)\ndf.set_index('Time', inplace=True)\nEND SOLUTION\n\nintegral_df = df.groupby('Time').apply(lambda g: integrate.trapz(g.A, g.Time, dx=g.Time.dt.seconds.mean()))\nintegral_df\nEND SOLUTION\n", "metadata": {"problem_id": 810, "library_problem_id": 99, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 99}}
{"id": 811, "code": "interp = scipy.interpolate.LinearInterpolator(x, y, axis=0)\nresult = interp(eval)", "metadata": {"problem_id": 811, "library_problem_id": 100, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 100}}
{"id": 812, "code": "def multinomial_log_likelihood(dataframe, weights):\n    total_weight = sum(weights)\n    return total_weight\n\ndef multinomial_maximum_likelihood(dataframe):\n    total_data = dataframe.sum()\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return totalthis\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total_data\n\ndef fit_model(dataframe):\n    total_data = dataframe.shape[0]\n    total_weight = sum(weights)\n    return total", "metadata": {"problem_id": 812, "library_problem_id": 101, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 101}}
{"id": 813, "code": "popt = np.array([1.05501927245, 1.14501927245])\n", "metadata": {"problem_id": 813, "library_problem_id": 102, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 102}}
{"id": 814, "code": "result = signal.find_peaks(arr, n)\n", "metadata": {"problem_id": 814, "library_problem_id": 103, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 103}}
{"id": 815, "code": "arr = np.array([[-624.59309896, -624atar, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624.59309896, -624", "metadata": {"problem_id": 815, "library_problem_id": 104, "library": "Scipy", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 103}}
{"id": 816, "code": "df = df.select_dtypes(include='float64')", "metadata": {"problem_id": 816, "library_problem_id": 105, "library": "Scipy", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 105}}
{"id": 817, "code": "import pandas as pd\ndata = load_iris()\ndata1 = pddatas", "metadata": {"problem_id": 817, "library_problem_id": 0, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 818, "code": "import pandas as pd\ndata = load_iris()\ndata1 = pddataconvert(data)", "metadata": {"problem_id": 818, "library_problem_id": 1, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 819, "code": "df = pd.DataFrame(data)", "metadata": {"problem_id": 819, "library_problem_id": 2, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 0}}
{"id": 820, "code": "\n    df = pd.DataFrame(data)\n    return df\n    ### END SOLUTION\n\nIn the above code, the function solve() is supposed to convert the data loaded from sklearn datasets to a pandas dataframe. However, the function solve() is not defined in the code provided.\n", "metadata": {"problem_id": 820, "library_problem_id": 3, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 821, "code": "df_out = pdatarate({'Col1': ['C', 'A', 'B'], 'Col2': [33, 2.5, 42], 'Col3': [['Apple', 'Orange', 'Banana'], ['Apple', 'Grape'], ['Banana']]})", "metadata": {"problem_id": 821, "library_problem_id": 4, "library": "Sklearn", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 4}}
{"id": 822, "code": "df_out = pdatarataframe.join(df['Col2'].apply(lambda x: pd.Series(x.split(' '))), on=df['Col1'].values, left_index=True, right_index=True)\n", "metadata": {"problem_id": 822, "library_problem_id": 5, "library": "Sklearn", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 4}}
{"id": 823, "code": "df_out = pdatarate(df['Col1'].values, {i: [i, i+1] for i in range(len(df))})\n", "metadata": {"problem_id": 823, "library_problem_id": 6, "library": "Sklearn", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 4}}
{"id": 824, "code": "df_out = pdatarate(df, ['Col1', 'Col2'])", "metadata": {"problem_id": 824, "library_problem_id": 7, "library": "Sklearn", "test_case_cnt": 4, "perturbation_type": "Semantic", "perturbation_origin_id": 4}}
{"id": 825, "code": "df_out = pdataray.apply(lambda x: x.apply(lambda y: [1 if \"Apple\" in x else 0 for x in y]))", "metadata": {"problem_id": 825, "library_problem_id": 8, "library": "Sklearn", "test_case_cnt": 4, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 4}}
{"id": 826, "code": "from sklearn.calibration import CalibrationPlot\n\ncalibration = CalibrationPlot(svmmodel,proba, x_test)\ncalibration.plot()\n", "metadata": {"problem_id": 826, "library_problem_id": 9, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 827, "code": "from sklearn.calibration import CalibrationModel\nfrom sklearn.calibration import calibration_curve\n\nmodel = CalibrationModel()\nproba = model.predict_proba(x_predict)\n", "metadata": {"problem_id": 827, "library_problem_id": 10, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 828, "code": "transform_output = transform_output.to_csv('temp.csv')\ndf = pddat.read_csv('temp.csv', index_col=[list_of_columns])", "metadata": {"problem_id": 828, "library_problem_id": 11, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 11}}
{"id": 829, "code": "transformed_df = pddat.merge(transform_output, df, left_index=True, right_index=True)\n", "metadata": {"problem_id": 829, "library_problem_id": 12, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 11}}
{"id": 830, "code": "\n    df_origin = pd.DataFrame(transform_output)\n    df_origin.columns = ['col1', 'col2']\n    df_origin.index = [1,2,3,4,5]\n    ### END SOLUTION\n\n    return df_origin\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "metadata": {"problem_id": 830, "library_problem_id": 13, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 11}}
{"id": 831, "code": "\nclf.steps.append('new_step_name', 'new_step_object')\n", "metadata": {"problem_id": 831, "library_problem_id": 14, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 14}}
{"id": 832, "code": "\nclf.steps.append('new_step')\n", "metadata": {"problem_id": 832, "library_problem_id": 15, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 14}}
{"id": 833, "code": "\nclf.steps.remove('reduce_dim')\n", "metadata": {"problem_id": 833, "library_problem_id": 16, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 14}}
{"id": 834, "code": "\nclf.steps.append('new_step_name', 'new_step_object')\n", "metadata": {"problem_id": 834, "library_problem_id": 17, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 17}}
{"id": 835, "code": "\nclf.steps.append('new_step')\n", "metadata": {"problem_id": 835, "library_problem_id": 18, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 17}}
{"id": 836, "code": "\nclf.steps.insert(len(clf.steps)-1, ('t1919810', PCA()))\n", "metadata": {"problem_id": 836, "library_problem_id": 19, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 17}}
{"id": 837, "code": "\nmodel = xgb.XGBRegressor()\ngridsearch = GridSearchCV(model, param_grid, n_jobs=-1, iid=True, cv=TimeSeriesSplit(n_splits=3, test_size=30))\ngridsearch.fit(trainX, trainY)\ngridsearch.best_params_\ngridsearch.best_score_\ngridsearch.bestior_rounds_\ngridsearch.best_index_\ngridsearch.best_score_\ngridsearch.best_estimator_\ngridsearch.cv_values_\ngridsearch.fitted_\ngridsearch.score(trainX, trainY)\ngridsearch.fit_params_\ngridsearch.fit(trainX, trainY)\n", "metadata": {"problem_id": 837, "library_problem_id": 20, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 20}}
{"id": 838, "code": "\n# define the grid\nparamGrid = [\n    {\"learning_rate\": [1, 0.1, 0.01, 0.001], \"max_depth\": [2, 3, 4, 5]},\n    {\"objective\": [\"MAPE\", \"MAPXE\", \"MAE\"], \"early_stopping_rounds\": [4, 5, 6, 7, 8, 9, 10]}\n]\n\n# define the model\nmodel = xgb.XGBRegressor()\n\n# define the search\ngridsearch = GridSearchCV(model, paramGrid, n_jobs=1, iid=True, verbose=1, cv=TimeSeriesSplit(n_splits=3).get_n_splits([trainX, trainY]))\n\n# fit the model\ngridsearch.fit(trainX, trainY)\n\n# get the best parameters\nbest_params = gridsearch.best_params_\n\n# define the model with the best parameters\nmodel = xgb.XGBRegressor(**best_params)\n\n# fit the model\nmodel.fit(trainX, trainY)\n\n# get the score\nscore = model.score(testX, testY)\n\n# get the prediction\npredictions = model.predict(testX)\n\n# save the score and prediction\nb = {\"score\": score, \"prediction\": predictions}\nEND SOLUTION\n", "metadata": {"problem_id": 838, "library_problem_id": 21, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 20}}
{"id": 839, "code": "proba = []\nfor train, test in cv:\n    logreg.fit(train, train)\n    proba_class = logreg.predict_proba(test)\n    proba.append(proba_class)\n", "metadata": {"problem_id": 839, "library_problem_id": 22, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 22}}
{"id": 840, "code": "proba = []\nfor train, test in cv:\n    logreg.fit(train, train)\n    proba.append(logreg.predict_proba(test))\n", "metadata": {"problem_id": 840, "library_problem_id": 23, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 22}}
{"id": 841, "code": "from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Fit the model to the data\nmodel = LinearRegression()\nmodel.fit(data['t'].values.reshape(-1,1), data['f1'].values)\n\n# Transform the data back to original scale\ninversed = scaler.inverse_transform(data['t'].values.reshape(-1,1))\nEND SOLUTION\n\n# Check the score\nscore = mean_squared_error(data['t'].values, inversed)\nprint('Score:', score)\n", "metadata": {"problem_id": 841, "library_problem_id": 24, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 24}}
{"id": 842, "code": "\n    from sklearn.linear_model import LinearRegression\n    model = LinearRegression()\n    model.fit(data.drop(['t'],axis=1),data['t'])\n    return model\n", "metadata": {"problem_id": 842, "library_problem_id": 25, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 24}}
{"id": 843, "code": "model_name = model.__class__.__name__", "metadata": {"problem_id": 843, "library_problem_id": 26, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 26}}
{"id": 844, "code": "model_name = model.__class__.__name__", "metadata": {"problem_id": 844, "library_problem_id": 27, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 26}}
{"id": 845, "code": "from sklearn.metrics import make_scorer\nfrom sklearn.model_selection import cross_val_score\n\ndef get_model_name(model):\n    model_name = model.__class__.__name__\n    return model_name\n\nmodels = [LinearSVC()]\nmodels.append(make_scorer(LinearSVC()))\n\nfor model in models:\n    scores = cross_val_score(model, X, y, cv=5)\n    model_name = get_model_name(model)\n    print(f'Name model: {model_name} , Mean score: {scores.mean()}')\nEND SOLUTION\n", "metadata": {"problem_id": 845, "library_problem_id": 28, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 26}}
{"id": 846, "code": "tf_idf_out = pipe.fit_transform(data)", "metadata": {"problem_id": 846, "library_problem_id": 29, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 29}}
{"id": 847, "code": "tf_idf_out = pipe.fit_transform(data)", "metadata": {"problem_id": 847, "library_problem_id": 30, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 29}}
{"id": 848, "code": "select_out = SelectKBest().fit_transform(data, target)", "metadata": {"problem_id": 848, "library_problem_id": 31, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 29}}
{"id": 849, "code": "\ngrid_search = GridSearchCV(bc, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nclf = grid_search.best_estimator_\nproba = grid_search.best_score_", "metadata": {"problem_id": 849, "library_problem_id": 32, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 850, "code": "\nregressor = RandomForestRegressor(n_estimators=150, min_samples_split=1, random_state=42)\nregressor.fit(X, y)\nprediction = regressor.predict(X_test)", "metadata": {"problem_id": 850, "library_problem_id": 33, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 33}}
{"id": 851, "code": "\nregressor = RandomForestRegressor(n_estimators=150, min_samples_split=1, random_state=42)\nregressor.fit(X, y)\npredictions = regressor.predict(X_test)", "metadata": {"problem_id": 851, "library_problem_id": 34, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 33}}
{"id": 852, "code": "\ntfidf = TfidfVectorizer(preprocessor_pipeline=preprocess)", "metadata": {"problem_id": 852, "library_problem_id": 35, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Origin", "perturbation_origin_id": 35}}
{"id": 853, "code": "\ndef prePro(text):\n    return text.lower()\n\nvectorizer = TfidfVectorizer(preprocessor=prePro)", "metadata": {"problem_id": 853, "library_problem_id": 36, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Semantic", "perturbation_origin_id": 35}}
{"id": 854, "code": "scalar = preprocessing.StandardScaler()\ndata_scaled = pd.DataFrame(scalar.fit_transform(data))\ndf_out = pdatar", "metadata": {"problem_id": 854, "library_problem_id": 37, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 37}}
{"id": 855, "code": "\n# Create a StandardScaler object\nscaler = preprocessing.StandardScaler()\n\n# Fit and transform the data\nscaled_data = scaler.fit_transform(data)\ndf_out = pd.DataFrame(scaled_data, columns=scaler.columns)\nEND SOLUTION\n\nIn the above code, you are fitting the scaler to your data and then transforming it to get the scaled data. The fitted scaler's columns attribute gives you the names of the columns in the original data, and the transformed data has the same names as the original data.\n", "metadata": {"problem_id": 855, "library_problem_id": 38, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 37}}
{"id": 856, "code": "coef = grid.best_estimator_.named_steps['model'].alpha", "metadata": {"problem_id": 856, "library_problem_id": 39, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 39}}
{"id": 857, "code": "coef = grid.best_estimator_.named_steps['model'].alpha", "metadata": {"problem_id": 857, "library_problem_id": 40, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 39}}
{"id": 858, "code": "model = SelectFromModel(clf, prefit=True)\nselected_features = model.get_feature_names_out()\nselected_features.columns = column_names", "metadata": {"problem_id": 858, "library_problem_id": 41, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 41}}
{"id": 859, "code": "model = SelectFromModel(clf, prefit=True)\nselected_columns = model.get_feature_names_out()", "metadata": {"problem_id": 859, "library_problem_id": 42, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 41}}
{"id": 860, "code": "model = SelectFromModel(clf, prefit=True)\nselected_columns = model.get_feature_names_out()\nselected_columns.shape # to check if it's shape is correct\nselected_columns = list(selected_columns)", "metadata": {"problem_id": 860, "library_problem_id": 43, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 41}}
{"id": 861, "code": "import pandas as pd\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nimport numpy as np\n\nX, y = load_data()\nclf = ExtraTreesClassifier(random_state=42)\nclf = clf.fit(X, y)\n\nmodel = SelectFromModel(clf, prefit=True)\nselected_columns = model.get_feature_names()\n", "metadata": {"problem_id": 861, "library_problem_id": 44, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 41}}
{"id": 862, "code": "km.fit(X)\nclosest_50_samples = km.cluster_centers_[p]", "metadata": {"problem_id": 862, "library_problem_id": 45, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 45}}
{"id": 863, "code": "from sklearn.cluster import KMeans\n\ndef find_closest_samples(data, n_samples):\n    kmeans = KMeans().fit(data)\n    indices, distances = zip(*sorted(list(data.items()) + [(cluster_center, distance)]))\n    indices.remove(cluster_center)\n    closest_samples = indices[n_samples]\n    return closest_samples\n\nclosest_50_samples = find_closest_samples(data, 50)", "metadata": {"problem_id": 863, "library_problem_id": 46, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 45}}
{"id": 864, "code": "km.fit(X)\nclosest_100_samples = km.transform(X)\n", "metadata": {"problem_id": 864, "library_problem_id": 47, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 45}}
{"id": 865, "code": "\n    km.fit(X)\n    centroids = km.cluster_centers_\n    distances = [np.linalg.norm(a-b) for a, b in zip(centroids, X)]\n    sorted_distance_indices = np.argsort(distances)\n    closest_cluster_indices = sorted_distance_indices[:p]\n    closest_cluster_samples = X[closest_cluster_indices]\n    return closest_cluster_samples\n    ### END SOLUTION\n\nIn the above code, the function `get_samples` is used to get the samples closest to the cluster center \"p\" in the KMeans algorithm. The function `get_samples` takes two arguments: `p` and `X`, which are the number of closest samples and the data itself respectively. It fits the KMeans algorithm on the data and then it calculates the distances between the cluster centers and the data points and sorts them. It then selects the first `p` closest samples as the samples closest to the cluster center \"p\".\n", "metadata": {"problem_id": 865, "library_problem_id": 48, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 45}}
{"id": 866, "code": "\nfrom sklearn.preprocessing import OneHotEncoder\n\n# One hot encode categorical variable\ncolumn_names = ['column_name']\nX_train = pd.concat([X_train, pdDATA.get_dummies(X_train['column_name'], prefix='')], axis=1)\nEND SOLUTION\n\n# Now you can use GradientBoostingClassifier\n...\nEND SOLUTION\n", "metadata": {"problem_id": 866, "library_problem_id": 49, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 49}}
{"id": 867, "code": "\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Create a list of lists\nlist_cols = ['column0_name', 'column1_name', 'column2_name']\n\n# Apply one hot encoder to each column\nfor i, col in enumerate(list_cols):\n    X_train[col] = X_train[col].apply(lambda x: x.split(' '))\n\n# Now apply one hot encoder\nn_unique_values = len(X_train[list_cols].unique().values)\nshape = (len(X_train), len(list_cols))\ndtype = np.dtype(object).name\ndtype = dtype.split(' ')\ndtype = [(dtype[0] + '_' + str(i+1)) for i in range(shape[1])]\ndtype = pd.get_dtype(shape)\ndtype = pdFER_ID = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype(shape)\ndtype = pd.get_dtype", "metadata": {"problem_id": 867, "library_problem_id": 50, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 49}}
{"id": 868, "code": "from sklearn.svm import SVR\nfrom sklearn.kernel_tracing import Tracing\n\ntracing = Tracing(kernel='rbf')\ntracing.fit(X, y)\npredict = tracing.predict(X)\nEND SOLUTION\n", "metadata": {"problem_id": 868, "library_problem_id": 51, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 51}}
{"id": 869, "code": "from sklearn.svm import SVR\nfrom sklearn.kernel_tracing import GaussianKernel\n\n# define the parameter\nC, gamma = .1, .1\n\n# define the model\nsvr = SVR(epsilon=C, kernel='linear')\n\n# fit the model\nsvr.fit(X, y)\n\n# define the model\ngaussian_kernel = GaussianKernel(kernel_params_C=C, kernel_params_gamma=gamma)\n\n# fit the model\ngaussian_kernel.fit(X, y)\n\npredict = svr.predict(X)\n", "metadata": {"problem_id": 869, "library_problem_id": 52, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 51}}
{"id": 870, "code": "from sklearn.svm import SVR\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=2)\nX_poly = poly.fit_transform(X)\n\nsvr = SVR(fit_transform(X_poly))\n", "metadata": {"problem_id": 870, "library_problem_id": 53, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 51}}
{"id": 871, "code": "from sklearn.svm import SVR\nfrom sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(degree=2)\nX_poly = poly.fit_transform(X)\nsvr = SVR(kernel='linear')\nsvr.fit(X_poly, y)\npredict = srv.predict(X_poly)", "metadata": {"problem_id": 871, "library_problem_id": 54, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 53}}
{"id": 872, "code": "from sklearn.metrics.pairwise import cosine_distances\n\ndef get_cosine_similarity(queries, documents):\n    tfidf = TfidfVectorizer()\n    matrix = tfidf.fit_transform(documents)\n    cosine_similarities_of_queries = cosine_distances(queries, matrix)\n    return cosine_similarities_of_queries\n", "metadata": {"problem_id": 872, "library_problem_id": 55, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 55}}
{"id": 873, "code": "from sklearn.metrics.pairwise import cosine_distances\n\ndef get_cosine_similarity(queries, documents):\n    tfidf = TfidfVectorizer()\n    matrix = tfidf.fit_transform(documents)\n    cosine_similarities_of_queries = cosine_distances(queries, documents)\n    return cosine_similarities_of_queries\n", "metadata": {"problem_id": 873, "library_problem_id": 56, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 55}}
{"id": 874, "code": "\n    matrix = []\n    for query in queries:\n        query_tfidf = tfidf.transform([query])\n        # calculate the cosine similarity\n        cosine_similarities = query_tfidf.dot(tfidf.fit_transform(documents))\n        # append to the matrix\n        matrix.append(cosine_similarities)\n    return matrix\n", "metadata": {"problem_id": 874, "library_problem_id": 57, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 55}}
{"id": 875, "code": "from sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\nnew_features = mlb.fit_transform(features)\n", "metadata": {"problem_id": 875, "library_problem_id": 58, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 58}}
{"id": 876, "code": "from sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\nnew_f = mlb.fit_transform(f)\n", "metadata": {"problem_id": 876, "library_problem_id": 59, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 58}}
{"id": 877, "code": "from sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\nnew_features = mlb.fit_transform(features)\n", "metadata": {"problem_id": 877, "library_problem_id": 60, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 58}}
{"id": 878, "code": "\n    df = pd.DataFrame(features)\n    df = df.apply(lambda x: x.astype('str').split(), axis=1)\n    df = df.drop_duplicates()\n    return df.values\nend =\n\nIn the above code, the function load_data() should be replaced by your actual code. It should return your data in the form of a 2D array where each row represents a sample and each column represents a feature.\n", "metadata": {"problem_id": 878, "library_problem_id": 61, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 58}}
{"id": 879, "code": "from sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\n\nfeatures = pd.DataFrame(features)\nfeatures = features.apply(lambda x: mlb.fit_transform(x))\n", "metadata": {"problem_id": 879, "library_problem_id": 62, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 58}}
{"id": 880, "code": "from sklearn.cluster import AgglomerativeClustering\n\n# Define the distance matrix\ndist_matrix = np.array([[0,0.8,0.9],[0.8,0,0.2],[0.9,0.2,0]])\n\n# Apply Agglomerative Clustering\ncluster = AgglomerativeClustering(n_clusters=2, distance_matrix=True)\ncluster.fit(dist_matrix)\n\ncluster_labels = cluster.labels_\nprint(cluster_labels)", "metadata": {"problem_id": 880, "library_problem_id": 63, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 63}}
{"id": 881, "code": "from sklearn.cluster import AgglomerativeClustering\n\ncluster = AgglomerativeClustering(n_clusters=2, affinity='distance_matrix', linkage_method='average')\ncluster.fit(data_matrix)\ncluster_labels = cluster.labels_\nEND SOLUTION\n\ncluster_labels contains the labels of the clusters.\n", "metadata": {"problem_id": 881, "library_problem_id": 64, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 63}}
{"id": 882, "code": "from sklearn.cluster import AgglomerativeClustering\n\n# Define the number of clusters\nn_clusters = 2\n\n# Create a list of lists where each list contains the distances between each fruit and all other fruits\ndistances = [0,0.6,0.8,0.111]\n\n# Create a 2D array of distances\ndistances_2d = np.array([0,0.6,0.8,0.111]).reshape(-1,1)\n\n# Apply Agglomerative Clustering\ncluster = AgglomerativeClustering(n_clusters=n_clusters, distance_threshold=distances_2d)\ncluster_labels = cluster.fit_predict()\nEND SOLUTION\n\ncluster_labels\n", "metadata": {"problem_id": 882, "library_problem_id": 65, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 63}}
{"id": 883, "code": "from scipy.cluster import hierarchy\nZ = linkage_matrix = ... # put solution in this variable\ncluster_labels = ... # put solution in this variable\nEND SOLUTION\n\ncluster_labels = hierarchy.fcluster(Z, 2, criterion='distance')\nEND SOLUTION\n", "metadata": {"problem_id": 883, "library_problem_id": 66, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 66}}
{"id": 884, "code": "from sklearn.cluster import AgglomerativeClustering\ncluster = AgglomerativeClustering(n_clusters=2, affinity='distance', linkage='average')\ncluster.fit_predict(data_matrix)\ncluster_labels = cluster.labels_\nEND SOLUTION\n\nWHERE cluster_labels contains the labels of your clusters.\n", "metadata": {"problem_id": 884, "library_problem_id": 67, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 66}}
{"id": 885, "code": "from scipy.cluster import hierarchy\nZ = hierarchy.linkage(simM, method='average', metric='euclidean')\ncluster_labels = hierarchy.fcluster(Z, 2, criterion='distance', align_threshold=0.5)", "metadata": {"problem_id": 885, "library_problem_id": 68, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 66}}
{"id": 886, "code": "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# \u521b\u5efa\u4e00\u4e2a\u5305\u542b\u4e24\u4e2a\u6570\u636e\u96c6\u7684\u6570\u636e\u6846\ndata = pd.DataFrame({\n    'x1': np.random.normal(5,2,100),\n    'x2': np.random.normal(5,2,100)})\n\n# \u521b\u5efa\u4e00\u4e2aStandardScaler\u5bf9\u8c61\nsc = StandardScaler()\n\n# \u4f7f\u7528\u5b83\u6765\u8f6c\u6362\u6570\u636e\nscaled_data = sc.fit_transform(data)\n\n# \u521b\u5efa\u4e00\u4e2aMinMaxScaler\u5bf9\u8c61\nmm = MinMaxScaler()\n\n# \u4f7f\u7528\u5b83\u6765\u8f6c\u6362\u6570\u636e\nmm_data = mm.fit_transform(data)\n", "metadata": {"problem_id": 886, "library_problem_id": 69, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 69}}
{"id": 887, "code": "from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data)\n", "metadata": {"problem_id": 887, "library_problem_id": 70, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 69}}
{"id": 888, "code": "from sklearn.preprocessing import PowerTransformer\n\npt = PowerTransformer(method='Box-Cox')\nbox_cox_data = pt.fit_transform(data)\nEND SOLUTION\n", "metadata": {"problem_id": 888, "library_problem_id": 71, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 71}}
{"id": 889, "code": "from sklearn.preprocessing import PowerTransformer\n\ntrans = PowerTransformer(normalize=None)\nbox_cox_data = trans.fit_transform(data)\n", "metadata": {"problem_id": 889, "library_problem_id": 72, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 71}}
{"id": 890, "code": "from sklearn.preprocessing import PowerTransformer\n\npt = PowerTransformer(method='YeoJohnson')\n\ntransformed_data = pt.fit_transform(data)\n", "metadata": {"problem_id": 890, "library_problem_id": 73, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 73}}
{"id": 891, "code": "from sklearn.preprocessing import apply_optional_preprocessing\nfrom sklearn.preprocessing import YeoJohnson\n\n# Applying Yeo-Johnson transformation\ntransformer = YeoJohnson()\ntransformed_data = transformer.transform(data)\n", "metadata": {"problem_id": 891, "library_problem_id": 74, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 73}}
{"id": 892, "code": "vectorizer = CountVectorizer(analyzer_char_to_drop=[\" \",\".\",\",\",\"]}", "metadata": {"problem_id": 892, "library_problem_id": 75, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 75}}
{"id": 893, "code": "from sklearn.model_selection import train_test_split\n\n# assuming 'image' column names are 'image1', 'image2', etc.\nimage_names = ['image'+str(i)+'_image' for i in range(1,20)]\n\ndataset = pd.concat([dataset, pddataset.drop(['image1', 'image2', ...], axis=1)], axis=1)\n\nx = dataset.drop(['image1', 'image2', ...], axis=1)\ny = dataset['image1', 'image2', ...]\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42)", "metadata": {"problem_id": 893, "library_problem_id": 76, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 76}}
{"id": 894, "code": "from sklearn.model_selection import train_test_split\n\n# assuming df is your dataframe\ndf = pd.read_csv('your_file.csv')\n\n# assuming 'object' is your target column\ntarget = df['object']\n\n# splitting the data into train and test datasets\ntrain, test = train_test_split(df, test_size=0.2, random_state=42)\n\n# defining x and y for training dataset\nx_train = train.drop(['object'], axis=1)\ny_train = train['object']\n\n# defining x and y for testing dataset\nx_test = test.drop(['object'], axis=1)\ny_test = test['object']\nEND SOLUTION\n", "metadata": {"problem_id": 894, "library_problem_id": 77, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 76}}
{"id": 895, "code": "from sklearn.model_selection import train_test_split\n\n# assuming 'image' column names are 'image1', 'image2', 'image3'\n# and 'label' column names are 'label1', 'label2'\n\n# assuming your dataset has 3 columns and 1 column for labels\n# and 3 columns for images\n\n# split the dataset into 3 parts\ntrain_dataset, test_dataset = train_test_split(dataset, test_size=0.3, random_state=42)\n\n# split the images into 3 parts\nx_train = train_dataset[['image1', 'image2', 'image3']].values\ny_train = train_dataset['label1', 'label2'].values\n\nx_test = test_dataset[['image1', 'image2', 'image3']].values\ny_test = test_dataset['label1', 'label2'].values\nEND SOLUTION\n", "metadata": {"problem_id": 895, "library_problem_id": 78, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 76}}
{"id": 896, "code": "\n    from sklearn.model_selection import train_test_split\n    X = data.iloc[:,:-1]\n    y = data.iloc[:,-1]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    return X_train, y_train, X_test, y_test\n    ### END SOLUTION\n\nIn the above code, the last column is used as the target variable and the rest are used as the features. The train_test_split function is used to split the dataset into a training set and a testing set. The test_size parameter is the proportion of the dataset to allocate as the test dataset. The random_state parameter is the seed for the random number generator used by the random_state function.\n", "metadata": {"problem_id": 896, "library_problem_id": 79, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 76}}
{"id": 897, "code": "df['mse'].values.reshape(-1,1).values", "metadata": {"problem_id": 897, "library_problem_id": 80, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 80}}
{"id": 898, "code": "from sklearn.cluster import KMeans\nimport pandas as pd\nimport numpy as np\n\ndef load_data():\n    df = pd.read_csv(\"file.csv\")\n    mse = df['mse'].values\n    date = df['date'].values\n    df = pdatarange = pd.date_range(start=date.min(), end=date.max(), freq='MS')\n    X = pd.concat([date, mse], axis=1).values\n    kmeans = KMeans(n_clusters=2, n_init=10).fit(X)\n    labels = kmeans.predict(X)\n    centroids = kmeans.cluster_centroids_\nEND SOLUTION\n\nIn the above code, you are trying to get the cluster centers which are the points that are closest to which the points are being clustered. So, you should get the centroids from the kmeans object.\n", "metadata": {"problem_id": 898, "library_problem_id": 81, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 80}}
{"id": 899, "code": "from sklearn.feature_selection import SelectKBest\n\nvectorizer.fit(corpus, y)\nselected_feature_names = vectorizer.get_feature_names()\nselected_feature_names", "metadata": {"problem_id": 899, "library_problem_id": 82, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 82}}
{"id": 900, "code": "from sklearn.feature_selection import SelectFromModel\n\nselected_features = SelectFromModel(LinearSVC(), attr='linear', dovect=True, threshold='1.0')\nselected_feature_names = selected_features.get_feature_names()\n", "metadata": {"problem_id": 900, "library_problem_id": 83, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 82}}
{"id": 901, "code": "\n    from sklearn.feature_selection import SelectKBest\n    from sklearn.feature_selection import f_regression\n    from sklearn.linear_model import LinearRegression\n    from sklearn.ensemble import RandomizedSearchCV\n    from sklearn.pipeline import Pipeline\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.svm import SVR\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_score\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import cross_val_predict\n    from sklearn", "metadata": {"problem_id": 901, "library_problem_id": 84, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 82}}
{"id": 902, "code": "vectorizer = CountVectorizer().fit_transform(corpus)\nfeature_names = CountVectorizer().get_feature_names()\n", "metadata": {"problem_id": 902, "library_problem_id": 85, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 85}}
{"id": 903, "code": "vectorizer = CountVectorizer().fit_transform(corpus)\nfeature_names = vectorizer.get_feature_names()\n", "metadata": {"problem_id": 903, "library_problem_id": 86, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 85}}
{"id": 904, "code": "vectorizer = CountVectorizer(stop_words=\"english\",lowercase=False, vocabulary={'Java', 'JavaScript', 'SQL', 'Jscript','Java','Developer','Frontend','SQL','Developer','Jscript','And','third','one','document','first','what','is','this','for','and','and','the','is','an','the','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and','and", "metadata": {"problem_id": 904, "library_problem_id": 87, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 85}}
{"id": 905, "code": "vectorizer = CountVectorizer(stop_words=\"english\",lowercase=False,vocabulary={'Java','JavaScript','SQL','Javascript','Java','JavaScript','SQL','Javascript','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','JavaScript','SQL','Java','Java", "metadata": {"problem_id": 905, "library_problem_id": 88, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 85}}
{"id": 906, "code": "slopes = []\nfor col in df1.columns:\n    df2 = df1[~np.isnan(df1[col])]\n    X = df2.values[:,0]\n    Y = df2.values[:,1]\n    lin_reg = LinearRegression().fit(X.reshape(-1,1), Y.reshape(-1,1))\n    slopes.append(lin_reg.coef_[0])\nslopes = np.array(slopes)\nEND SOLUTION\nEND\n", "metadata": {"problem_id": 906, "library_problem_id": 89, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 89}}
{"id": 907, "code": "slopes = []\nfor col in df1.columns:\n    df2 = df1[col]\n    df2 = df2.dropna()\n    X = df2.values\n    Y = df2.values\n    model = LinearRegression().fit(X,Y)\n    slope = model.coef_[0]\n    slopes.append(slope)\n", "metadata": {"problem_id": 907, "library_problem_id": 90, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 89}}
{"id": 908, "code": "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\ntransformed_df = pd.DataFrame(df)\nEND SOLUTION\n\nIn the above code, you are trying to fit the LabelEncoder on the 'Sex' column and then transforming the dataframe. However, you are missing the 'y' parameter in the fit_transform function. The correct way to do it is:\n\ndf['Sex'] = LabelEncoder().fit(df['Sex'], df).transform(df)\nEND SOLUTION\n", "metadata": {"problem_id": 908, "library_problem_id": 91, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 91}}
{"id": 909, "code": "df['Sex'] = LabelEncoder().fit_transform(df['Sex'])\nEND SOLUTION\n", "metadata": {"problem_id": 909, "library_problem_id": 92, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 91}}
{"id": 910, "code": "\n    for col in df.columns:\n        if df[col].name == 'Sex':\n            df[col] = df[col].map({'male': 1, 'female': 0})\n    return df\n# END SOLUTION\n\nThe above code is not working as expected, and the error is due to the fact that you are trying to fit the LabelEncoder on the entire dataframe, which is not what you want. You want to fit the LabelEncoder on the 'Sex' column only.\n\nHere is the correct way to do it:\n\ndf['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n", "metadata": {"problem_id": 910, "library_problem_id": 93, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 91}}
{"id": 911, "code": "ElasticNet = linear_model.ElasticNet() # create a lasso instance\nElasticNet.fit(X_train, y_train) # fit data\n\nprint(ElasticNet.coef_) # print out the coefficients\nprint (ElasticNet.intercept_) # print out the coefficients\n\nprint (\"R^2 for training set:\"),\nprint (ElasticNet.score(X_train, y_train))\n\nprint ('-'*50)\n\nprint (\"R^2 for test set:\"),\nprint (ElasticNet.score(X_test, y_test))\nEND SOLUTION\n", "metadata": {"problem_id": 911, "library_problem_id": 94, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 94}}
{"id": 912, "code": "scalar = MinMaxScaler()\ntransformed = scalar.fit_transform(np_array)", "metadata": {"problem_id": 912, "library_problem_id": 95, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 95}}
{"id": 913, "code": "scalar = MinMaxScaler()\ntransformed = scalar.fit_transform(np_array)", "metadata": {"problem_id": 913, "library_problem_id": 96, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 95}}
{"id": 914, "code": "\n    scaler = MinMaxScaler()\n    reshaped = scaler.fit_transform(a.reshape(-1,1))\n    return reshaped\n", "metadata": {"problem_id": 914, "library_problem_id": 97, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 95}}
{"id": 915, "code": "import pandas as pd\n\ndef predict_solution(df):\n    closing = df.loc['2013-02-15':'2016-05-21']\n    ma_50 = df.loc['2013-02-15':'2016-05-21']\n    ma_100 = df.loc['2013-02-15':'2016-05-21']\n    ma_200 = df.loc['2013-02-15':'2016-05-21']\n    buy_sell = df.loc['2013-02-15':'2016-05-21']\n\n    closing_cols = closing.columns\n    buy_sell_cols = buy_sell.columns\n\n    closing_cols = closing.drop(['Close'])\n    buy_sell_cols = buy_sell.drop(['Close'])\n\n    closing_cols.shape[0]\n    buy_sell_cols.shape[0]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1]\n\n    closing_cols.shape[1]\n    buy_sell_cols.shape[1", "metadata": {"problem_id": 915, "library_problem_id": 98, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 98}}
{"id": 916, "code": "\nnew_X = np.array([[1, 1, 0, 0] if 'asdf' in list(str(col)) else [0, 0, 0, 1] for col in [\"col1\", \"col2\"]])\n", "metadata": {"problem_id": 916, "library_problem_id": 99, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Origin", "perturbation_origin_id": 99}}
{"id": 917, "code": "\nnew_X = np.array([[1, 1], [1, 0]])\nclf.fit(new_X, [2, 3])", "metadata": {"problem_id": 917, "library_problem_id": 100, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Surface", "perturbation_origin_id": 99}}
{"id": 918, "code": "\nnew_X = np.array([[1,2], [3,1]])\nclf.fit(new_X, [3,2])", "metadata": {"problem_id": 918, "library_problem_id": 101, "library": "Sklearn", "test_case_cnt": 0, "perturbation_type": "Surface", "perturbation_origin_id": 99}}
{"id": 919, "code": "\nlogReg = LogisticRegression()\nlogReg.fit(X,y)\npredictions = logReg.predict(X)", "metadata": {"problem_id": 919, "library_problem_id": 102, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 102}}
{"id": 920, "code": "\nX = dataframe.iloc[:,:-1].astype(float)\ny = dataframe.iloc[:,-1]\nlogReg = LogisticRegression()\nlogReg.fit(X,y)\nprediction = logReg.predict(X)", "metadata": {"problem_id": 920, "library_problem_id": 103, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 102}}
{"id": 921, "code": "train_dataframe = features_dataframe.sort_values(by=\"date\").reset_index()", "metadata": {"problem_id": 921, "library_problem_id": 104, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 104}}
{"id": 922, "code": "train_dataframe = features_dataframe.sort_values(by=\"date\").reset_index()", "metadata": {"problem_id": 922, "library_problem_id": 105, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 104}}
{"id": 923, "code": "\n    train_size = 0.2\n    train_dataframe, test_dataframe = train_test_split(features_dataframe, test_size=train_size)\n    train_dataframe = train_dataframe.sort_values(by=[\"date\"])\n    test_dataframe = test_dataframe.sort_values(by=[\"date\"])\n    ### END SOLUTION\n    return train_dataframe, test_dataframe\n   ", "metadata": {"problem_id": 923, "library_problem_id": 106, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 104}}
{"id": 924, "code": "df[['X1', 'X2', 'X3']] = scaler.fit_transform(df[['X1', 'X2', 'X3']])\nEND SOLUTION\n", "metadata": {"problem_id": 924, "library_problem_id": 107, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 107}}
{"id": 925, "code": "myData[['A2', 'A3']].apply(lambda x: x.sub(x.mean()).div(x.std()))", "metadata": {"problem_id": 925, "library_problem_id": 108, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 107}}
{"id": 926, "code": "count = CountVectorizer(lowercase = False)\nvocabulary = count.fit_transform([words])", "metadata": {"problem_id": 926, "library_problem_id": 109, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 109}}
{"id": 927, "code": "count = CountVectorizer().fit_transform(words)\nfeature_names = count.get_feature_names_out()", "metadata": {"problem_id": 927, "library_problem_id": 110, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 109}}
{"id": 928, "code": "full_results.cv_results_['mean_test_score']", "metadata": {"problem_id": 928, "library_problem_id": 111, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 111}}
{"id": 929, "code": "full_results.cv_results_['mean_fit_time']", "metadata": {"problem_id": 929, "library_problem_id": 112, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 111}}
{"id": 930, "code": "\nfrom sklearn.externals import joblib\n\n# Save the model to disk using one line\njoblib.dump(fitted_model, 'sklearn_model')\n", "metadata": {"problem_id": 930, "library_problem_id": 113, "library": "Sklearn", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 113}}
{"id": 931, "code": "from sklearn.metrics.pairwise import cosine_distance\n\ntfidf_matrix = tfidf.fit_transform(df['description'])\ncosine_similarity_matrix = 1 - cosine_distance(tfidf_matrix, tfidf_matrix)\nEND SOLUTION\n\nIn the above code, you are calculating the cosine similarity between items 1ffg and 2hhj. The result is 1.0 which means they are exactly the same.\n", "metadata": {"problem_id": 931, "library_problem_id": 114, "library": "Sklearn", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 114}}
{"id": 932, "code": "\noptim.lr = 0.001\noptim.step()\n", "metadata": {"problem_id": 932, "library_problem_id": 0, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 0}}
{"id": 933, "code": "\noptimizer = torch.optim.SGD(..., lr=0.01)\noptimizer.load_state_dict(torch.load(...))\noptimizer.step()\noptimizer.load_state_dict(torchatar.optim.SGD(..., lr=0.001))\noptimizer.step()\n", "metadata": {"problem_id": 933, "library_problem_id": 1, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 934, "code": "\noptim.lr = 0.005\noptim.step()\n", "metadata": {"problem_id": 934, "library_problem_id": 2, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 0}}
{"id": 935, "code": "\noptimizer = torch.optim.SGD(..., lr=0.05)\noptimizer.lr = 0.05\noptimizer.step()\n", "metadata": {"problem_id": 935, "library_problem_id": 3, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 0}}
{"id": 936, "code": "# Convert the word2vec model to PyTorch tensor\nword2vec_tensor = torch.tensor(word2vec.numpy(), dtype=\"float32\")\n\n# Create the embedding layer with the same shape as the word2vec tensor\nembedding = torch.nn.Embedding.from_tensor(word2vec_tensor)\n\n# Assign the weights to the embedding layer\nembedding.weight = torch.tensor(word2vec.vectors, dtype=\"float32\")\nEND SOLUTION\n\nIn the above code, you are converting the word2vec model to a tensor and then converting the word2vec vectors to a tensor and assigning them to the embedding layer.\n", "metadata": {"problem_id": 936, "library_problem_id": 4, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 4}}
{"id": 937, "code": "\n    word2vec.wv.vak.shape\n    ### END SOLUTION\n    return embedded_input\n\nHere is the function where you are getting the word2vec weights and adding them to the PyTorch embedding layer.\n\n```python\nclass EmbeddingLayer(torch.nn.Embedding):\n    def __init__(self, weights):\n        super().__init__(weights)\n\ndef get_embedded_input(input_Tensor):\n    weights = Word2Vec(input_Tensor, size=100, min_count=1)\n    return EmbeddingLayer(weights)\n```\n\nIn the above code, you are creating a class `EmbeddingLayer` which inherits from `torch.nn.Embedding`. In the constructor of `EmbeddingLayer`, you are passing the weights obtained from `Word2Vec` to the parent class `torch.nn.Embedding`.\n\nIn the `get_embedded_input` function, you are creating an instance of `Word2Vec` and passing the input data to it. It will return the weights of the Word2Vec model. Then you are creating an instance of `EmbeddingLayer` and passing the weights obtained from `Word2Vec` to it.\n", "metadata": {"problem_id": 937, "library_problem_id": 5, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 4}}
{"id": 938, "code": "x = x.cpu().numpy()\npx = pd.DataFrame(x)\nEND SOLUTION\n\nThe above code converts the tensor to numpy array and then to pandas dataframe.\n", "metadata": {"problem_id": 938, "library_problem_id": 6, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 6}}
{"id": 939, "code": "px = pd.DataFrame(px.detach().cpu().numpy().flatten())\n", "metadata": {"problem_id": 939, "library_problem_id": 7, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 6}}
{"id": 940, "code": "x = x.cpu().numpy()\npx = pd.DataFrame(x)\npx = pdjor.DataFrame(x)\nEND SOLUTION\n\nEND SOLUTION\n", "metadata": {"problem_id": 940, "library_problem_id": 8, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 6}}
{"id": 941, "code": "C = torch.tensor([[1, 3], [4, 6]])\n", "metadata": {"problem_id": 941, "library_problem_id": 9, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 9}}
{"id": 942, "code": "C = torch.tensor([[1, 3], [4, 6]])\nA_logical = torch.tensor([1, 0, 1])\n", "metadata": {"problem_id": 942, "library_problem_id": 10, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 943, "code": "C = torch.ByteTensor([1, 1, 0]) # the logical index\nB = torchsch.LongTensor([[999, 777, 114514], [9999, 7777, 1919810]])\nC = B[:, A_log]", "metadata": {"problem_id": 943, "library_problem_id": 11, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 944, "code": "C = torch.tensor([[1, 3], [4, 6]])\n", "metadata": {"problem_id": 944, "library_problem_id": 12, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Semantic", "perturbation_origin_id": 9}}
{"id": 945, "code": "\n    C = torch.tensor([[1, 3], [4, 6]])\n    return C\n", "metadata": {"problem_id": 945, "library_problem_id": 13, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 9}}
{"id": 946, "code": "C = torch.ByteTensor([0, 0, 1])\nC = B[:, A_log]", "metadata": {"problem_id": 946, "library_problem_id": 14, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 9}}
{"id": 947, "code": "C = torch.tensor([[1, 3], [4, 6]])\nidx = torch.tensor([1, 2])\n", "metadata": {"problem_id": 947, "library_problem_id": 15, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 9}}
{"id": 948, "code": "x_tensor = torch.tensor(x_array, dtype=torch.float16)", "metadata": {"problem_id": 948, "library_problem_id": 16, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 16}}
{"id": 949, "code": "x_tensor = torch.tensor(x_array, dtype=torch.float64)", "metadata": {"problem_id": 949, "library_problem_id": 17, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 16}}
{"id": 950, "code": "\n    tensor = torch.tensor(a, dtype=torch.float16)\n    return tensor\n\nx_tensor = Convert(x_array)\n", "metadata": {"problem_id": 950, "library_problem_id": 18, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 16}}
{"id": 951, "code": "lens = torch.tensor([3, 5, 4])\nmax_len = torch.max(lens) + 1\nmask = torchatar.tensor(lens.shape[0], dtype=torch.bool)\nfor i in range(lens.shape[0]):\n    mask[i] = 1 - mask[i]\nEND SOLUTION\n", "metadata": {"problem_id": 951, "library_problem_id": 19, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 19}}
{"id": 952, "code": "lens = torch.tensor([1, 9, 3, 5])\nmax_len = torch.max(lens) + 1\nmask = torchatar.tensor(lens.shape[0], dtype=torch.bool)\nfor i in range(lens.shape[0]):\n    mask[i, :lens[i]] = 1\nEND SOLUTION\n\nIn the above code, you are creating a binary mask where 1 represents the presence of a word and 0 represents the absence. The shape of the mask is equal to the maximum length of the sentences plus one, which is the maximum length of all sentences. Then, for each sentence, you set the mask to 1 where the sentence is present.\n", "metadata": {"problem_id": 952, "library_problem_id": 20, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 19}}
{"id": 953, "code": "lens = torch.tensor([3, 5, 4])\nmax_len = torch.max(lens) + 1\nmask = torchatar.tensor([[0, 0, 1, 1, 1],\n                          [1, 1, 1, 1, 1],\n                          [0, 1, 1, 1, 1]])\nEND SOLUTION\nWHERE:\nWHERE:\nWHEREEND\nEND WHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHEREENDWHERE", "metadata": {"problem_id": 953, "library_problem_id": 21, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 19}}
{"id": 954, "code": "\n    max_len = max(lens)\n    dummy_tensor = torch.arange(10000).reshape(100,100).float().requires_grad_(False)\n    mask = torch.zeros(dummy_tensor.shape, dtype=torchataria.float()).bool()\n    for i, lense in enumerate(lens):\n        mask[i, :lense] = 1\n    return mask\n", "metadata": {"problem_id": 954, "library_problem_id": 22, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 19}}
{"id": 955, "code": "Tensor_2D = torch.diag(Tensor_2D)\nTensor_3D = Tensor_2D.reshape(*Tensor_2D.shape[0],1)", "metadata": {"problem_id": 955, "library_problem_id": 23, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 23}}
{"id": 956, "code": "\n    tensor_1D = torch.diag(t)\n    tensor_2D = tensor_1D.reshape(*t.shape,1)\n    return tensor_2D\n    ", "metadata": {"problem_id": 956, "library_problem_id": 24, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 23}}
{"id": 957, "code": "torch.stack([a,b],dim=0)\n", "metadata": {"problem_id": 957, "library_problem_id": 25, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 25}}
{"id": 958, "code": "torch.stack([a, b], dim=0)\n", "metadata": {"problem_id": 958, "library_problem_id": 26, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 25}}
{"id": 959, "code": "\n    tensor_a = torch.tensor(a, requires_grad=True)\n    tensor_b = torchatarches.tensor(b, requires_grad=True)\n    tensor_c = torch.stack([tensor_a, tensor_b], dim=0)\n    ### END SOLUTION\n\nIn the above code, tensor_c is a tensor of shape (3,11).\n", "metadata": {"problem_id": 959, "library_problem_id": 27, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 25}}
{"id": 960, "code": "a[torch.arange(10).long(), lengths, :] = 0", "metadata": {"problem_id": 960, "library_problem_id": 28, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 28}}
{"id": 961, "code": "a[..., lengths[:]] = 2333", "metadata": {"problem_id": 961, "library_problem_id": 29, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 28}}
{"id": 962, "code": "a[..., lengths, :] = 0", "metadata": {"problem_id": 962, "library_problem_id": 30, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 28}}
{"id": 963, "code": "a[ : , : lengths , : ] = 2333", "metadata": {"problem_id": 963, "library_problem_id": 31, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 28}}
{"id": 964, "code": "tensor_of_tensors = torch.stack(list_of_tensors)\n", "metadata": {"problem_id": 964, "library_problem_id": 32, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 32}}
{"id": 965, "code": "list = [torch.randn(3), torch.randn(3), torch.randn(3)]\nnew_tensors = torch.tensor(list)\nEND SOLUTION\n", "metadata": {"problem_id": 965, "library_problem_id": 33, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 32}}
{"id": 966, "code": "\n    tensor_of_tensors = torch.tensor(list_of_tensors)\n    ### END SOLUTION\ntensor_of_tensors = torch.tensor(list_of_tensors)\n", "metadata": {"problem_id": 966, "library_problem_id": 34, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 32}}
{"id": 967, "code": "tensor_of_tensors = torch.stack(list_of_tensors)\n", "metadata": {"problem_id": 967, "library_problem_id": 35, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 32}}
{"id": 968, "code": "result = torch.einsum('... -> ->', t)", "metadata": {"problem_id": 968, "library_problem_id": 36, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 36}}
{"id": 969, "code": "result = torch.einsum('... -> -> -> ->', t, idx)\n", "metadata": {"problem_id": 969, "library_problem_id": 37, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 36}}
{"id": 970, "code": "result = torch.einsum('ij,ik->ij', t, idx)\n", "metadata": {"problem_id": 970, "library_problem_id": 38, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 36}}
{"id": 971, "code": "ids = torch.argmax(scores,1)\nresult = x[ids.flatten()]", "metadata": {"problem_id": 971, "library_problem_id": 39, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 39}}
{"id": 972, "code": "ids = torch.argmax(scores,1)\nresult = x[ids.flatten()]", "metadata": {"problem_id": 972, "library_problem_id": 40, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 39}}
{"id": 973, "code": "ids = torch.tensor([[0,1,0],[1,0,0],[0,0,1],...]])\nx = torch.tensor([[[1,1,1],...],...,[...],...])\n\nselected_ids = ids.argmax(dim=1)\nresult = x[selected_ids]", "metadata": {"problem_id": 973, "library_problem_id": 41, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 39}}
{"id": 974, "code": "_, indices = torch.topk(softmax_output, 1, dim=1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squ", "metadata": {"problem_id": 974, "library_problem_id": 42, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 42}}
{"id": 975, "code": "_, indices = torch.topk(softmax_output, 1, dim=1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squeeze(1)\n_, indices = indices.squ", "metadata": {"problem_id": 975, "library_problem_id": 43, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 42}}
{"id": 976, "code": "_, indices = torch.topk(softmax_output, 1, dim=1)\n_, indices = indices.squeeze()\ny = y.squeeze()\n", "metadata": {"problem_id": 976, "library_problem_id": 44, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 42}}
{"id": 977, "code": "\n    _, indices = torch.topk(softmax_output, 1, dim=1)\n    _, top_class = indices.max(dim=1)\n    return top_class\n", "metadata": {"problem_id": 977, "library_problem_id": 45, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 42}}
{"id": 978, "code": "_, indices = torch.topk(softmax_output, 1, dim=1)\n_, highest_prob_indices = torch.where(softmax_output == highest_prob_probabilities)\n", "metadata": {"problem_id": 978, "library_problem_id": 46, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 42}}
{"id": 979, "code": "def cross_entropy2d(input, target):\n    # input: (n, c, w, z), target: (n, w, z)\n    n, c, w, z = input.size()\n    # log_p: (n, c, w, z)\n    log_p = F.log_softmax(input, dim=1)\n    # log_p: (n*w*z, c)\n    log_p = log_p.permute(0, 3, 2, 1).contiguous().view(-1, c)  # make class dimension last dimension\n    log_p = log_p[target.view(n, w, z, 1).repeat(0, 0, 0, c) >= 0]  # this looks wrong -> Should rather be a one-hot vector\n    log_p = log_p.view(-1, c)\n    # target: (n*w*z,)\n    mask = target >= 0\n    target = target[mask]\n    loss = F.nll_loss(log_p, target.view(-1))\n    return loss\n\nimages = Variable(torch.randn(5, 3, 4, 4))\nlabels = Variable(torch.LongTensor(5, 4, 4).random_(3))\ncross_entropy2d(images, labels)\n", "metadata": {"problem_id": 979, "library_problem_id": 47, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 47}}
{"id": 980, "code": "def count_equal(tensor1, tensor2):\n    tensor1_flat = tensor1.flatten()\n    tensor2_flat = tensor2.flatten()\n    tensor1_flat.equals(tensor2_flat)\nEND SOLUTION\n\ntensor1 = torch.tensor([...])\ntensor2 = torchatar([...])\n\ncnt_equal = tensor1.sum().item() - tensor2.sum().item()\nEND SOLUTION\n", "metadata": {"problem_id": 980, "library_problem_id": 48, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 48}}
{"id": 981, "code": "def count_equal(tensor1, tensor2):\n    tensor1_flat = tensor1.flatten()\n    tensor2_flat = tensor2.flatten()\n    tensor1_flat.equals(tensor2_flat)\nEND SOLUTION\n\ntensor1 = torch.tensor([...])\ntensor2 = torchatar([...])\n\ncnt_equal = tensor1.sum()\nEND SOLUTION\n", "metadata": {"problem_id": 981, "library_problem_id": 49, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 48}}
{"id": 982, "code": "def count_not_equal(tensor1, tensor2):\n    return torch.sum((tensor1 - tensor2).abs().sum() > 0)\n\ntensor1 = torch.tensor([...])\ntensor2 = torchatar([...])\n\ncnt_not_equal = count_not_equal(tensor1, tensor2)", "metadata": {"problem_id": 982, "library_problem_id": 50, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 48}}
{"id": 983, "code": "\n    cnt_equal = torch.sum((A==B).float())\n    return cnt_equal\n\n# A and B are your tensors\n# cnt_equal is your result\n# cnt_equal.item() will give you the count of elements equal to each other\n# You can use it as you want\n# cnt_equal.item()\n", "metadata": {"problem_id": 983, "library_problem_id": 51, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 48}}
{"id": 984, "code": "def count_equal(tensor1, tensor2):\n    tensor1_flat = tensor1.flatten()\n    tensor2_flat = tensor2.flatten()\n    tensor1_flat.equals(tensor2_flat)\nEND SOLUTION\n\ntensor1 = torch.randint(0,10,size=(2,10))\ntensor2 = torch.randint(0,10,size=(2,10))\n\ntensor1_flat = tensor1.flatten()\ntensor2_flat = tensor2.flatten()\n\ncnt_equal = torch.sum(tensor1_flat == tensor2_flat)\nEND SOLUTION\n", "metadata": {"problem_id": 984, "library_problem_id": 52, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 48}}
{"id": 985, "code": "def count_not_equal(tensor1, tensor2):\n    return torch.sum((tensor1 != tensor2).flatten())\n\ntensor1 = torch.tensor([...])\ntensor2 = torchatar([...])\n\ncnt_not_equal = torch.sum((tensor1 != tensor2).flatten())", "metadata": {"problem_id": 985, "library_problem_id": 53, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Difficult-Rewrite", "perturbation_origin_id": 48}}
{"id": 986, "code": "\nchunk_dim = 10\ntensor_split = torch.split(a, chunk_dim, dim=3)\ntensor_split.shape\n", "metadata": {"problem_id": 986, "library_problem_id": 54, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 54}}
{"id": 987, "code": "\nchunk_dim = 10\ntensor_split = torch.split(a, chunk_dim, dim=2)\ntensor_split", "metadata": {"problem_id": 987, "library_problem_id": 55, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 54}}
{"id": 988, "code": "output = torch.where(mask.bool(), clean_input_spectrogram, output)", "metadata": {"problem_id": 988, "library_problem_id": 56, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 56}}
{"id": 989, "code": "output = torch.where(mask.bool(), clean_input_spectrogram, output)", "metadata": {"problem_id": 989, "library_problem_id": 57, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 56}}
{"id": 990, "code": "x_sign = torch.sign(x)\ny_sign = torch.sign(y)\nmin_val = torch.min(torch.abs(x), torch.abs(y))\nsigned_min = min_val * torch.sign(min_val)\n", "metadata": {"problem_id": 990, "library_problem_id": 58, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 58}}
{"id": 991, "code": "x_sign = torch.sign(x)\ny_sign = torch.sign(y)\nmax_tensor = torch.max(torch.abs(x), torch.abs(y))\nsigned_max = max_tensor * torch.sign(max_tensor)\n", "metadata": {"problem_id": 991, "library_problem_id": 59, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Semantic", "perturbation_origin_id": 58}}
{"id": 992, "code": "\n    sign_x = torch.sign(x)\n    sign_y = torch.sign(y)\n    min_val = torch.min(torch.abs(x), torch.abs(y))\n    keep_indexes = torch.where(torch.abs(x) < min_val, torch.where(y>0, y, x))\n    keep_values = torch.where(torch.abs(x) < min_val, torchdatatypesigny, torchdatatypesignx)\n    result = torch.multiply_entries(keep_indexes, keep_values)\n    return result\n", "metadata": {"problem_id": 992, "library_problem_id": 60, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Surface", "perturbation_origin_id": 58}}
{"id": 993, "code": "import torch\nconfidence_score = torch.nn.Sigmoid()(output)[0].item()\n", "metadata": {"problem_id": 993, "library_problem_id": 61, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 61}}
{"id": 994, "code": "result = torch.zeros(len(a), len(b))\nfor i in range(len(a)):\n    result[i] = np.mean(a[i][:-1] + b[i][1:])\nEND SOLUTION\n", "metadata": {"problem_id": 994, "library_problem_id": 62, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Origin", "perturbation_origin_id": 62}}
{"id": 995, "code": "\n    result = torch.zeros_like(a)\n    for i in range(len(a)):\n        result[:,i] = torch.where(i<len(b), a[i,:], b[i,:])\n    return result\n\n\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\na, b = load_data()\ndef solve(a, b):\n    # return the solution in this function\n    result = torchiorder(a, b)\n    result = torch.where(torch.arange(len(a)) < torch.arange(len(b)), a[i,:], b[i,:])\n    return result\n\n\n\nA:\n\n<code>\nimport numpy as np\nimport pandas as pd\nimport torch\na, b = loaddatastorage()\ndef solve(a, b):\n    # return the solution in this function\n    result = torch.zeros_like(a)\n    for i in range(len(a)):\n        result[:,i] = torch.where(i<len(b), a[i,:], b[i,:])\n    return result\n", "metadata": {"problem_id": 995, "library_problem_id": 63, "library": "Pytorch", "test_case_cnt": 3, "perturbation_type": "Surface", "perturbation_origin_id": 62}}
{"id": 996, "code": "t = torch.tensor([0., 0., 0., 0.])\nnew=torch.tensor([[0., 0., 0.,0.]])\nr = torchsch.stack([t,new]) \nEND SOLUTION\n", "metadata": {"problem_id": 996, "library_problem_id": 64, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Origin", "perturbation_origin_id": 64}}
{"id": 997, "code": "t = torch.tensor([0., 0., 0., 0.])\nnew=torch.tensor([[0., 0., 0.,0.]])\nr = torchsch.stack([t,new]) \nEND SOLUTION\n", "metadata": {"problem_id": 997, "library_problem_id": 65, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Surface", "perturbation_origin_id": 64}}
{"id": 998, "code": "t = torch.tensor([[-1, -1, -1, -1],[-1, 1, 2, -1],[-1, 3, 4, -1],[-1, 5, 6, -1],[-1, 7, 8, -1]])\nprint(t)\n", "metadata": {"problem_id": 998, "library_problem_id": 66, "library": "Pytorch", "test_case_cnt": 2, "perturbation_type": "Semantic", "perturbation_origin_id": 64}}
{"id": 999, "code": "result = torch.bmm(data.perm(1, 2, 0)[...], W).squeeze()\nresult = result.view(10, 2, 3)\nEND SOLUTION\n\nIn your code, you are trying to perform the matrix multiplication operation between the data and the weight W. The perm() function is used to rearrange the dimensions of the tensor data and the weight W. The perm(1, 2, 0) will rearrange the tensor data to be in the shape (10, 2, 3) and (10, 3, 10), and then you can perform the matrix multiplication operation between these two tensors. The result is then reshaped to the shape (10, 2, 3).\n", "metadata": {"problem_id": 999, "library_problem_id": 67, "library": "Pytorch", "test_case_cnt": 1, "perturbation_type": "Origin", "perturbation_origin_id": 67}}
